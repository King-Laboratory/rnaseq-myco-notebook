{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extended RNA-Seq Analysis Training Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For simplicity and time, The short tutorial workflow uses truncated and partial run data from the Cushman et al., project.\n",
    "\n",
    "The tutorial repeats the short tutorial, but with the full fastq files and includes some extra steps, such as how to download and prepare the transcriptome files used by salmon, alternate ways to navigate the NCBI databases for annotation or reference files you might need, and how to combine salmon outputs at the end into a single genecount file.\n",
    "\n",
    "Full fastq files can be rather large, and so the downloading, extracting, and analysis of them means this tutorial can take over 1 hour 45 minutes to run the code fully. This is part of the reason we have a short and easy introductory tutorial, and this longer more full tutorial for those interested.\n",
    "\n",
    "If this is too lengthy feel free to move on to the snakemake tutorial or the DEG analysis tutorial -- all the files used in the DEG tutorial were created using this extended tutorial workflow.\n",
    "\n",
    "![RNA-Seq workflow](images/rnaseq-workflow.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Objectives\n",
    "\n",
    "* **Install necessary bioinformatics tools:**  Learn to install and manage bioinformatics software using mamba.\n",
    "\n",
    "* **Set up a project directory structure:** Organize files efficiently for RNA-Seq analysis.\n",
    "\n",
    "* **Download RNA-Seq data from the SRA:** Utilize `prefetch` and `fasterq-dump` to download and convert SRA data to FASTQ format.  Learn to obtain accession numbers from NCBI databases (both manually and using BigQuery).\n",
    "\n",
    "* **Quality control of raw reads:** Use `FastQC` to assess the quality of raw sequencing reads and `MultiQC` to generate a summary report.\n",
    "\n",
    "* **Read trimming and adapter removal:** Employ `Trimmomatic` to improve read quality by removing adapter sequences and low-quality bases.\n",
    "\n",
    "* **Transcriptome preparation:** Download and prepare a reference transcriptome using `entrez-direct` and `gffread`, including creating a decoy file for Salmon.\n",
    "\n",
    "* **RNA-Seq read alignment and quantification:** Use `Salmon` to align reads to the transcriptome and quantify gene expression levels.\n",
    "\n",
    "* **Gene expression analysis:**  Interpret Salmon output to identify highly expressed genes and analyze the expression of specific genes of interest.\n",
    "\n",
    "* **Combine gene counts:** Merge individual sample quantification results into a single gene count table for downstream analysis (e.g., differential expression)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "**APIs:**\n",
    "\n",
    "* **gsutil:**  The Google Cloud Storage (GCS) tool `gsutil` is used extensively to download data from a Google Cloud Storage bucket.  This implicitly requires the Google Cloud Storage API to be enabled.\n",
    "\n",
    "**Software and Dependencies:**\n",
    "\n",
    "* **Trimmomatic:**  Used for quality trimming of raw sequencing reads.\n",
    "* **FastQC:**  A quality control tool for high-throughput sequence data.\n",
    "* **MultiQC:**  Aggregates results from multiple FastQC runs into a single report.\n",
    "* **Salmon:** A tool for quantifying transcript abundances from RNA-Seq data.\n",
    "* **Entrez Direct (EDirect):** NCBI's command-line tool for accessing the Entrez databases (used here to retrieve reference genome information).\n",
    "* **gffread:**  Parses GFF/GTF annotation files and extracts information from them, such as to create a transcriptome reference file from genome and annotation files.\n",
    "* **parallel-fastq-dump:**  A parallel version of the `fastq-dump` tool (part of SRA Toolkit).  It is likely optimized to process multiple files efficiently.\n",
    "* **sra-tools:** NCBI's SRA Toolkit for downloading and processing data from the Sequence Read Archive.  Specifically, `prefetch` and `fasterq-dump` are used here.\n",
    "* **pigz:** A parallel version of the gzip compression/decompression tool.  It's faster for larger files.\n",
    "* **gsutil:** Google Cloud Storage (GCS) command line tool (used to download the accession list file).\n",
    "* **BigQuery (optional):** Google's data warehouse service (used optionally to generate an accession list file, requires the BigQuery API to be enabled in your GCP Project and  proper authentication credentials in the environment)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 1: Install the tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using mamba and bioconda, install the tools that will be used in this tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "100 81.7M  100 81.7M    0     0   165M      0 --:--:-- --:--:-- --:--:--  165M\n",
      "PREFIX=/home/jupyter/miniforge\n",
      "Unpacking bootstrapper...\n",
      "ln: failed to create symbolic link '/home/jupyter/miniforge/_conda': File exists\n"
     ]
    }
   ],
   "source": [
    "!curl -L -O https://github.com/conda-forge/miniforge/releases/latest/download/Miniforge3-$(uname)-$(uname -m).sh \n",
    "!bash Miniforge3-$(uname)-$(uname -m).sh -b -u -p $HOME/miniforge "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Show the system where to find the miniforge:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"PATH\"] += os.pathsep + os.environ[\"HOME\"]+\"/miniforge/bin\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conda-forge/linux-64                                        Using cache\n",
      "conda-forge/noarch                                          Using cache\n",
      "bioconda/linux-64                                           Using cache\n",
      "bioconda/noarch                                             Using cache\n",
      "\u001b[?25l\u001b[2K\u001b[0G[+] 0.0s\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[0G\u001b[?25h\u001b[?25l\u001b[2K\u001b[0G\u001b[?25h\n",
      "Pinned packages:\n",
      "\n",
      "  - python=3.10\n",
      "\n",
      "\n",
      "Transaction\n",
      "\n",
      "  Prefix: /opt/conda\n",
      "\n",
      "  Updating specs:\n",
      "\n",
      "   - trimmomatic\n",
      "   - fastqc\n",
      "   - multiqc\n",
      "   - salmon\n",
      "   - entrez-direct\n",
      "   - gffread\n",
      "   - parallel-fastq-dump\n",
      "   - sra-tools=3.0.5\n",
      "   - pigz\n",
      "\n",
      "\n",
      "  Package                           Version  Build             Channel          Size\n",
      "──────────────────────────────────────────────────────────────────────────────────────\n",
      "  Install:\n",
      "──────────────────────────────────────────────────────────────────────────────────────\n",
      "\n",
      "  \u001b[32m+ curl                     \u001b[0m        8.17.0  h4e3cde8_0        conda-forge     186kB\n",
      "  \u001b[32m+ entrez-direct            \u001b[0m          24.0  he881be0_0        bioconda         17MB\n",
      "  \u001b[32m+ gffread                  \u001b[0m        0.12.7  h077b44d_6        bioconda        135kB\n",
      "  \u001b[32m+ libidn2                  \u001b[0m         2.3.8  hfac485b_1        conda-forge     139kB\n",
      "  \u001b[32m+ libunistring             \u001b[0m        0.9.10  h7f98852_0        conda-forge       1MB\n",
      "  \u001b[32m+ ncbi-vdb                 \u001b[0m         3.3.0  h9948957_0        bioconda          9MB\n",
      "  \u001b[32m+ ossuuid                  \u001b[0m         1.6.2  h5888daf_1001     conda-forge      54kB\n",
      "  \u001b[32m+ parallel-fastq-dump      \u001b[0m         0.6.7  pyhdfd78af_0      bioconda         10kB\n",
      "  \u001b[32m+ perl-alien-build         \u001b[0m          2.84  pl5321h7b50bb2_1  bioconda        200kB\n",
      "  \u001b[32m+ perl-alien-libxml2       \u001b[0m          0.17  pl5321h577a1d6_1  bioconda         14kB\n",
      "  \u001b[32m+ perl-business-isbn       \u001b[0m         3.007  pl5321hd8ed1ab_0  conda-forge      18kB\n",
      "  \u001b[32m+ perl-business-isbn-data  \u001b[0m  20210112.006  pl5321hd8ed1ab_0  conda-forge      22kB\n",
      "  \u001b[32m+ perl-capture-tiny        \u001b[0m          0.48  pl5321ha770c72_1  conda-forge      17kB\n",
      "  \u001b[32m+ perl-carp                \u001b[0m          1.50  pl5321hd8ed1ab_0  conda-forge      22kB\n",
      "  \u001b[32m+ perl-constant            \u001b[0m          1.33  pl5321hd8ed1ab_0  conda-forge      16kB\n",
      "  \u001b[32m+ perl-exporter            \u001b[0m          5.74  pl5321hd8ed1ab_0  conda-forge      19kB\n",
      "  \u001b[32m+ perl-extutils-makemaker  \u001b[0m          7.70  pl5321hd8ed1ab_0  conda-forge     157kB\n",
      "  \u001b[32m+ perl-ffi-checklib        \u001b[0m          0.28  pl5321hdfd78af_0  bioconda         16kB\n",
      "  \u001b[32m+ perl-file-chdir          \u001b[0m        0.1011  pl5321hd8ed1ab_0  conda-forge      17kB\n",
      "  \u001b[32m+ perl-file-path           \u001b[0m          2.18  pl5321hd8ed1ab_0  conda-forge      22kB\n",
      "  \u001b[32m+ perl-file-temp           \u001b[0m        0.2304  pl5321hd8ed1ab_0  conda-forge      32kB\n",
      "  \u001b[32m+ perl-file-which          \u001b[0m          1.24  pl5321hd8ed1ab_0  conda-forge      17kB\n",
      "  \u001b[32m+ perl-importer            \u001b[0m         0.026  pl5321hd8ed1ab_0  conda-forge      27kB\n",
      "  \u001b[32m+ perl-parent              \u001b[0m         0.243  pl5321hd8ed1ab_0  conda-forge      14kB\n",
      "  \u001b[32m+ perl-path-tiny           \u001b[0m         0.124  pl5321hd8ed1ab_0  conda-forge      42kB\n",
      "  \u001b[32m+ perl-pathtools           \u001b[0m          3.75  pl5321hb9d3cd8_2  conda-forge      51kB\n",
      "  \u001b[32m+ perl-scope-guard         \u001b[0m          0.21  pl5321hd8ed1ab_0  conda-forge      16kB\n",
      "  \u001b[32m+ perl-sub-info            \u001b[0m         0.002  pl5321hd8ed1ab_0  conda-forge      19kB\n",
      "  \u001b[32m+ perl-term-table          \u001b[0m         0.028  pl5321hdfd78af_0  bioconda         25kB\n",
      "  \u001b[32m+ perl-test-fatal          \u001b[0m         0.016  pl5321ha770c72_0  conda-forge      20kB\n",
      "  \u001b[32m+ perl-test-warnings       \u001b[0m         0.031  pl5321ha770c72_0  conda-forge      22kB\n",
      "  \u001b[32m+ perl-test2-suite         \u001b[0m      0.000163  pl5321hdfd78af_0  bioconda        213kB\n",
      "  \u001b[32m+ perl-try-tiny            \u001b[0m          0.31  pl5321ha770c72_0  conda-forge      18kB\n",
      "  \u001b[32m+ perl-uri                 \u001b[0m          5.34  pl5321ha770c72_0  conda-forge      79kB\n",
      "  \u001b[32m+ perl-xml-libxml          \u001b[0m        2.0210  pl5321hf886d80_0  bioconda        278kB\n",
      "  \u001b[32m+ perl-xml-namespacesupport\u001b[0m          1.12  pl5321hd8ed1ab_0  conda-forge      23kB\n",
      "  \u001b[32m+ perl-xml-sax             \u001b[0m          1.02  pl5321hd8ed1ab_0  conda-forge      44kB\n",
      "  \u001b[32m+ perl-xml-sax-base        \u001b[0m          1.09  pl5321hd8ed1ab_0  conda-forge      28kB\n",
      "  \u001b[32m+ pigz                     \u001b[0m           2.8  h421ea60_2        conda-forge      81kB\n",
      "  \u001b[32m+ sra-tools                \u001b[0m         3.0.5  h9f5acd7_1        bioconda         74MB\n",
      "  \u001b[32m+ wget                     \u001b[0m        1.21.4  hda4d442_0        conda-forge     770kB\n",
      "  \u001b[32m+ zlib                     \u001b[0m         1.3.1  hb9d3cd8_2        conda-forge      92kB\n",
      "\n",
      "  Summary:\n",
      "\n",
      "  Install: 42 packages\n",
      "\n",
      "  Total download: 104MB\n",
      "\n",
      "──────────────────────────────────────────────────────────────────────────────────────\n",
      "\n",
      "\n",
      "\n",
      "Transaction starting\n",
      "\u001b[?25l\u001b[2K\u001b[0G[+] 0.0s\n",
      "Downloading      ╸\u001b[33m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m   0.0 B                            0.0s\n",
      "Extracting       \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m       0                            0.0s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Glibunistring                                         1.4MB @  ??.?MB/s  0.0s\n",
      "[+] 0.1s\n",
      "Downloading  (5) \u001b[33m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m   1.8MB entrez-direct              0.0s\n",
      "Extracting   (1) \u001b[33m━━━━━━━━━━╸\u001b[0m\u001b[90m━━━━━━━━━━━━\u001b[0m       0 libunistring               0.0s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Gperl-xml-libxml                                    278.0kB @  ??.?MB/s  0.1s\n",
      "wget                                               770.4kB @   3.0MB/s  0.1s\n",
      "[+] 0.2s\n",
      "Downloading  (5) ━━╸\u001b[33m━━━━━━━━━━━━━━━━━━━━\u001b[0m  16.9MB entrez-direct              0.1s\n",
      "Extracting   (3) \u001b[33m━━━━━━━━━━━╸\u001b[0m\u001b[90m━━━━━━━━━━━\u001b[0m       0 libunistring               0.1s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Gperl-test2-suite                                   212.7kB @   4.2MB/s  0.1s\n",
      "perl-alien-build                                   200.1kB @  ??.?MB/s  0.1s\n",
      "curl                                               186.2kB @  ??.?MB/s  0.0s\n",
      "ncbi-vdb                                             8.6MB @  29.4MB/s  0.2s\n",
      "[+] 0.3s\n",
      "Downloading  (5) ━━━━━╸\u001b[33m━━━━━━━━━━━━━━━━━\u001b[0m  31.5MB entrez-direct              0.2s\n",
      "Extracting   (5) \u001b[33m━━━━━━━━━━━━━╸\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m       1 libunistring               0.2s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Gentrez-direct                                       17.1MB @  52.9MB/s  0.3s\n",
      "libidn2                                            139.0kB @  ??.?MB/s  0.0s\n",
      "perl-extutils-makemaker                            157.3kB @  ??.?MB/s  0.1s\n",
      "gffread                                            134.8kB @  ??.?MB/s  0.1s\n",
      "pigz                                                81.2kB @  ??.?MB/s  0.0s\n",
      "perl-uri                                            78.7kB @   1.4MB/s  0.1s\n",
      "[+] 0.4s\n",
      "Downloading  (5) ━━━━━━╸\u001b[33m━━━━━━━━━━━━━━━━\u001b[0m  34.5MB ossuuid                    0.3s\n",
      "Extracting   (9) ╸\u001b[33m━━━━━╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━\u001b[0m       2 libunistring               0.3s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Gperl-pathtools                                      50.7kB @ 921.1kB/s  0.1s\n",
      "ossuuid                                             54.2kB @  ??.?MB/s  0.1s\n",
      "perl-xml-sax                                        43.5kB @  ??.?MB/s  0.1s\n",
      "perl-path-tiny                                      41.5kB @ 766.5kB/s  0.1s\n",
      "perl-file-temp                                      31.5kB @ 623.7kB/s  0.1s\n",
      "[+] 0.5s\n",
      "Downloading  (5) ━━━━━━━╸\u001b[33m━━━━━━━━━━━━━━━\u001b[0m  40.0MB perl-importer              0.4s\n",
      "Extracting  (13) ━╸\u001b[33m━━━━━━━╸\u001b[0m\u001b[90m━━━━━━━━━━━━━\u001b[0m       5 entrez-direct              0.4s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Gzlib                                                92.3kB @  ??.?MB/s  0.2s\n",
      "perl-xml-sax-base                                   27.6kB @  ??.?MB/s  0.1s\n",
      "perl-importer                                       26.9kB @  ??.?MB/s  0.1s\n",
      "perl-xml-namespacesupport                           22.9kB @  ??.?MB/s  0.1s\n",
      "perl-term-table                                     24.7kB @  ??.?MB/s  0.1s\n",
      "[+] 0.6s\n",
      "Downloading  (5) ━━━━━━━━╸\u001b[33m━━━━━━━━━━━━━━\u001b[0m  43.1MB perl-business-isbn-data    0.5s\n",
      "Extracting  (14) ━━━╸\u001b[33m━━━━━━━━╸\u001b[0m\u001b[90m━━━━━━━━━━\u001b[0m       9 entrez-direct              0.5s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Gperl-carp                                           22.3kB @  ??.?MB/s  0.0s\n",
      "perl-file-path                                      22.4kB @  ??.?MB/s  0.1s\n",
      "perl-test-warnings                                  21.7kB @  ??.?MB/s  0.1s\n",
      "perl-business-isbn-data                             21.5kB @  ??.?MB/s  0.1s\n",
      "perl-sub-info                                       19.0kB @  ??.?MB/s  0.0s\n",
      "perl-exporter                                       19.1kB @  ??.?MB/s  0.0s\n",
      "perl-test-fatal                                     19.5kB @  ??.?MB/s  0.1s\n",
      "[+] 0.7s\n",
      "Downloading  (5) ━━━━━━━━━╸\u001b[33m━━━━━━━━━━━━━\u001b[0m  46.6MB perl-business-isbn         0.6s\n",
      "Extracting  (17) ━━━━━━╸\u001b[33m━━━━━━━━━╸\u001b[0m\u001b[90m━━━━━━\u001b[0m      13 entrez-direct              0.6s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Gperl-try-tiny                                       17.7kB @  ??.?MB/s  0.1s\n",
      "perl-file-which                                     17.3kB @  ??.?MB/s  0.1s\n",
      "perl-file-chdir                                     17.0kB @ 338.2kB/s  0.1s\n",
      "perl-business-isbn                                  18.3kB @  ??.?MB/s  0.1s\n",
      "perl-capture-tiny                                   16.5kB @  ??.?MB/s  0.0s\n",
      "perl-ffi-checklib                                   16.1kB @  ??.?MB/s  0.1s\n",
      "[+] 0.8s\n",
      "Downloading  (5) ━━━━━━━━━━╸\u001b[33m━━━━━━━━━━━━\u001b[0m  51.2MB perl-alien-libxml2         0.7s\n",
      "Extracting  (21) ━━━━━━━╸\u001b[33m━━━━━━━━━━━╸\u001b[0m\u001b[90m━━━\u001b[0m      15 entrez-direct              0.7s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Gperl-scope-guard                                    16.1kB @  ??.?MB/s  0.1s\n",
      "perl-constant                                       15.7kB @  ??.?MB/s  0.1s\n",
      "perl-alien-libxml2                                  14.2kB @  ??.?MB/s  0.1s\n",
      "perl-parent                                         13.9kB @  ??.?MB/s  0.1s\n",
      "parallel-fastq-dump                                  9.9kB @ 180.1kB/s  0.1s\n",
      "[+] 0.9s\n",
      "Downloading  (1) ━━━━━━━━━━╸\u001b[33m━━━━━━━━━━━━\u001b[0m  54.2MB sra-tools                  0.8s\n",
      "Extracting  (22) ━━━━━━━━━╸\u001b[33m━━━━━━━━━━━━━\u001b[0m      19 gffread                    0.8s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 1.0s\n",
      "Downloading  (1) ━━━━━━━━━━━╸\u001b[33m━━━━━━━━━━━\u001b[0m  57.8MB sra-tools                  0.9s\n",
      "Extracting  (16) ━━━━━━━━━━━━╸\u001b[33m━━━━━━━━━━\u001b[0m      25 gffread                    0.9s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 1.1s\n",
      "Downloading  (1) ━━━━━━━━━━━━╸\u001b[33m━━━━━━━━━━\u001b[0m  60.1MB sra-tools                  1.0s\n",
      "Extracting  (11) ━━━━━━━━━━━━━━━╸\u001b[33m━━━━━━━\u001b[0m      30 gffread                    1.0s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 1.2s\n",
      "Downloading  (1) ━━━━━━━━━━━━━╸\u001b[33m━━━━━━━━━\u001b[0m  64.8MB sra-tools                  1.1s\n",
      "Extracting   (5) ━━━━━━━━━━━━━━━━━━╸\u001b[33m━━━━\u001b[0m      36 gffread                    1.1s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 1.3s\n",
      "Downloading  (1) ━━━━━━━━━━━━━╸\u001b[33m━━━━━━━━━\u001b[0m  67.8MB sra-tools                  1.2s\n",
      "Extracting   (1) ━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━━\u001b[0m      40 entrez-direct              1.2s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 1.4s\n",
      "Downloading  (1) ━━━━━━━━━━━━━━╸\u001b[33m━━━━━━━━\u001b[0m  70.3MB sra-tools                  1.3s\n",
      "Extracting   (1) ━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━━\u001b[0m      40 entrez-direct              1.3s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 1.5s\n",
      "Downloading  (1) ━━━━━━━━━━━━━━━╸\u001b[33m━━━━━━━\u001b[0m  73.1MB sra-tools                  1.4s\n",
      "Extracting   (1) ━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━━\u001b[0m      40 entrez-direct              1.4s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 1.6s\n",
      "Downloading  (1) ━━━━━━━━━━━━━━━╸\u001b[33m━━━━━━━\u001b[0m  74.0MB sra-tools                  1.5s\n",
      "Extracting   (1) ━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━━\u001b[0m      40 entrez-direct              1.5s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 1.7s\n",
      "Downloading  (1) ━━━━━━━━━━━━━━━━╸\u001b[33m━━━━━━\u001b[0m  80.6MB sra-tools                  1.6s\n",
      "Extracting   (1) ━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━━\u001b[0m      40 entrez-direct              1.6s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 1.8s\n",
      "Downloading  (1) ━━━━━━━━━━━━━━━━━╸\u001b[33m━━━━━\u001b[0m  82.7MB sra-tools                  1.7s\n",
      "Extracting   (1) ━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━━\u001b[0m      40 entrez-direct              1.7s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 1.9s\n",
      "Downloading  (1) ━━━━━━━━━━━━━━━━━╸\u001b[33m━━━━━\u001b[0m  84.3MB sra-tools                  1.8s\n",
      "Extracting   (1) ━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━━\u001b[0m      40 entrez-direct              1.8s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 2.0s\n",
      "Downloading  (1) ━━━━━━━━━━━━━━━━━╸\u001b[33m━━━━━\u001b[0m  84.9MB sra-tools                  1.9s\n",
      "Extracting   (1) ━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━━\u001b[0m      40 entrez-direct              1.9s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 2.1s\n",
      "Downloading  (1) ━━━━━━━━━━━━━━━━━━╸\u001b[33m━━━━\u001b[0m  87.8MB sra-tools                  2.0s\n",
      "Extracting   (1) ━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━━\u001b[0m      40 entrez-direct              2.0s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 2.2s\n",
      "Downloading  (1) ━━━━━━━━━━━━━━━━━━━╸\u001b[33m━━━\u001b[0m  92.5MB sra-tools                  2.1s\n",
      "Extracting   (1) ━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━━\u001b[0m      40 entrez-direct              2.1s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 2.3s\n",
      "Downloading  (1) ━━━━━━━━━━━━━━━━━━━╸\u001b[33m━━━\u001b[0m  93.9MB sra-tools                  2.2s\n",
      "Extracting   (1) ━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━━\u001b[0m      40 entrez-direct              2.2s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 2.4s\n",
      "Downloading  (1) ━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━━\u001b[0m  97.2MB sra-tools                  2.3s\n",
      "Extracting   (1) ━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━━\u001b[0m      40 entrez-direct              2.3s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 2.5s\n",
      "Downloading  (1) ━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━━\u001b[0m 100.0MB sra-tools                  2.4s\n",
      "Extracting   (1) ━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━━\u001b[0m      40 entrez-direct              2.4s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Gsra-tools                                           74.2MB @  28.7MB/s  2.5s\n",
      "[+] 2.6s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━ 104.4MB                            2.5s\n",
      "Extracting   (1) ━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━━\u001b[0m      40 entrez-direct              2.5s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 2.7s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━ 104.4MB                            2.5s\n",
      "Extracting   (1) ━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━━\u001b[0m      40 entrez-direct              2.6s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 2.8s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━ 104.4MB                            2.5s\n",
      "Extracting   (1) ━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━━\u001b[0m      40 entrez-direct              2.7s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 2.9s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━ 104.4MB                            2.5s\n",
      "Extracting   (2) ━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━━\u001b[0m      40 sra-tools                  2.8s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 3.0s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━ 104.4MB                            2.5s\n",
      "Extracting   (2) ━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━━\u001b[0m      40 sra-tools                  2.9s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 3.1s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━ 104.4MB                            2.5s\n",
      "Extracting   (1) ━━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━\u001b[0m      41 sra-tools                  3.0s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 3.2s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━ 104.4MB                            2.5s\n",
      "Extracting   (1) ━━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━\u001b[0m      41 sra-tools                  3.1s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 3.3s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━ 104.4MB                            2.5s\n",
      "Extracting   (1) ━━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━\u001b[0m      41 sra-tools                  3.2s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 3.4s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━ 104.4MB                            2.5s\n",
      "Extracting   (1) ━━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━\u001b[0m      41 sra-tools                  3.3s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 3.5s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━ 104.4MB                            2.5s\n",
      "Extracting   (1) ━━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━\u001b[0m      41 sra-tools                  3.4s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 3.6s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━ 104.4MB                            2.5s\n",
      "Extracting   (1) ━━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━\u001b[0m      41 sra-tools                  3.5s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 3.7s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━ 104.4MB                            2.5s\n",
      "Extracting   (1) ━━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━\u001b[0m      41 sra-tools                  3.6s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 3.8s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━ 104.4MB                            2.5s\n",
      "Extracting   (1) ━━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━\u001b[0m      41 sra-tools                  3.7s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 3.9s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━ 104.4MB                            2.5s\n",
      "Extracting   (1) ━━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━\u001b[0m      41 sra-tools                  3.8s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 4.0s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━ 104.4MB                            2.5s\n",
      "Extracting   (1) ━━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━\u001b[0m      41 sra-tools                  3.9s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 4.1s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━ 104.4MB                            2.5s\n",
      "Extracting   (1) ━━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━\u001b[0m      41 sra-tools                  4.0s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 4.2s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━ 104.4MB                            2.5s\n",
      "Extracting   (1) ━━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━\u001b[0m      41 sra-tools                  4.1s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 4.3s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━ 104.4MB                            2.5s\n",
      "Extracting   (1) ━━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━\u001b[0m      41 sra-tools                  4.2s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 4.4s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━ 104.4MB                            2.5s\n",
      "Extracting   (1) ━━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━\u001b[0m      41 sra-tools                  4.3s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 4.5s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━ 104.4MB                            2.5s\n",
      "Extracting   (1) ━━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━\u001b[0m      41 sra-tools                  4.4s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 4.6s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━ 104.4MB                            2.5s\n",
      "Extracting   (1) ━━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━\u001b[0m      41 sra-tools                  4.5s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 4.7s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━ 104.4MB                            2.5s\n",
      "Extracting   (1) ━━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━\u001b[0m      41 sra-tools                  4.6s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 4.8s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━ 104.4MB                            2.5s\n",
      "Extracting   (1) ━━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━\u001b[0m      41 sra-tools                  4.7s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 4.9s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━ 104.4MB                            2.5s\n",
      "Extracting   (1) ━━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━\u001b[0m      41 sra-tools                  4.8s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 5.0s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━ 104.4MB                            2.5s\n",
      "Extracting   (1) ━━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━\u001b[0m      41 sra-tools                  4.9s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 5.1s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━ 104.4MB                            2.5s\n",
      "Extracting   (1) ━━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━\u001b[0m      41 sra-tools                  5.0s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 5.2s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━ 104.4MB                            2.5s\n",
      "Extracting   (1) ━━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━\u001b[0m      41 sra-tools                  5.1s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 5.3s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━ 104.4MB                            2.5s\n",
      "Extracting   (1) ━━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━\u001b[0m      41 sra-tools                  5.2s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 5.4s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━ 104.4MB                            2.5s\n",
      "Extracting   (1) ━━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━\u001b[0m      41 sra-tools                  5.3s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 5.5s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━ 104.4MB                            2.5s\n",
      "Extracting   (1) ━━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━\u001b[0m      41 sra-tools                  5.4s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 5.6s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━ 104.4MB                            2.5s\n",
      "Extracting   (1) ━━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━\u001b[0m      41 sra-tools                  5.5s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 5.7s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━ 104.4MB                            2.5s\n",
      "Extracting   (1) ━━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━\u001b[0m      41 sra-tools                  5.6s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 5.8s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━ 104.4MB                            2.5s\n",
      "Extracting   (1) ━━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━\u001b[0m      41 sra-tools                  5.7s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 5.9s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━ 104.4MB                            2.5s\n",
      "Extracting   (1) ━━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━\u001b[0m      41 sra-tools                  5.8s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 6.0s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━ 104.4MB                            2.5s\n",
      "Extracting   (1) ━━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━\u001b[0m      41 sra-tools                  5.9s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 6.1s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━ 104.4MB                            2.5s\n",
      "Extracting   (1) ━━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━\u001b[0m      41 sra-tools                  6.0s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 6.2s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━ 104.4MB                            2.5s\n",
      "Extracting   (1) ━━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━\u001b[0m      41 sra-tools                  6.1s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 6.3s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━ 104.4MB                            2.5s\n",
      "Extracting   (1) ━━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━\u001b[0m      41 sra-tools                  6.2s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 6.4s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━ 104.4MB                            2.5s\n",
      "Extracting   (1) ━━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━\u001b[0m      41 sra-tools                  6.3s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 6.5s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━ 104.4MB                            2.5s\n",
      "Extracting   (1) ━━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━\u001b[0m      41 sra-tools                  6.4s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 6.6s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━ 104.4MB                            2.5s\n",
      "Extracting   (1) ━━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━\u001b[0m      41 sra-tools                  6.5s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 6.7s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━ 104.4MB                            2.5s\n",
      "Extracting   (1) ━━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━\u001b[0m      41 sra-tools                  6.6s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 6.8s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━ 104.4MB                            2.5s\n",
      "Extracting   (1) ━━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━\u001b[0m      41 sra-tools                  6.7s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 6.9s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━ 104.4MB                            2.5s\n",
      "Extracting   (1) ━━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━\u001b[0m      41 sra-tools                  6.8s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 7.0s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━ 104.4MB                            2.5s\n",
      "Extracting   (1) ━━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━\u001b[0m      41 sra-tools                  6.9s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 7.1s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━ 104.4MB                            2.5s\n",
      "Extracting   (1) ━━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━\u001b[0m      41 sra-tools                  7.0s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 7.2s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━ 104.4MB                            2.5s\n",
      "Extracting   (1) ━━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━\u001b[0m      41 sra-tools                  7.1s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 7.3s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━ 104.4MB                            2.5s\n",
      "Extracting   (1) ━━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━\u001b[0m      41 sra-tools                  7.2s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 7.4s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━ 104.4MB                            2.5s\n",
      "Extracting   (1) ━━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━\u001b[0m      41 sra-tools                  7.3s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 7.5s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━ 104.4MB                            2.5s\n",
      "Extracting   (1) ━━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━\u001b[0m      41 sra-tools                  7.4s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 7.6s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━ 104.4MB                            2.5s\n",
      "Extracting   (1) ━━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━\u001b[0m      41 sra-tools                  7.5s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 7.7s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━ 104.4MB                            2.5s\n",
      "Extracting   (1) ━━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━\u001b[0m      41 sra-tools                  7.6s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 7.8s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━ 104.4MB                            2.5s\n",
      "Extracting   (1) ━━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━\u001b[0m      41 sra-tools                  7.7s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 7.9s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━ 104.4MB                            2.5s\n",
      "Extracting   (1) ━━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━\u001b[0m      41 sra-tools                  7.8s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 8.0s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━ 104.4MB                            2.5s\n",
      "Extracting   (1) ━━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━\u001b[0m      41 sra-tools                  7.9s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 8.1s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━ 104.4MB                            2.5s\n",
      "Extracting   (1) ━━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━\u001b[0m      41 sra-tools                  8.0s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 8.2s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━ 104.4MB                            2.5s\n",
      "Extracting   (1) ━━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━\u001b[0m      41 sra-tools                  8.1s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 8.3s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━ 104.4MB                            2.5s\n",
      "Extracting   (1) ━━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━\u001b[0m      41 sra-tools                  8.2s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 8.4s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━ 104.4MB                            2.5s\n",
      "Extracting   (1) ━━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━\u001b[0m      41 sra-tools                  8.3s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 8.5s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━ 104.4MB                            2.5s\n",
      "Extracting   (1) ━━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━\u001b[0m      41 sra-tools                  8.4s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 8.6s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━ 104.4MB                            2.5s\n",
      "Extracting   (1) ━━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━\u001b[0m      41 sra-tools                  8.5s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 8.7s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━ 104.4MB                            2.5s\n",
      "Extracting   (1) ━━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━\u001b[0m      41 sra-tools                  8.6s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 8.8s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━ 104.4MB                            2.5s\n",
      "Extracting   (1) ━━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━\u001b[0m      41 sra-tools                  8.7s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 8.9s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━ 104.4MB                            2.5s\n",
      "Extracting   (1) ━━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━\u001b[0m      41 sra-tools                  8.8s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 9.0s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━ 104.4MB                            2.5s\n",
      "Extracting   (1) ━━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━\u001b[0m      41 sra-tools                  8.9s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 9.1s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━ 104.4MB                            2.5s\n",
      "Extracting   (1) ━━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━\u001b[0m      41 sra-tools                  9.0s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 9.2s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━ 104.4MB                            2.5s\n",
      "Extracting   (1) ━━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━\u001b[0m      41 sra-tools                  9.1s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 9.3s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━ 104.4MB                            2.5s\n",
      "Extracting   (1) ━━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━\u001b[0m      41 sra-tools                  9.2s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 9.4s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━ 104.4MB                            2.5s\n",
      "Extracting   (1) ━━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━\u001b[0m      41 sra-tools                  9.3s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 9.5s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━ 104.4MB                            2.5s\n",
      "Extracting   (1) ━━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━\u001b[0m      41 sra-tools                  9.4s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 9.6s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━ 104.4MB                            2.5s\n",
      "Extracting   (1) ━━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━\u001b[0m      41 sra-tools                  9.5s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 9.7s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━ 104.4MB                            2.5s\n",
      "Extracting   (1) ━━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━\u001b[0m      41 sra-tools                  9.6s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 9.8s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━ 104.4MB                            2.5s\n",
      "Extracting   (1) ━━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━\u001b[0m      41 sra-tools                  9.7s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 9.9s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━ 104.4MB                            2.5s\n",
      "Extracting   (1) ━━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━\u001b[0m      41 sra-tools                  9.8s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 10.0s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━ 104.4MB                            2.5s\n",
      "Extracting   (1) ━━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━\u001b[0m      41 sra-tools                  9.9s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 10.1s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━ 104.4MB                            2.5s\n",
      "Extracting   (1) ━━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━\u001b[0m      41 sra-tools                 10.0s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 10.2s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━ 104.4MB                            2.5s\n",
      "Extracting   (1) ━━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━\u001b[0m      41 sra-tools                 10.1s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 10.3s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━ 104.4MB                            2.5s\n",
      "Extracting   (1) ━━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━\u001b[0m      41 sra-tools                 10.2s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 10.4s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━ 104.4MB                            2.5s\n",
      "Extracting   (1) ━━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━\u001b[0m      41 sra-tools                 10.3s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 10.5s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━ 104.4MB                            2.5s\n",
      "Extracting   (1) ━━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━\u001b[0m      41 sra-tools                 10.4s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 10.6s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━ 104.4MB                            2.5s\n",
      "Extracting   (1) ━━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━\u001b[0m      41 sra-tools                 10.5s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 10.7s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━ 104.4MB                            2.5s\n",
      "Extracting   (1) ━━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━\u001b[0m      41 sra-tools                 10.6s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 10.8s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━ 104.4MB                            2.5s\n",
      "Extracting   (1) ━━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━\u001b[0m      41 sra-tools                 10.7s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 10.9s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━ 104.4MB                            2.5s\n",
      "Extracting   (1) ━━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━\u001b[0m      41 sra-tools                 10.8s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 11.0s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━ 104.4MB                            2.5s\n",
      "Extracting   (1) ━━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━\u001b[0m      41 sra-tools                 10.9s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 11.1s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━ 104.4MB                            2.5s\n",
      "Extracting   (1) ━━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━\u001b[0m      41 sra-tools                 11.0s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 11.2s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━ 104.4MB                            2.5s\n",
      "Extracting   (1) ━━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━\u001b[0m      41 sra-tools                 11.1s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 11.3s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━ 104.4MB                            2.5s\n",
      "Extracting   (1) ━━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━\u001b[0m      41 sra-tools                 11.2s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 11.4s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━ 104.4MB                            2.5s\n",
      "Extracting   (1) ━━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━\u001b[0m      41 sra-tools                 11.3s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 11.5s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━ 104.4MB                            2.5s\n",
      "Extracting   (1) ━━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━\u001b[0m      41 sra-tools                 11.4s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 11.6s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━ 104.4MB                            2.5s\n",
      "Extracting   (1) ━━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━\u001b[0m      41 sra-tools                 11.5s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 11.7s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━ 104.4MB                            2.5s\n",
      "Extracting   (1) ━━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━\u001b[0m      41 sra-tools                 11.6s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 11.8s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━ 104.4MB                            2.5s\n",
      "Extracting   (1) ━━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━\u001b[0m      41 sra-tools                 11.7s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 11.9s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━ 104.4MB                            2.5s\n",
      "Extracting   (1) ━━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━\u001b[0m      41 sra-tools                 11.8s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 12.0s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━ 104.4MB                            2.5s\n",
      "Extracting   (1) ━━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━\u001b[0m      41 sra-tools                 11.9s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 12.1s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━ 104.4MB                            2.5s\n",
      "Extracting   (1) ━━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━\u001b[0m      41 sra-tools                 12.0s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 12.2s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━ 104.4MB                            2.5s\n",
      "Extracting   (1) ━━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━\u001b[0m      41 sra-tools                 12.1s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 12.3s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━ 104.4MB                            2.5s\n",
      "Extracting   (1) ━━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━\u001b[0m      41 sra-tools                 12.2s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 12.4s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━ 104.4MB                            2.5s\n",
      "Extracting   (1) ━━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━\u001b[0m      41 sra-tools                 12.3s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 12.5s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━ 104.4MB                            2.5s\n",
      "Extracting   (1) ━━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━\u001b[0m      41 sra-tools                 12.4s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 12.6s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━ 104.4MB                            2.5s\n",
      "Extracting   (1) ━━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━\u001b[0m      41 sra-tools                 12.5s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 12.7s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━ 104.4MB                            2.5s\n",
      "Extracting   (1) ━━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━\u001b[0m      41 sra-tools                 12.6s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 12.8s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━ 104.4MB                            2.5s\n",
      "Extracting   (1) ━━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━\u001b[0m      41 sra-tools                 12.7s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 12.9s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━ 104.4MB                            2.5s\n",
      "Extracting   (1) ━━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━\u001b[0m      41 sra-tools                 12.8s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 13.0s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━ 104.4MB                            2.5s\n",
      "Extracting   (1) ━━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━\u001b[0m      41 sra-tools                 12.9s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 13.1s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━ 104.4MB                            2.5s\n",
      "Extracting   (1) ━━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━\u001b[0m      41 sra-tools                 13.0s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 13.2s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━ 104.4MB                            2.5s\n",
      "Extracting   (1) ━━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━\u001b[0m      41 sra-tools                 13.1s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 13.3s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━ 104.4MB                            2.5s\n",
      "Extracting   (1) ━━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━\u001b[0m      41 sra-tools                 13.2s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 13.4s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━ 104.4MB                            2.5s\n",
      "Extracting   (1) ━━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━\u001b[0m      41 sra-tools                 13.3s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 13.5s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━ 104.4MB                            2.5s\n",
      "Extracting   (1) ━━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━\u001b[0m      41 sra-tools                 13.4s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 13.6s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━ 104.4MB                            2.5s\n",
      "Extracting   (1) ━━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━\u001b[0m      41 sra-tools                 13.5s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 13.7s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━ 104.4MB                            2.5s\n",
      "Extracting   (1) ━━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━\u001b[0m      41 sra-tools                 13.6s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 13.8s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━ 104.4MB                            2.5s\n",
      "Extracting   (1) ━━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━\u001b[0m      41 sra-tools                 13.7s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 13.9s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━ 104.4MB                            2.5s\n",
      "Extracting   (1) ━━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━\u001b[0m      41 sra-tools                 13.8s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 14.0s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━ 104.4MB                            2.5s\n",
      "Extracting   (1) ━━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━\u001b[0m      41 sra-tools                 13.9s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 14.1s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━ 104.4MB                            2.5s\n",
      "Extracting   (1) ━━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━\u001b[0m      41 sra-tools                 14.0s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 14.2s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━ 104.4MB                            2.5s\n",
      "Extracting   (1) ━━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━\u001b[0m      41 sra-tools                 14.1s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 14.3s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━ 104.4MB                            2.5s\n",
      "Extracting   (1) ━━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━\u001b[0m      41 sra-tools                 14.2s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 14.4s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━ 104.4MB                            2.5s\n",
      "Extracting   (1) ━━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━\u001b[0m      41 sra-tools                 14.3s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 14.5s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━ 104.4MB                            2.5s\n",
      "Extracting   (1) ━━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━\u001b[0m      41 sra-tools                 14.4s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 14.6s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━ 104.4MB                            2.5s\n",
      "Extracting   (1) ━━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━\u001b[0m      41 sra-tools                 14.5s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 14.7s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━ 104.4MB                            2.5s\n",
      "Extracting   (1) ━━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━\u001b[0m      41 sra-tools                 14.6s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 14.8s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━ 104.4MB                            2.5s\n",
      "Extracting   (1) ━━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━\u001b[0m      41 sra-tools                 14.7s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G\u001b[?25hLinking gffread-0.12.7-h077b44d_6\n",
      "Linking ncbi-vdb-3.3.0-h9948957_0\n",
      "Linking pigz-2.8-h421ea60_2\n",
      "Linking zlib-1.3.1-hb9d3cd8_2\n",
      "Linking curl-8.17.0-h4e3cde8_0\n",
      "Linking ossuuid-1.6.2-h5888daf_1001\n",
      "\u001b[33m\u001b[1mwarning  libmamba\u001b[m [ossuuid-1.6.2-h5888daf_1001] The following files were already present in the environment:\n",
      "    - lib/libuuid.a\n",
      "    - lib/libuuid.so\n",
      "    - lib/pkgconfig/uuid.pc\n",
      "Linking perl-capture-tiny-0.48-pl5321ha770c72_1\n",
      "Linking perl-test-warnings-0.031-pl5321ha770c72_0\n",
      "Linking perl-try-tiny-0.31-pl5321ha770c72_0\n",
      "Linking libunistring-0.9.10-h7f98852_0\n",
      "Linking perl-test-fatal-0.016-pl5321ha770c72_0\n",
      "Linking libidn2-2.3.8-hfac485b_1\n",
      "Linking wget-1.21.4-hda4d442_0\n",
      "Linking perl-ffi-checklib-0.28-pl5321hdfd78af_0\n",
      "Linking perl-file-which-1.24-pl5321hd8ed1ab_0\n",
      "Linking perl-path-tiny-0.124-pl5321hd8ed1ab_0\n",
      "Linking perl-xml-sax-base-1.09-pl5321hd8ed1ab_0\n",
      "Linking perl-constant-1.33-pl5321hd8ed1ab_0\n",
      "Linking perl-parent-0.243-pl5321hd8ed1ab_0\n",
      "Linking perl-exporter-5.74-pl5321hd8ed1ab_0\n",
      "Linking perl-extutils-makemaker-7.70-pl5321hd8ed1ab_0\n",
      "Linking perl-importer-0.026-pl5321hd8ed1ab_0\n",
      "Linking perl-scope-guard-0.21-pl5321hd8ed1ab_0\n",
      "Linking perl-xml-namespacesupport-1.12-pl5321hd8ed1ab_0\n",
      "Linking perl-file-path-2.18-pl5321hd8ed1ab_0\n",
      "Linking perl-carp-1.50-pl5321hd8ed1ab_0\n",
      "Linking perl-business-isbn-data-20210112.006-pl5321hd8ed1ab_0\n",
      "Linking perl-sub-info-0.002-pl5321hd8ed1ab_0\n",
      "Linking perl-file-temp-0.2304-pl5321hd8ed1ab_0\n",
      "Linking perl-business-isbn-3.007-pl5321hd8ed1ab_0\n",
      "Linking perl-xml-sax-1.02-pl5321hd8ed1ab_0\n",
      "Linking entrez-direct-24.0-he881be0_0\n",
      "Linking perl-term-table-0.028-pl5321hdfd78af_0\n",
      "Linking perl-test2-suite-0.000163-pl5321hdfd78af_0\n",
      "Linking perl-pathtools-3.75-pl5321hb9d3cd8_2\n",
      "Linking perl-uri-5.34-pl5321ha770c72_0\n",
      "Linking perl-file-chdir-0.1011-pl5321hd8ed1ab_0\n",
      "Linking perl-alien-build-2.84-pl5321h7b50bb2_1\n",
      "Linking perl-alien-libxml2-0.17-pl5321h577a1d6_1\n",
      "Linking perl-xml-libxml-2.0210-pl5321hf886d80_0\n",
      "Linking sra-tools-3.0.5-h9f5acd7_1\n",
      "No entry for '/LIBS/GUID' in ~/.ncbi/user-settings.mkfg; adding...\n",
      "\n",
      "Linking parallel-fastq-dump-0.6.7-pyhdfd78af_0\n",
      "\n",
      "Transaction finished\n",
      "\n"
     ]
    }
   ],
   "source": [
    "! mamba install -y -c conda-forge -c bioconda trimmomatic fastqc multiqc salmon entrez-direct gffread parallel-fastq-dump sra-tools=3.0.5 pigz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "prefetch : 3.0.5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "! prefetch --version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 2: Setup Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a set of directories to store the reads, reference sequence files, and output files. Notice that first we remove the `data` directory to clean up files from Tutorial_1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jupyter/rnaseq-myco-notebook\n"
     ]
    }
   ],
   "source": [
    "! cd $HOMEDIR\n",
    "! echo $PWD\n",
    "! rm -r data/\n",
    "! mkdir -p data\n",
    "! mkdir -p data/raw_fastq\n",
    "! mkdir -p data/trimmed\n",
    "! mkdir -p data/fastqc\n",
    "! mkdir -p data/aligned\n",
    "! mkdir -p data/reference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set number of cores depending on your VM size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CORES=4\n"
     ]
    }
   ],
   "source": [
    "numthreads=!nproc\n",
    "numthreadsint = int(numthreads[0])\n",
    "%env CORES = $numthreadsint\n",
    "#!echo ${CORES}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 3: Downloading relevant FASTQ files using SRA Tools\n",
    "\n",
    "Next we will need to download the relevant fastq files.\n",
    "\n",
    "Because these files can be large, the process of downloading and extracting fastq files can be quite lengthy.\n",
    "\n",
    "The sequence data for this tutorial comes from work by Cushman et al., <em><a href='https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8191103/'>Increased whiB7 expression and antibiotic resistance in Mycobacterium chelonae carrying two prophages</a><em>.\n",
    "\n",
    "We will be downloading the sample runs from this project using SRA tools, downloading from the NCBI's SRA (Sequence Run Archives).\n",
    "\n",
    "However, first we need to find the associated accession numbers in order to download.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 3.1: Finding run accession numbers.\n",
    "\n",
    "The SRA stores sequence data in terms of runs, (SRR stands for Sequence Read Run). To download runs, we will need the accession ID for each run we wish to download. \n",
    "\n",
    "The Cushman et al., project contains 12 runs. To make it easier, these are the run IDs associated with this project:\n",
    "\n",
    "+ SRR13349122\n",
    "+ SRR13349123\n",
    "+ SRR13349124\n",
    "+ SRR13349125\n",
    "+ SRR13349126\n",
    "+ SRR13349127\n",
    "+ SRR13349128\n",
    "+ SRR13349129\n",
    "+ SRR13349130\n",
    "+ SRR13349131\n",
    "+ SRR13349132\n",
    "+ SRR13349133\n",
    "\n",
    "\n",
    "In this case, all these runs belong to the SRP (Sequence Run Project): SRP300216.\n",
    "\n",
    "Sequence run experiments can be searched for using the SRA database on the NCBI website; and article-specific sample run information can be found in the supplementary section of that article.\n",
    "\n",
    "For instance, here, the the authors posted a link to the sequence data GSE (Gene Series number), <a href='https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE164210'>GSE164210</a>. This leads to the appropriate 'Gene Expression Omnibus' page where, among other useful files and information, the relevant SRA database link can be found. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can download this text file with the accession numbers and continue to STEP 3.2, or you can optionally use BigQuery to generate an accession list following the instructions outlined in [this notebook](https://github.com/STRIDES/NIHCloudLabGCP/blob/main/notebooks/SRADownload/SRA-Download.ipynb).\n",
    "### STEP 3.1.1: Download the accession list file with `gsutil`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying gs://nigms-sandbox/me-inbre-rnaseq-pipelinev2/accs.txt...\n",
      "/ [1 files][  144.0 B/  144.0 B]                                                \n",
      "Operation completed over 1 objects/144.0 B.                                      \n"
     ]
    }
   ],
   "source": [
    "! gsutil cp gs://nigms-sandbox/me-inbre-rnaseq-pipelinev2/accs.txt ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 3.1.2 (Optional): Generate the accession list file with BigQuery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the biquery api\n",
    "from google.cloud import bigquery"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now make sure you have enabled the BigQuery API. You just need to search for BigQuery, go to the BQ page and click `Enable`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client creating using default project: kinglab-maine-strides\n"
     ]
    }
   ],
   "source": [
    "# Designate the client for the API\n",
    "client = bigquery.Client(location=\"US\")\n",
    "print(\"Client creating using default project: {}\".format(client.project))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The table we are working with has the following Id:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_id = \"nih-sra-datastore.sra.metadata\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It has the following column names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['acc',\n",
       " 'assay_type',\n",
       " 'center_name',\n",
       " 'consent',\n",
       " 'experiment',\n",
       " 'sample_name',\n",
       " 'instrument',\n",
       " 'librarylayout',\n",
       " 'libraryselection',\n",
       " 'librarysource',\n",
       " 'platform',\n",
       " 'sample_acc',\n",
       " 'biosample',\n",
       " 'organism',\n",
       " 'sra_study',\n",
       " 'releasedate',\n",
       " 'bioproject',\n",
       " 'mbytes',\n",
       " 'loaddate',\n",
       " 'avgspotlen',\n",
       " 'mbases',\n",
       " 'insertsize',\n",
       " 'library_name',\n",
       " 'biosamplemodel_sam',\n",
       " 'collection_date_sam',\n",
       " 'geo_loc_name_country_calc',\n",
       " 'geo_loc_name_country_continent_calc',\n",
       " 'geo_loc_name_sam',\n",
       " 'ena_first_public_run',\n",
       " 'ena_last_update_run',\n",
       " 'sample_name_sam',\n",
       " 'datastore_filetype',\n",
       " 'datastore_provider',\n",
       " 'datastore_region',\n",
       " 'attributes',\n",
       " 'run_file_version',\n",
       " 'jattr']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_ref = client.get_table(table_id)\n",
    "column_names = [field.name for field in table_ref.schema]\n",
    "column_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first column (`acc`), is accession ID."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will query BigQuery using the species name and a range of accession numbers associated with this particular study. Feel free to play around with the query to generate different variations of accession numbers!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "#standardSQL\n",
    "SELECT acc\n",
    "FROM `nih-sra-datastore.sra.metadata`\n",
    "WHERE organism = 'Mycobacteroides chelonae'\n",
    "and acc LIKE '%SRR133491%'\n",
    "ORDER BY acc\n",
    "\"\"\"\n",
    "query_job = client.query(\n",
    "    query,\n",
    "    # Location must match that of the dataset(s) referenced in the query.\n",
    "    location=\"US\",\n",
    ")  # API request - starts the query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(('SRR13349122',), {'acc': 0}),\n",
       " Row(('SRR13349123',), {'acc': 0}),\n",
       " Row(('SRR13349124',), {'acc': 0}),\n",
       " Row(('SRR13349125',), {'acc': 0}),\n",
       " Row(('SRR13349126',), {'acc': 0}),\n",
       " Row(('SRR13349127',), {'acc': 0}),\n",
       " Row(('SRR13349128',), {'acc': 0}),\n",
       " Row(('SRR13349129',), {'acc': 0}),\n",
       " Row(('SRR13349130',), {'acc': 0}),\n",
       " Row(('SRR13349131',), {'acc': 0}),\n",
       " Row(('SRR13349132',), {'acc': 0}),\n",
       " Row(('SRR13349133',), {'acc': 0})]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result=list(query_job)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('accs2.txt', 'w') as f:\n",
    "    for acc in result:\n",
    "        f.write(acc[0]+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SRR13349122\n",
      "SRR13349123\n",
      "SRR13349124\n",
      "SRR13349125\n",
      "SRR13349126\n",
      "SRR13349127\n",
      "SRR13349128\n",
      "SRR13349129\n",
      "SRR13349130\n",
      "SRR13349131\n",
      "SRR13349132\n",
      "SRR13349133\n"
     ]
    }
   ],
   "source": [
    "cat accs2.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 3.2: Using the SRA-toolkit for a single sample.\n",
    "\n",
    "Now use the Sequence Run accession ID to download the sequence data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2026-01-05T18:12:58 prefetch.3.0.5: Current preference is set to retrieve SRA Normalized Format files with full base quality scores.\n",
      "2026-01-05T18:12:58 prefetch.3.0.5: 1) Downloading 'SRR13349124'...\n",
      "2026-01-05T18:12:58 prefetch.3.0.5: SRA Normalized Format file is being retrieved, if this is different from your preference, it may be due to current file availability.\n",
      "2026-01-05T18:12:58 prefetch.3.0.5:  Downloading via HTTPS...\n",
      "2026-01-05T18:13:18 prefetch.3.0.5:  HTTPS download succeed\n",
      "2026-01-05T18:13:20 prefetch.3.0.5:  'SRR13349124' is valid\n",
      "2026-01-05T18:13:20 prefetch.3.0.5: 1) 'SRR13349124' was downloaded successfully\n",
      "2026-01-05T18:13:20 prefetch.3.0.5: 'SRR13349124' has 0 dependencies\n"
     ]
    }
   ],
   "source": [
    "! prefetch SRR13349124 -O data/raw_fastq -f yes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the SRA archives sequence files in the SRA format. \n",
    "\n",
    "Typically genome workflows process data in the form of zipped or unzipped .fastq, or .fasta files\n",
    "\n",
    "So before we move on, we need to convert the files from .sra to .fastq using the fastq-dump tool.\n",
    "\n",
    "We will also compresss the fastq files to make them take less space, making them fastq.gz files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-05T18:13:20 fasterq-dump.3.0.5 err: name not found while resolving query within virtual file system module - failed to resolve accession 'data/raw_fastq/SRR13349122/SRR13349122.sra' - Cannot resolve accession ( 404 )\n",
      "fasterq-dump quit with error code 3\n",
      "2026-01-05T18:13:20 fasterq-dump.3.0.5 err: name not found while resolving query within virtual file system module - failed to resolve accession 'data/raw_fastq/SRR13349123/SRR13349123.sra' - Cannot resolve accession ( 404 )\n",
      "fasterq-dump quit with error code 3\n",
      "spots read      : 10,727,273\n",
      "reads read      : 21,454,546\n",
      "reads written   : 21,454,546\n",
      "2026-01-05T18:13:51 fasterq-dump.3.0.5 err: name not found while resolving query within virtual file system module - failed to resolve accession 'data/raw_fastq/SRR13349125/SRR13349125.sra' - Cannot resolve accession ( 404 )\n",
      "fasterq-dump quit with error code 3\n",
      "2026-01-05T18:13:51 fasterq-dump.3.0.5 err: name not found while resolving query within virtual file system module - failed to resolve accession 'data/raw_fastq/SRR13349126/SRR13349126.sra' - Cannot resolve accession ( 404 )\n",
      "fasterq-dump quit with error code 3\n",
      "2026-01-05T18:13:51 fasterq-dump.3.0.5 err: name not found while resolving query within virtual file system module - failed to resolve accession 'data/raw_fastq/SRR13349127/SRR13349127.sra' - Cannot resolve accession ( 404 )\n",
      "fasterq-dump quit with error code 3\n",
      "2026-01-05T18:13:51 fasterq-dump.3.0.5 err: name not found while resolving query within virtual file system module - failed to resolve accession 'data/raw_fastq/SRR13349128/SRR13349128.sra' - Cannot resolve accession ( 404 )\n",
      "fasterq-dump quit with error code 3\n",
      "2026-01-05T18:13:51 fasterq-dump.3.0.5 err: name not found while resolving query within virtual file system module - failed to resolve accession 'data/raw_fastq/SRR13349129/SRR13349129.sra' - Cannot resolve accession ( 404 )\n",
      "fasterq-dump quit with error code 3\n",
      "2026-01-05T18:13:51 fasterq-dump.3.0.5 err: name not found while resolving query within virtual file system module - failed to resolve accession 'data/raw_fastq/SRR13349130/SRR13349130.sra' - Cannot resolve accession ( 404 )\n",
      "fasterq-dump quit with error code 3\n",
      "2026-01-05T18:13:52 fasterq-dump.3.0.5 err: name not found while resolving query within virtual file system module - failed to resolve accession 'data/raw_fastq/SRR13349131/SRR13349131.sra' - Cannot resolve accession ( 404 )\n",
      "fasterq-dump quit with error code 3\n",
      "2026-01-05T18:13:52 fasterq-dump.3.0.5 err: name not found while resolving query within virtual file system module - failed to resolve accession 'data/raw_fastq/SRR13349132/SRR13349132.sra' - Cannot resolve accession ( 404 )\n",
      "fasterq-dump quit with error code 3\n",
      "2026-01-05T18:13:52 fasterq-dump.3.0.5 err: name not found while resolving query within virtual file system module - failed to resolve accession 'data/raw_fastq/SRR13349133/SRR13349133.sra' - Cannot resolve accession ( 404 )\n",
      "fasterq-dump quit with error code 3\n"
     ]
    }
   ],
   "source": [
    "! for x in `cat accs.txt`; do fasterq-dump -f -O data/raw_fastq -e $CORES -m 4G data/raw_fastq/$x/$x.sra; done\n",
    "# Note that you will get a result only for SRR13349124. Igonre error related to other accession IDs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 3.3 Downloading multiple files using the SRA-toolkit.\n",
    "\n",
    "One may, as in our case, wish to download multiple runs at once.\n",
    "\n",
    "To aid in this, SRA-tools supports batch downloading.\n",
    "\n",
    "We can download multiple SRA files using a single line of code by creating a list of the SRA IDs we wish to download, and inputting that into the prefetch command."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then feed that list into the sra-toolkit prefetch command. Note, it may take some time to download all the fastq files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2026-01-05T18:13:52 prefetch.3.0.5: Current preference is set to retrieve SRA Normalized Format files with full base quality scores.\n",
      "2026-01-05T18:13:52 prefetch.3.0.5: 1) Downloading 'SRR13349122'...\n",
      "2026-01-05T18:13:52 prefetch.3.0.5: SRA Normalized Format file is being retrieved, if this is different from your preference, it may be due to current file availability.\n",
      "2026-01-05T18:13:52 prefetch.3.0.5:  Downloading via HTTPS...\n",
      "2026-01-05T18:14:12 prefetch.3.0.5:  HTTPS download succeed\n",
      "2026-01-05T18:14:14 prefetch.3.0.5:  'SRR13349122' is valid\n",
      "2026-01-05T18:14:14 prefetch.3.0.5: 1) 'SRR13349122' was downloaded successfully\n",
      "2026-01-05T18:14:14 prefetch.3.0.5: 'SRR13349122' has 0 unresolved dependencies\n",
      "\n",
      "2026-01-05T18:14:14 prefetch.3.0.5: Current preference is set to retrieve SRA Normalized Format files with full base quality scores.\n",
      "2026-01-05T18:14:14 prefetch.3.0.5: 2) Downloading 'SRR13349123'...\n",
      "2026-01-05T18:14:14 prefetch.3.0.5: SRA Normalized Format file is being retrieved, if this is different from your preference, it may be due to current file availability.\n",
      "2026-01-05T18:14:14 prefetch.3.0.5:  Downloading via HTTPS...\n",
      "2026-01-05T18:14:32 prefetch.3.0.5:  HTTPS download succeed\n",
      "2026-01-05T18:14:33 prefetch.3.0.5:  'SRR13349123' is valid\n",
      "2026-01-05T18:14:33 prefetch.3.0.5: 2) 'SRR13349123' was downloaded successfully\n",
      "2026-01-05T18:14:33 prefetch.3.0.5: 'SRR13349123' has 0 unresolved dependencies\n",
      "\n",
      "2026-01-05T18:14:33 prefetch.3.0.5: Current preference is set to retrieve SRA Normalized Format files with full base quality scores.\n",
      "2026-01-05T18:14:33 prefetch.3.0.5: 3) 'SRR13349124' is found locally\n",
      "2026-01-05T18:14:33 prefetch.3.0.5: 'SRR13349124' has 0 unresolved dependencies\n",
      "\n",
      "2026-01-05T18:14:33 prefetch.3.0.5: Current preference is set to retrieve SRA Normalized Format files with full base quality scores.\n",
      "2026-01-05T18:14:33 prefetch.3.0.5: 4) Downloading 'SRR13349125'...\n",
      "2026-01-05T18:14:33 prefetch.3.0.5: SRA Normalized Format file is being retrieved, if this is different from your preference, it may be due to current file availability.\n",
      "2026-01-05T18:14:33 prefetch.3.0.5:  Downloading via HTTPS...\n",
      "2026-01-05T18:14:52 prefetch.3.0.5:  HTTPS download succeed\n",
      "2026-01-05T18:14:54 prefetch.3.0.5:  'SRR13349125' is valid\n",
      "2026-01-05T18:14:54 prefetch.3.0.5: 4) 'SRR13349125' was downloaded successfully\n",
      "2026-01-05T18:14:54 prefetch.3.0.5: 'SRR13349125' has 0 unresolved dependencies\n",
      "\n",
      "2026-01-05T18:14:54 prefetch.3.0.5: Current preference is set to retrieve SRA Normalized Format files with full base quality scores.\n",
      "2026-01-05T18:14:54 prefetch.3.0.5: 5) Downloading 'SRR13349126'...\n",
      "2026-01-05T18:14:54 prefetch.3.0.5: SRA Normalized Format file is being retrieved, if this is different from your preference, it may be due to current file availability.\n",
      "2026-01-05T18:14:54 prefetch.3.0.5:  Downloading via HTTPS...\n",
      "2026-01-05T18:15:16 prefetch.3.0.5:  HTTPS download succeed\n",
      "2026-01-05T18:15:17 prefetch.3.0.5:  'SRR13349126' is valid\n",
      "2026-01-05T18:15:17 prefetch.3.0.5: 5) 'SRR13349126' was downloaded successfully\n",
      "2026-01-05T18:15:17 prefetch.3.0.5: 'SRR13349126' has 0 unresolved dependencies\n",
      "\n",
      "2026-01-05T18:15:18 prefetch.3.0.5: Current preference is set to retrieve SRA Normalized Format files with full base quality scores.\n",
      "2026-01-05T18:15:18 prefetch.3.0.5: 6) Downloading 'SRR13349127'...\n",
      "2026-01-05T18:15:18 prefetch.3.0.5: SRA Normalized Format file is being retrieved, if this is different from your preference, it may be due to current file availability.\n",
      "2026-01-05T18:15:18 prefetch.3.0.5:  Downloading via HTTPS...\n",
      "2026-01-05T18:15:38 prefetch.3.0.5:  HTTPS download succeed\n",
      "2026-01-05T18:15:40 prefetch.3.0.5:  'SRR13349127' is valid\n",
      "2026-01-05T18:15:40 prefetch.3.0.5: 6) 'SRR13349127' was downloaded successfully\n",
      "2026-01-05T18:15:40 prefetch.3.0.5: 'SRR13349127' has 0 unresolved dependencies\n",
      "\n",
      "2026-01-05T18:15:40 prefetch.3.0.5: Current preference is set to retrieve SRA Normalized Format files with full base quality scores.\n",
      "2026-01-05T18:15:40 prefetch.3.0.5: 7) Downloading 'SRR13349128'...\n",
      "2026-01-05T18:15:40 prefetch.3.0.5: SRA Normalized Format file is being retrieved, if this is different from your preference, it may be due to current file availability.\n",
      "2026-01-05T18:15:40 prefetch.3.0.5:  Downloading via HTTPS...\n",
      "2026-01-05T18:16:02 prefetch.3.0.5:  HTTPS download succeed\n",
      "2026-01-05T18:16:05 prefetch.3.0.5:  'SRR13349128' is valid\n",
      "2026-01-05T18:16:05 prefetch.3.0.5: 7) 'SRR13349128' was downloaded successfully\n",
      "2026-01-05T18:16:05 prefetch.3.0.5: 'SRR13349128' has 0 unresolved dependencies\n",
      "\n",
      "2026-01-05T18:16:05 prefetch.3.0.5: Current preference is set to retrieve SRA Normalized Format files with full base quality scores.\n",
      "2026-01-05T18:16:05 prefetch.3.0.5: 8) Downloading 'SRR13349129'...\n",
      "2026-01-05T18:16:05 prefetch.3.0.5: SRA Normalized Format file is being retrieved, if this is different from your preference, it may be due to current file availability.\n",
      "2026-01-05T18:16:05 prefetch.3.0.5:  Downloading via HTTPS...\n",
      "2026-01-05T18:16:27 prefetch.3.0.5:  HTTPS download succeed\n",
      "2026-01-05T18:16:29 prefetch.3.0.5:  'SRR13349129' is valid\n",
      "2026-01-05T18:16:29 prefetch.3.0.5: 8) 'SRR13349129' was downloaded successfully\n",
      "2026-01-05T18:16:29 prefetch.3.0.5: 'SRR13349129' has 0 unresolved dependencies\n",
      "\n",
      "2026-01-05T18:16:29 prefetch.3.0.5: Current preference is set to retrieve SRA Normalized Format files with full base quality scores.\n",
      "2026-01-05T18:16:29 prefetch.3.0.5: 9) Downloading 'SRR13349130'...\n",
      "2026-01-05T18:16:29 prefetch.3.0.5: SRA Normalized Format file is being retrieved, if this is different from your preference, it may be due to current file availability.\n",
      "2026-01-05T18:16:29 prefetch.3.0.5:  Downloading via HTTPS...\n",
      "2026-01-05T18:16:47 prefetch.3.0.5:  HTTPS download succeed\n",
      "2026-01-05T18:16:48 prefetch.3.0.5:  'SRR13349130' is valid\n",
      "2026-01-05T18:16:48 prefetch.3.0.5: 9) 'SRR13349130' was downloaded successfully\n",
      "2026-01-05T18:16:48 prefetch.3.0.5: 'SRR13349130' has 0 unresolved dependencies\n",
      "\n",
      "2026-01-05T18:16:48 prefetch.3.0.5: Current preference is set to retrieve SRA Normalized Format files with full base quality scores.\n",
      "2026-01-05T18:16:48 prefetch.3.0.5: 10) Downloading 'SRR13349131'...\n",
      "2026-01-05T18:16:48 prefetch.3.0.5: SRA Normalized Format file is being retrieved, if this is different from your preference, it may be due to current file availability.\n",
      "2026-01-05T18:16:48 prefetch.3.0.5:  Downloading via HTTPS...\n",
      "2026-01-05T18:17:06 prefetch.3.0.5:  HTTPS download succeed\n",
      "2026-01-05T18:17:08 prefetch.3.0.5:  'SRR13349131' is valid\n",
      "2026-01-05T18:17:08 prefetch.3.0.5: 10) 'SRR13349131' was downloaded successfully\n",
      "2026-01-05T18:17:08 prefetch.3.0.5: 'SRR13349131' has 0 unresolved dependencies\n",
      "\n",
      "2026-01-05T18:17:08 prefetch.3.0.5: Current preference is set to retrieve SRA Normalized Format files with full base quality scores.\n",
      "2026-01-05T18:17:08 prefetch.3.0.5: 11) Downloading 'SRR13349132'...\n",
      "2026-01-05T18:17:08 prefetch.3.0.5: SRA Normalized Format file is being retrieved, if this is different from your preference, it may be due to current file availability.\n",
      "2026-01-05T18:17:08 prefetch.3.0.5:  Downloading via HTTPS...\n",
      "2026-01-05T18:17:27 prefetch.3.0.5:  HTTPS download succeed\n",
      "2026-01-05T18:17:29 prefetch.3.0.5:  'SRR13349132' is valid\n",
      "2026-01-05T18:17:29 prefetch.3.0.5: 11) 'SRR13349132' was downloaded successfully\n",
      "2026-01-05T18:17:29 prefetch.3.0.5: 'SRR13349132' has 0 unresolved dependencies\n",
      "\n",
      "2026-01-05T18:17:29 prefetch.3.0.5: Current preference is set to retrieve SRA Normalized Format files with full base quality scores.\n",
      "2026-01-05T18:17:29 prefetch.3.0.5: 12) Downloading 'SRR13349133'...\n",
      "2026-01-05T18:17:29 prefetch.3.0.5: SRA Normalized Format file is being retrieved, if this is different from your preference, it may be due to current file availability.\n",
      "2026-01-05T18:17:29 prefetch.3.0.5:  Downloading via HTTPS...\n",
      "2026-01-05T18:17:48 prefetch.3.0.5:  HTTPS download succeed\n",
      "2026-01-05T18:17:50 prefetch.3.0.5:  'SRR13349133' is valid\n",
      "2026-01-05T18:17:50 prefetch.3.0.5: 12) 'SRR13349133' was downloaded successfully\n",
      "2026-01-05T18:17:50 prefetch.3.0.5: 'SRR13349133' has 0 unresolved dependencies\n"
     ]
    }
   ],
   "source": [
    "! prefetch -O data/raw_fastq/ --option-file accs.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 3.3 Converting Multiple SRA files to Fastq\n",
    "\n",
    "We used fasterq-dump before to convert SRA files to fastq. However, fasterq-dump does not have native batch compatibility. As before, we will use a loop to convert each file in our list. In this case, we are going to convert to fastq.gz for downstream processing. This step should take about 30 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spots read      : 10,827,590\n",
      "reads read      : 21,655,180\n",
      "reads written   : 21,655,180\n",
      "spots read      : 11,165,256\n",
      "reads read      : 22,330,512\n",
      "reads written   : 22,330,512\n",
      "spots read      : 10,727,273\n",
      "reads read      : 21,454,546\n",
      "reads written   : 21,454,546\n",
      "spots read      : 10,992,686\n",
      "reads read      : 21,985,372\n",
      "reads written   : 21,985,372\n",
      "spots read      : 12,267,497\n",
      "reads read      : 24,534,994\n",
      "reads written   : 24,534,994\n",
      "spots read      : 12,563,032\n",
      "reads read      : 25,126,064\n",
      "reads written   : 25,126,064\n",
      "spots read      : 12,652,387\n",
      "reads read      : 25,304,774\n",
      "reads written   : 25,304,774\n",
      "spots read      : 12,961,793\n",
      "reads read      : 25,923,586\n",
      "reads written   : 25,923,586\n",
      "spots read      : 10,083,015\n",
      "reads read      : 20,166,030\n",
      "reads written   : 20,166,030\n",
      "spots read      : 10,491,160\n",
      "reads read      : 20,982,320\n",
      "reads written   : 20,982,320\n",
      "spots read      : 11,341,357\n",
      "reads read      : 22,682,714\n",
      "reads written   : 22,682,714\n",
      "spots read      : 11,603,881\n",
      "reads read      : 23,207,762\n",
      "reads written   : 23,207,762\n"
     ]
    }
   ],
   "source": [
    "! for x in `cat accs.txt`; do fasterq-dump -f -O data/raw_fastq -e $CORES -m 4G data/raw_fastq/$x/$x.sra; done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert to fastq.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "real\t20m53.257s\n",
      "user\t77m19.848s\n",
      "sys\t2m20.395s\n"
     ]
    }
   ],
   "source": [
    "! time pigz data/raw_fastq/*.fastq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 4: Copy reference transcriptome files that will be used by Salmon using E-Direct\n",
    "\n",
    "Salmon is a tool that aligns RNA-Seq reads to a transcriptome.\n",
    "\n",
    "So we will need a transcriptome reference file.\n",
    "\n",
    "To get one, we can search through the NCBI assembly database, find an assembly, and download transcriptome reference files from that assembly using FTP links.\n",
    "\n",
    "For instance, we will use the <a href='https://www.ncbi.nlm.nih.gov/assembly/GCF_001632805.1'>ASM163280v1</a> refseq assembly, found by searching through the NCBI assembly database. The FTP links can be accessed through the website in various ways, one way is to click the 'FTP directory for RefSeq assembly' link, found under 'Access the data', section.\n",
    "\n",
    "Alternatively, if one were inclined, one could take the less common route and perform this through the NCBI command line tool suite called 'Entrez Direct' (EDirect).\n",
    "\n",
    "This is an intricate and complicated set of tools, with many ways to do any one thing.\n",
    "\n",
    "Below is an example of using an eDirect search query with a refseq identifier to obtain the relevant FTP directory, and then using that to download desired reference files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  1436k 100  1436k   0     0 10849k     0  --:--:-- --:--:-- --:--:-- 10886k\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 426539 100 426539   0     0  1186k     0  --:--:-- --:--:-- --:--:--  1190k\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 231931 100 231931   0     0  2609k     0  --:--:-- --:--:-- --:--:--  2633k\n"
     ]
    }
   ],
   "source": [
    "#parse for the ftp link and download the genome reference fasta file\n",
    "\n",
    "! esearch -db assembly -query GCF_001632805.1 | efetch -format docsum \\\n",
    "| xtract -pattern DocumentSummary -element FtpPath_RefSeq \\\n",
    "| awk -F\"/\" '{print \"curl -o data/reference/\"$NF\"_genomic.fna.gz \" $0\"/\"$NF\"_genomic.fna.gz\"}' \\\n",
    "| bash\n",
    "\n",
    "#parse for the ftp link and download the gtf reference fasta file\n",
    "\n",
    "! esearch -db assembly -query GCF_001632805.1 | efetch -format docsum \\\n",
    "| xtract -pattern DocumentSummary -element FtpPath_RefSeq \\\n",
    "| awk -F\"/\" '{print \"curl -o data/reference/\"$NF\"_genomic.gff.gz \" $0\"/\"$NF\"_genomic.gff.gz\"}' \\\n",
    "| bash\n",
    "\n",
    "# parse for the ftp link and download the feature-table reference file \n",
    "# (for later use for merging readcounts with gene names in R code).\n",
    "\n",
    "! esearch -db assembly -query GCF_001632805.1 | efetch -format docsum \\\n",
    "| xtract -pattern DocumentSummary -element FtpPath_RefSeq \\\n",
    "| awk -F\"/\" '{print \"curl -o data/reference/\"$NF\"_feature_table.txt.gz \" $0\"/\"$NF\"_feature_table.txt.gz\"}' \\\n",
    "| bash\n",
    "\n",
    "\n",
    "#unzip the compresseed fasta files\n",
    "\n",
    "! gzip -d data/reference/*.gz --force"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we can use a tool called gffread to create a transcriptome reference file using the gtf and genome files we downloaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FASTA index file data/reference/GCF_001632805.1_ASM163280v1_genomic.fna.fai created.\n"
     ]
    }
   ],
   "source": [
    "! gffread -w data/reference/GCF_001632805.1_transcriptome_reference.fa -g data/reference/GCF_001632805.1_ASM163280v1_genomic.fna data/reference/GCF_001632805.1_ASM163280v1_genomic.gff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is also recommended to include the full genome at the end of the transcriptome reference file, for the purpose of performing a 'decoy-aware' mapping, more information about which can be found in the Salmon documentation.\n",
    "\n",
    "To alert the tool to the presence of this, we will also create a 'decoy file', which salmon needs pointed towards the full genome sequence in our transcriptome reference file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "! cat data/reference/GCF_001632805.1_transcriptome_reference.fa <(echo) data/reference/GCF_001632805.1_ASM163280v1_genomic.fna > data/reference/GCF_001632805.1_transcriptome_reference_w_decoy.fa\n",
    "! echo \"NZ_CP007220.1\" > data/reference/decoys.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 5: Copy data file for Trimmomatic\n",
    "\n",
    "One of trimmomatics functions is to trim sequence machine specific adapter sequences. These are usually within the trimmomatic installation directory in a folder called adapters.\n",
    "\n",
    "Directories of packages within mamba installations can be confusing, so in the case of using mamba with trimmomatic, it may be easier to simply download or create a file with the relevant adapter sequencecs and store it in an easy to find directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying gs://nigms-sandbox/me-inbre-rnaseq-pipelinev2/config/TruSeq3-PE.fa...\n",
      "/ [1/1 files][   95.0 B/   95.0 B] 100% Done                                    \n",
      "Operation completed over 1 objects/95.0 B.                                       \n",
      ">PrefixPE/1\n",
      "TACACTCTTTCCCTACACGACGCTCTTCCGATCT\n",
      ">PrefixPE/2\n",
      "GTGACTGGAGTTCAGACGTGTGCTCTTCCGATCT\n",
      "\n"
     ]
    }
   ],
   "source": [
    "! gsutil -m cp -r gs://nigms-sandbox/me-inbre-rnaseq-pipelinev2/config/TruSeq3-PE.fa .\n",
    "! head TruSeq3-PE.fa "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 6: Run Trimmomatic\n",
    "Trimmomatic will trim off any adapter sequences or low quality sequence it detects in the FASTQ files.\n",
    "\n",
    "Using piping and our original list, it is possible to queue up a batch run of trimmomatic for all our files, note that this is a different way to run a loop compared with what we did before.\n",
    "\n",
    "The below code may take approximately 35 minutes to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TrimmomaticPE: Started with arguments:\n",
      " -threads 4 data/raw_fastq/SRR13349122_1.fastq.gz data/raw_fastq/SRR13349122_2.fastq.gz data/trimmed/SRR13349122_1_trimmed.fastq.gz data/trimmed/SRR13349122_1_trimmed_unpaired.fastq.gz data/trimmed/SRR13349122_2_trimmed.fastq.gz data/trimmed/SRR13349122_2_trimmed_unpaired.fastq.gz ILLUMINACLIP:TruSeq3-PE.fa:2:30:10:2:keepBothReads LEADING:3 TRAILING:3 MINLEN:36\n",
      "ILLUMINACLIP: Using adapter file from Trimmomatic installation folder: /opt/conda/share/trimmomatic-0.40-0/adapters/TruSeq3-PE.fa\n",
      "Using PrefixPair: 'TACACTCTTTCCCTACACGACGCTCTTCCGATCT' and 'GTGACTGGAGTTCAGACGTGTGCTCTTCCGATCT'\n",
      "ILLUMINACLIP: Using 1 prefix pairs, 0 forward/reverse sequences, 0 forward only sequences, 0 reverse only sequences\n",
      "Quality encoding detected as phred33\n",
      "Input Read Pairs: 10827590 Both Surviving: 10810267 (99.84%) Forward Only Surviving: 17297 (0.16%) Reverse Only Surviving: 0 (0.00%) Dropped: 26 (0.00%)\n",
      "TrimmomaticPE: Completed successfully\n",
      "TrimmomaticPE: Started with arguments:\n",
      " -threads 4 data/raw_fastq/SRR13349123_1.fastq.gz data/raw_fastq/SRR13349123_2.fastq.gz data/trimmed/SRR13349123_1_trimmed.fastq.gz data/trimmed/SRR13349123_1_trimmed_unpaired.fastq.gz data/trimmed/SRR13349123_2_trimmed.fastq.gz data/trimmed/SRR13349123_2_trimmed_unpaired.fastq.gz ILLUMINACLIP:TruSeq3-PE.fa:2:30:10:2:keepBothReads LEADING:3 TRAILING:3 MINLEN:36\n",
      "ILLUMINACLIP: Using adapter file from Trimmomatic installation folder: /opt/conda/share/trimmomatic-0.40-0/adapters/TruSeq3-PE.fa\n",
      "Using PrefixPair: 'TACACTCTTTCCCTACACGACGCTCTTCCGATCT' and 'GTGACTGGAGTTCAGACGTGTGCTCTTCCGATCT'\n",
      "ILLUMINACLIP: Using 1 prefix pairs, 0 forward/reverse sequences, 0 forward only sequences, 0 reverse only sequences\n",
      "Quality encoding detected as phred33\n",
      "Input Read Pairs: 11165256 Both Surviving: 11096258 (99.38%) Forward Only Surviving: 68966 (0.62%) Reverse Only Surviving: 0 (0.00%) Dropped: 32 (0.00%)\n",
      "TrimmomaticPE: Completed successfully\n",
      "TrimmomaticPE: Started with arguments:\n",
      " -threads 4 data/raw_fastq/SRR13349124_1.fastq.gz data/raw_fastq/SRR13349124_2.fastq.gz data/trimmed/SRR13349124_1_trimmed.fastq.gz data/trimmed/SRR13349124_1_trimmed_unpaired.fastq.gz data/trimmed/SRR13349124_2_trimmed.fastq.gz data/trimmed/SRR13349124_2_trimmed_unpaired.fastq.gz ILLUMINACLIP:TruSeq3-PE.fa:2:30:10:2:keepBothReads LEADING:3 TRAILING:3 MINLEN:36\n",
      "ILLUMINACLIP: Using adapter file from Trimmomatic installation folder: /opt/conda/share/trimmomatic-0.40-0/adapters/TruSeq3-PE.fa\n",
      "Using PrefixPair: 'TACACTCTTTCCCTACACGACGCTCTTCCGATCT' and 'GTGACTGGAGTTCAGACGTGTGCTCTTCCGATCT'\n",
      "ILLUMINACLIP: Using 1 prefix pairs, 0 forward/reverse sequences, 0 forward only sequences, 0 reverse only sequences\n",
      "Quality encoding detected as phred33\n",
      "Input Read Pairs: 10727273 Both Surviving: 10710165 (99.84%) Forward Only Surviving: 17076 (0.16%) Reverse Only Surviving: 0 (0.00%) Dropped: 32 (0.00%)\n",
      "TrimmomaticPE: Completed successfully\n",
      "TrimmomaticPE: Started with arguments:\n",
      " -threads 4 data/raw_fastq/SRR13349125_1.fastq.gz data/raw_fastq/SRR13349125_2.fastq.gz data/trimmed/SRR13349125_1_trimmed.fastq.gz data/trimmed/SRR13349125_1_trimmed_unpaired.fastq.gz data/trimmed/SRR13349125_2_trimmed.fastq.gz data/trimmed/SRR13349125_2_trimmed_unpaired.fastq.gz ILLUMINACLIP:TruSeq3-PE.fa:2:30:10:2:keepBothReads LEADING:3 TRAILING:3 MINLEN:36\n",
      "ILLUMINACLIP: Using adapter file from Trimmomatic installation folder: /opt/conda/share/trimmomatic-0.40-0/adapters/TruSeq3-PE.fa\n",
      "Using PrefixPair: 'TACACTCTTTCCCTACACGACGCTCTTCCGATCT' and 'GTGACTGGAGTTCAGACGTGTGCTCTTCCGATCT'\n",
      "ILLUMINACLIP: Using 1 prefix pairs, 0 forward/reverse sequences, 0 forward only sequences, 0 reverse only sequences\n",
      "Quality encoding detected as phred33\n",
      "Input Read Pairs: 10992686 Both Surviving: 10924466 (99.38%) Forward Only Surviving: 68182 (0.62%) Reverse Only Surviving: 0 (0.00%) Dropped: 38 (0.00%)\n",
      "TrimmomaticPE: Completed successfully\n",
      "TrimmomaticPE: Started with arguments:\n",
      " -threads 4 data/raw_fastq/SRR13349126_1.fastq.gz data/raw_fastq/SRR13349126_2.fastq.gz data/trimmed/SRR13349126_1_trimmed.fastq.gz data/trimmed/SRR13349126_1_trimmed_unpaired.fastq.gz data/trimmed/SRR13349126_2_trimmed.fastq.gz data/trimmed/SRR13349126_2_trimmed_unpaired.fastq.gz ILLUMINACLIP:TruSeq3-PE.fa:2:30:10:2:keepBothReads LEADING:3 TRAILING:3 MINLEN:36\n",
      "ILLUMINACLIP: Using adapter file from Trimmomatic installation folder: /opt/conda/share/trimmomatic-0.40-0/adapters/TruSeq3-PE.fa\n",
      "Using PrefixPair: 'TACACTCTTTCCCTACACGACGCTCTTCCGATCT' and 'GTGACTGGAGTTCAGACGTGTGCTCTTCCGATCT'\n",
      "ILLUMINACLIP: Using 1 prefix pairs, 0 forward/reverse sequences, 0 forward only sequences, 0 reverse only sequences\n",
      "Quality encoding detected as phred33\n",
      "Input Read Pairs: 12267497 Both Surviving: 12248005 (99.84%) Forward Only Surviving: 19411 (0.16%) Reverse Only Surviving: 0 (0.00%) Dropped: 81 (0.00%)\n",
      "TrimmomaticPE: Completed successfully\n",
      "TrimmomaticPE: Started with arguments:\n",
      " -threads 4 data/raw_fastq/SRR13349127_1.fastq.gz data/raw_fastq/SRR13349127_2.fastq.gz data/trimmed/SRR13349127_1_trimmed.fastq.gz data/trimmed/SRR13349127_1_trimmed_unpaired.fastq.gz data/trimmed/SRR13349127_2_trimmed.fastq.gz data/trimmed/SRR13349127_2_trimmed_unpaired.fastq.gz ILLUMINACLIP:TruSeq3-PE.fa:2:30:10:2:keepBothReads LEADING:3 TRAILING:3 MINLEN:36\n",
      "ILLUMINACLIP: Using adapter file from Trimmomatic installation folder: /opt/conda/share/trimmomatic-0.40-0/adapters/TruSeq3-PE.fa\n",
      "Using PrefixPair: 'TACACTCTTTCCCTACACGACGCTCTTCCGATCT' and 'GTGACTGGAGTTCAGACGTGTGCTCTTCCGATCT'\n",
      "ILLUMINACLIP: Using 1 prefix pairs, 0 forward/reverse sequences, 0 forward only sequences, 0 reverse only sequences\n",
      "Quality encoding detected as phred33\n",
      "Input Read Pairs: 12563032 Both Surviving: 12485561 (99.38%) Forward Only Surviving: 77386 (0.62%) Reverse Only Surviving: 0 (0.00%) Dropped: 85 (0.00%)\n",
      "TrimmomaticPE: Completed successfully\n",
      "TrimmomaticPE: Started with arguments:\n",
      " -threads 4 data/raw_fastq/SRR13349128_1.fastq.gz data/raw_fastq/SRR13349128_2.fastq.gz data/trimmed/SRR13349128_1_trimmed.fastq.gz data/trimmed/SRR13349128_1_trimmed_unpaired.fastq.gz data/trimmed/SRR13349128_2_trimmed.fastq.gz data/trimmed/SRR13349128_2_trimmed_unpaired.fastq.gz ILLUMINACLIP:TruSeq3-PE.fa:2:30:10:2:keepBothReads LEADING:3 TRAILING:3 MINLEN:36\n",
      "ILLUMINACLIP: Using adapter file from Trimmomatic installation folder: /opt/conda/share/trimmomatic-0.40-0/adapters/TruSeq3-PE.fa\n",
      "Using PrefixPair: 'TACACTCTTTCCCTACACGACGCTCTTCCGATCT' and 'GTGACTGGAGTTCAGACGTGTGCTCTTCCGATCT'\n",
      "ILLUMINACLIP: Using 1 prefix pairs, 0 forward/reverse sequences, 0 forward only sequences, 0 reverse only sequences\n",
      "Quality encoding detected as phred33\n",
      "Input Read Pairs: 12652387 Both Surviving: 12631972 (99.84%) Forward Only Surviving: 20327 (0.16%) Reverse Only Surviving: 0 (0.00%) Dropped: 88 (0.00%)\n",
      "TrimmomaticPE: Completed successfully\n",
      "TrimmomaticPE: Started with arguments:\n",
      " -threads 4 data/raw_fastq/SRR13349129_1.fastq.gz data/raw_fastq/SRR13349129_2.fastq.gz data/trimmed/SRR13349129_1_trimmed.fastq.gz data/trimmed/SRR13349129_1_trimmed_unpaired.fastq.gz data/trimmed/SRR13349129_2_trimmed.fastq.gz data/trimmed/SRR13349129_2_trimmed_unpaired.fastq.gz ILLUMINACLIP:TruSeq3-PE.fa:2:30:10:2:keepBothReads LEADING:3 TRAILING:3 MINLEN:36\n",
      "ILLUMINACLIP: Using adapter file from Trimmomatic installation folder: /opt/conda/share/trimmomatic-0.40-0/adapters/TruSeq3-PE.fa\n",
      "Using PrefixPair: 'TACACTCTTTCCCTACACGACGCTCTTCCGATCT' and 'GTGACTGGAGTTCAGACGTGTGCTCTTCCGATCT'\n",
      "ILLUMINACLIP: Using 1 prefix pairs, 0 forward/reverse sequences, 0 forward only sequences, 0 reverse only sequences\n",
      "Quality encoding detected as phred33\n",
      "Input Read Pairs: 12961793 Both Surviving: 12881935 (99.38%) Forward Only Surviving: 79783 (0.62%) Reverse Only Surviving: 0 (0.00%) Dropped: 75 (0.00%)\n",
      "TrimmomaticPE: Completed successfully\n",
      "TrimmomaticPE: Started with arguments:\n",
      " -threads 4 data/raw_fastq/SRR13349130_1.fastq.gz data/raw_fastq/SRR13349130_2.fastq.gz data/trimmed/SRR13349130_1_trimmed.fastq.gz data/trimmed/SRR13349130_1_trimmed_unpaired.fastq.gz data/trimmed/SRR13349130_2_trimmed.fastq.gz data/trimmed/SRR13349130_2_trimmed_unpaired.fastq.gz ILLUMINACLIP:TruSeq3-PE.fa:2:30:10:2:keepBothReads LEADING:3 TRAILING:3 MINLEN:36\n",
      "ILLUMINACLIP: Using adapter file from Trimmomatic installation folder: /opt/conda/share/trimmomatic-0.40-0/adapters/TruSeq3-PE.fa\n",
      "Using PrefixPair: 'TACACTCTTTCCCTACACGACGCTCTTCCGATCT' and 'GTGACTGGAGTTCAGACGTGTGCTCTTCCGATCT'\n",
      "ILLUMINACLIP: Using 1 prefix pairs, 0 forward/reverse sequences, 0 forward only sequences, 0 reverse only sequences\n",
      "Quality encoding detected as phred33\n",
      "Input Read Pairs: 10083015 Both Surviving: 10067073 (99.84%) Forward Only Surviving: 15920 (0.16%) Reverse Only Surviving: 0 (0.00%) Dropped: 22 (0.00%)\n",
      "TrimmomaticPE: Completed successfully\n",
      "TrimmomaticPE: Started with arguments:\n",
      " -threads 4 data/raw_fastq/SRR13349131_1.fastq.gz data/raw_fastq/SRR13349131_2.fastq.gz data/trimmed/SRR13349131_1_trimmed.fastq.gz data/trimmed/SRR13349131_1_trimmed_unpaired.fastq.gz data/trimmed/SRR13349131_2_trimmed.fastq.gz data/trimmed/SRR13349131_2_trimmed_unpaired.fastq.gz ILLUMINACLIP:TruSeq3-PE.fa:2:30:10:2:keepBothReads LEADING:3 TRAILING:3 MINLEN:36\n",
      "ILLUMINACLIP: Using adapter file from Trimmomatic installation folder: /opt/conda/share/trimmomatic-0.40-0/adapters/TruSeq3-PE.fa\n",
      "Using PrefixPair: 'TACACTCTTTCCCTACACGACGCTCTTCCGATCT' and 'GTGACTGGAGTTCAGACGTGTGCTCTTCCGATCT'\n",
      "ILLUMINACLIP: Using 1 prefix pairs, 0 forward/reverse sequences, 0 forward only sequences, 0 reverse only sequences\n",
      "Quality encoding detected as phred33\n",
      "Input Read Pairs: 10491160 Both Surviving: 10427189 (99.39%) Forward Only Surviving: 63929 (0.61%) Reverse Only Surviving: 0 (0.00%) Dropped: 42 (0.00%)\n",
      "TrimmomaticPE: Completed successfully\n",
      "TrimmomaticPE: Started with arguments:\n",
      " -threads 4 data/raw_fastq/SRR13349132_1.fastq.gz data/raw_fastq/SRR13349132_2.fastq.gz data/trimmed/SRR13349132_1_trimmed.fastq.gz data/trimmed/SRR13349132_1_trimmed_unpaired.fastq.gz data/trimmed/SRR13349132_2_trimmed.fastq.gz data/trimmed/SRR13349132_2_trimmed_unpaired.fastq.gz ILLUMINACLIP:TruSeq3-PE.fa:2:30:10:2:keepBothReads LEADING:3 TRAILING:3 MINLEN:36\n",
      "ILLUMINACLIP: Using adapter file from Trimmomatic installation folder: /opt/conda/share/trimmomatic-0.40-0/adapters/TruSeq3-PE.fa\n",
      "Using PrefixPair: 'TACACTCTTTCCCTACACGACGCTCTTCCGATCT' and 'GTGACTGGAGTTCAGACGTGTGCTCTTCCGATCT'\n",
      "ILLUMINACLIP: Using 1 prefix pairs, 0 forward/reverse sequences, 0 forward only sequences, 0 reverse only sequences\n",
      "Quality encoding detected as phred33\n",
      "Input Read Pairs: 11603881 Both Surviving: 11531393 (99.38%) Forward Only Surviving: 72435 (0.62%) Reverse Only Surviving: 0 (0.00%) Dropped: 53 (0.00%)\n",
      "TrimmomaticPE: Completed successfully\n"
     ]
    }
   ],
   "source": [
    "! cat accs.txt | xargs -I {} trimmomatic PE -threads $CORES 'data/raw_fastq/{}_1.fastq.gz' 'data/raw_fastq/{}_2.fastq.gz' 'data/trimmed/{}_1_trimmed.fastq.gz' 'data/trimmed/{}_1_trimmed_unpaired.fastq.gz' 'data/trimmed/{}_2_trimmed.fastq.gz' 'data/trimmed/{}_2_trimmed_unpaired.fastq.gz' ILLUMINACLIP:TruSeq3-PE.fa:2:30:10:2:keepBothReads LEADING:3 TRAILING:3 MINLEN:36"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 7: Run FastQC\n",
    "FastQC is an invaluable tool that allows you to evaluate whether there are problems with a set of reads. For example, it will provide a report of whether there is any bias in the sequence composition of the reads.\n",
    "\n",
    "If you notice the results of the trimming, you may have noted the sequences in the reverse reads were few, and largely unpaired. This may be an artifact from how the original sequencing process. This is okay, we can proceed from here simply using the forward reads.\n",
    "\n",
    "The below code may take around 10 minutes to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "application/gzip\n",
      "Started analysis of SRR13349122_1_trimmed.fastq.gz\n",
      "Approx 5% complete for SRR13349122_1_trimmed.fastq.gz\n",
      "Approx 10% complete for SRR13349122_1_trimmed.fastq.gz\n",
      "Approx 15% complete for SRR13349122_1_trimmed.fastq.gz\n",
      "Approx 20% complete for SRR13349122_1_trimmed.fastq.gz\n",
      "Approx 25% complete for SRR13349122_1_trimmed.fastq.gz\n",
      "Approx 30% complete for SRR13349122_1_trimmed.fastq.gz\n",
      "Approx 35% complete for SRR13349122_1_trimmed.fastq.gz\n",
      "Approx 40% complete for SRR13349122_1_trimmed.fastq.gz\n",
      "Approx 45% complete for SRR13349122_1_trimmed.fastq.gz\n",
      "Approx 50% complete for SRR13349122_1_trimmed.fastq.gz\n",
      "Approx 55% complete for SRR13349122_1_trimmed.fastq.gz\n",
      "Approx 60% complete for SRR13349122_1_trimmed.fastq.gz\n",
      "Approx 65% complete for SRR13349122_1_trimmed.fastq.gz\n",
      "Approx 70% complete for SRR13349122_1_trimmed.fastq.gz\n",
      "Approx 75% complete for SRR13349122_1_trimmed.fastq.gz\n",
      "Approx 80% complete for SRR13349122_1_trimmed.fastq.gz\n",
      "Approx 85% complete for SRR13349122_1_trimmed.fastq.gz\n",
      "Approx 90% complete for SRR13349122_1_trimmed.fastq.gz\n",
      "Approx 95% complete for SRR13349122_1_trimmed.fastq.gz\n",
      "Analysis complete for SRR13349122_1_trimmed.fastq.gz\n",
      "application/gzip\n",
      "Started analysis of SRR13349123_1_trimmed.fastq.gz\n",
      "Approx 5% complete for SRR13349123_1_trimmed.fastq.gz\n",
      "Approx 10% complete for SRR13349123_1_trimmed.fastq.gz\n",
      "Approx 15% complete for SRR13349123_1_trimmed.fastq.gz\n",
      "Approx 20% complete for SRR13349123_1_trimmed.fastq.gz\n",
      "Approx 25% complete for SRR13349123_1_trimmed.fastq.gz\n",
      "Approx 30% complete for SRR13349123_1_trimmed.fastq.gz\n",
      "Approx 35% complete for SRR13349123_1_trimmed.fastq.gz\n",
      "Approx 40% complete for SRR13349123_1_trimmed.fastq.gz\n",
      "Approx 45% complete for SRR13349123_1_trimmed.fastq.gz\n",
      "Approx 50% complete for SRR13349123_1_trimmed.fastq.gz\n",
      "Approx 55% complete for SRR13349123_1_trimmed.fastq.gz\n",
      "Approx 60% complete for SRR13349123_1_trimmed.fastq.gz\n",
      "Approx 65% complete for SRR13349123_1_trimmed.fastq.gz\n",
      "Approx 70% complete for SRR13349123_1_trimmed.fastq.gz\n",
      "Approx 75% complete for SRR13349123_1_trimmed.fastq.gz\n",
      "Approx 80% complete for SRR13349123_1_trimmed.fastq.gz\n",
      "Approx 85% complete for SRR13349123_1_trimmed.fastq.gz\n",
      "Approx 90% complete for SRR13349123_1_trimmed.fastq.gz\n",
      "Approx 95% complete for SRR13349123_1_trimmed.fastq.gz\n",
      "Analysis complete for SRR13349123_1_trimmed.fastq.gz\n",
      "application/gzip\n",
      "Started analysis of SRR13349124_1_trimmed.fastq.gz\n",
      "Approx 5% complete for SRR13349124_1_trimmed.fastq.gz\n",
      "Approx 10% complete for SRR13349124_1_trimmed.fastq.gz\n",
      "Approx 15% complete for SRR13349124_1_trimmed.fastq.gz\n",
      "Approx 20% complete for SRR13349124_1_trimmed.fastq.gz\n",
      "Approx 25% complete for SRR13349124_1_trimmed.fastq.gz\n",
      "Approx 30% complete for SRR13349124_1_trimmed.fastq.gz\n",
      "Approx 35% complete for SRR13349124_1_trimmed.fastq.gz\n",
      "Approx 40% complete for SRR13349124_1_trimmed.fastq.gz\n",
      "Approx 45% complete for SRR13349124_1_trimmed.fastq.gz\n",
      "Approx 50% complete for SRR13349124_1_trimmed.fastq.gz\n",
      "Approx 55% complete for SRR13349124_1_trimmed.fastq.gz\n",
      "Approx 60% complete for SRR13349124_1_trimmed.fastq.gz\n",
      "Approx 65% complete for SRR13349124_1_trimmed.fastq.gz\n",
      "Approx 70% complete for SRR13349124_1_trimmed.fastq.gz\n",
      "Approx 75% complete for SRR13349124_1_trimmed.fastq.gz\n",
      "Approx 80% complete for SRR13349124_1_trimmed.fastq.gz\n",
      "Approx 85% complete for SRR13349124_1_trimmed.fastq.gz\n",
      "Approx 90% complete for SRR13349124_1_trimmed.fastq.gz\n",
      "Approx 95% complete for SRR13349124_1_trimmed.fastq.gz\n",
      "Analysis complete for SRR13349124_1_trimmed.fastq.gz\n",
      "application/gzip\n",
      "Started analysis of SRR13349125_1_trimmed.fastq.gz\n",
      "Approx 5% complete for SRR13349125_1_trimmed.fastq.gz\n",
      "Approx 10% complete for SRR13349125_1_trimmed.fastq.gz\n",
      "Approx 15% complete for SRR13349125_1_trimmed.fastq.gz\n",
      "Approx 20% complete for SRR13349125_1_trimmed.fastq.gz\n",
      "Approx 25% complete for SRR13349125_1_trimmed.fastq.gz\n",
      "Approx 30% complete for SRR13349125_1_trimmed.fastq.gz\n",
      "Approx 35% complete for SRR13349125_1_trimmed.fastq.gz\n",
      "Approx 40% complete for SRR13349125_1_trimmed.fastq.gz\n",
      "Approx 45% complete for SRR13349125_1_trimmed.fastq.gz\n",
      "Approx 50% complete for SRR13349125_1_trimmed.fastq.gz\n",
      "Approx 55% complete for SRR13349125_1_trimmed.fastq.gz\n",
      "Approx 60% complete for SRR13349125_1_trimmed.fastq.gz\n",
      "Approx 65% complete for SRR13349125_1_trimmed.fastq.gz\n",
      "Approx 70% complete for SRR13349125_1_trimmed.fastq.gz\n",
      "Approx 75% complete for SRR13349125_1_trimmed.fastq.gz\n",
      "Approx 80% complete for SRR13349125_1_trimmed.fastq.gz\n",
      "Approx 85% complete for SRR13349125_1_trimmed.fastq.gz\n",
      "Approx 90% complete for SRR13349125_1_trimmed.fastq.gz\n",
      "Approx 95% complete for SRR13349125_1_trimmed.fastq.gz\n",
      "Analysis complete for SRR13349125_1_trimmed.fastq.gz\n",
      "application/gzip\n",
      "Started analysis of SRR13349126_1_trimmed.fastq.gz\n",
      "Approx 5% complete for SRR13349126_1_trimmed.fastq.gz\n",
      "Approx 10% complete for SRR13349126_1_trimmed.fastq.gz\n",
      "Approx 15% complete for SRR13349126_1_trimmed.fastq.gz\n",
      "Approx 20% complete for SRR13349126_1_trimmed.fastq.gz\n",
      "Approx 25% complete for SRR13349126_1_trimmed.fastq.gz\n",
      "Approx 30% complete for SRR13349126_1_trimmed.fastq.gz\n",
      "Approx 35% complete for SRR13349126_1_trimmed.fastq.gz\n",
      "Approx 40% complete for SRR13349126_1_trimmed.fastq.gz\n",
      "Approx 45% complete for SRR13349126_1_trimmed.fastq.gz\n",
      "Approx 50% complete for SRR13349126_1_trimmed.fastq.gz\n",
      "Approx 55% complete for SRR13349126_1_trimmed.fastq.gz\n",
      "Approx 60% complete for SRR13349126_1_trimmed.fastq.gz\n",
      "Approx 65% complete for SRR13349126_1_trimmed.fastq.gz\n",
      "Approx 70% complete for SRR13349126_1_trimmed.fastq.gz\n",
      "Approx 75% complete for SRR13349126_1_trimmed.fastq.gz\n",
      "Approx 80% complete for SRR13349126_1_trimmed.fastq.gz\n",
      "Approx 85% complete for SRR13349126_1_trimmed.fastq.gz\n",
      "Approx 90% complete for SRR13349126_1_trimmed.fastq.gz\n",
      "Approx 95% complete for SRR13349126_1_trimmed.fastq.gz\n",
      "Approx 100% complete for SRR13349126_1_trimmed.fastq.gz\n",
      "Analysis complete for SRR13349126_1_trimmed.fastq.gz\n",
      "application/gzip\n",
      "Started analysis of SRR13349127_1_trimmed.fastq.gz\n",
      "Approx 5% complete for SRR13349127_1_trimmed.fastq.gz\n",
      "Approx 10% complete for SRR13349127_1_trimmed.fastq.gz\n",
      "Approx 15% complete for SRR13349127_1_trimmed.fastq.gz\n",
      "Approx 20% complete for SRR13349127_1_trimmed.fastq.gz\n",
      "Approx 25% complete for SRR13349127_1_trimmed.fastq.gz\n",
      "Approx 30% complete for SRR13349127_1_trimmed.fastq.gz\n",
      "Approx 35% complete for SRR13349127_1_trimmed.fastq.gz\n",
      "Approx 40% complete for SRR13349127_1_trimmed.fastq.gz\n",
      "Approx 45% complete for SRR13349127_1_trimmed.fastq.gz\n",
      "Approx 50% complete for SRR13349127_1_trimmed.fastq.gz\n",
      "Approx 55% complete for SRR13349127_1_trimmed.fastq.gz\n",
      "Approx 60% complete for SRR13349127_1_trimmed.fastq.gz\n",
      "Approx 65% complete for SRR13349127_1_trimmed.fastq.gz\n",
      "Approx 70% complete for SRR13349127_1_trimmed.fastq.gz\n",
      "Approx 75% complete for SRR13349127_1_trimmed.fastq.gz\n",
      "Approx 80% complete for SRR13349127_1_trimmed.fastq.gz\n",
      "Approx 85% complete for SRR13349127_1_trimmed.fastq.gz\n",
      "Approx 90% complete for SRR13349127_1_trimmed.fastq.gz\n",
      "Approx 95% complete for SRR13349127_1_trimmed.fastq.gz\n",
      "Analysis complete for SRR13349127_1_trimmed.fastq.gz\n",
      "application/gzip\n",
      "Started analysis of SRR13349128_1_trimmed.fastq.gz\n",
      "Approx 5% complete for SRR13349128_1_trimmed.fastq.gz\n",
      "Approx 10% complete for SRR13349128_1_trimmed.fastq.gz\n",
      "Approx 15% complete for SRR13349128_1_trimmed.fastq.gz\n",
      "Approx 20% complete for SRR13349128_1_trimmed.fastq.gz\n",
      "Approx 25% complete for SRR13349128_1_trimmed.fastq.gz\n",
      "Approx 30% complete for SRR13349128_1_trimmed.fastq.gz\n",
      "Approx 35% complete for SRR13349128_1_trimmed.fastq.gz\n",
      "Approx 40% complete for SRR13349128_1_trimmed.fastq.gz\n",
      "Approx 45% complete for SRR13349128_1_trimmed.fastq.gz\n",
      "Approx 50% complete for SRR13349128_1_trimmed.fastq.gz\n",
      "Approx 55% complete for SRR13349128_1_trimmed.fastq.gz\n",
      "Approx 60% complete for SRR13349128_1_trimmed.fastq.gz\n",
      "Approx 65% complete for SRR13349128_1_trimmed.fastq.gz\n",
      "Approx 70% complete for SRR13349128_1_trimmed.fastq.gz\n",
      "Approx 75% complete for SRR13349128_1_trimmed.fastq.gz\n",
      "Approx 80% complete for SRR13349128_1_trimmed.fastq.gz\n",
      "Approx 85% complete for SRR13349128_1_trimmed.fastq.gz\n",
      "Approx 90% complete for SRR13349128_1_trimmed.fastq.gz\n",
      "Approx 95% complete for SRR13349128_1_trimmed.fastq.gz\n",
      "Analysis complete for SRR13349128_1_trimmed.fastq.gz\n",
      "application/gzip\n",
      "Started analysis of SRR13349129_1_trimmed.fastq.gz\n",
      "Approx 5% complete for SRR13349129_1_trimmed.fastq.gz\n",
      "Approx 10% complete for SRR13349129_1_trimmed.fastq.gz\n",
      "Approx 15% complete for SRR13349129_1_trimmed.fastq.gz\n",
      "Approx 20% complete for SRR13349129_1_trimmed.fastq.gz\n",
      "Approx 25% complete for SRR13349129_1_trimmed.fastq.gz\n",
      "Approx 30% complete for SRR13349129_1_trimmed.fastq.gz\n",
      "Approx 35% complete for SRR13349129_1_trimmed.fastq.gz\n",
      "Approx 40% complete for SRR13349129_1_trimmed.fastq.gz\n",
      "Approx 45% complete for SRR13349129_1_trimmed.fastq.gz\n",
      "Approx 50% complete for SRR13349129_1_trimmed.fastq.gz\n",
      "Approx 55% complete for SRR13349129_1_trimmed.fastq.gz\n",
      "Approx 60% complete for SRR13349129_1_trimmed.fastq.gz\n",
      "Approx 65% complete for SRR13349129_1_trimmed.fastq.gz\n",
      "Approx 70% complete for SRR13349129_1_trimmed.fastq.gz\n",
      "Approx 75% complete for SRR13349129_1_trimmed.fastq.gz\n",
      "Approx 80% complete for SRR13349129_1_trimmed.fastq.gz\n",
      "Approx 85% complete for SRR13349129_1_trimmed.fastq.gz\n",
      "Approx 90% complete for SRR13349129_1_trimmed.fastq.gz\n",
      "Approx 95% complete for SRR13349129_1_trimmed.fastq.gz\n",
      "Analysis complete for SRR13349129_1_trimmed.fastq.gz\n",
      "application/gzip\n",
      "Started analysis of SRR13349130_1_trimmed.fastq.gz\n",
      "Approx 5% complete for SRR13349130_1_trimmed.fastq.gz\n",
      "Approx 10% complete for SRR13349130_1_trimmed.fastq.gz\n",
      "Approx 15% complete for SRR13349130_1_trimmed.fastq.gz\n",
      "Approx 20% complete for SRR13349130_1_trimmed.fastq.gz\n",
      "Approx 25% complete for SRR13349130_1_trimmed.fastq.gz\n",
      "Approx 30% complete for SRR13349130_1_trimmed.fastq.gz\n",
      "Approx 35% complete for SRR13349130_1_trimmed.fastq.gz\n",
      "Approx 40% complete for SRR13349130_1_trimmed.fastq.gz\n",
      "Approx 45% complete for SRR13349130_1_trimmed.fastq.gz\n",
      "Approx 50% complete for SRR13349130_1_trimmed.fastq.gz\n",
      "Approx 55% complete for SRR13349130_1_trimmed.fastq.gz\n",
      "Approx 60% complete for SRR13349130_1_trimmed.fastq.gz\n",
      "Approx 65% complete for SRR13349130_1_trimmed.fastq.gz\n",
      "Approx 70% complete for SRR13349130_1_trimmed.fastq.gz\n",
      "Approx 75% complete for SRR13349130_1_trimmed.fastq.gz\n",
      "Approx 80% complete for SRR13349130_1_trimmed.fastq.gz\n",
      "Approx 85% complete for SRR13349130_1_trimmed.fastq.gz\n",
      "Approx 90% complete for SRR13349130_1_trimmed.fastq.gz\n",
      "Approx 95% complete for SRR13349130_1_trimmed.fastq.gz\n",
      "Analysis complete for SRR13349130_1_trimmed.fastq.gz\n",
      "application/gzip\n",
      "Started analysis of SRR13349131_1_trimmed.fastq.gz\n",
      "Approx 5% complete for SRR13349131_1_trimmed.fastq.gz\n",
      "Approx 10% complete for SRR13349131_1_trimmed.fastq.gz\n",
      "Approx 15% complete for SRR13349131_1_trimmed.fastq.gz\n",
      "Approx 20% complete for SRR13349131_1_trimmed.fastq.gz\n",
      "Approx 25% complete for SRR13349131_1_trimmed.fastq.gz\n",
      "Approx 30% complete for SRR13349131_1_trimmed.fastq.gz\n",
      "Approx 35% complete for SRR13349131_1_trimmed.fastq.gz\n",
      "Approx 40% complete for SRR13349131_1_trimmed.fastq.gz\n",
      "Approx 45% complete for SRR13349131_1_trimmed.fastq.gz\n",
      "Approx 50% complete for SRR13349131_1_trimmed.fastq.gz\n",
      "Approx 55% complete for SRR13349131_1_trimmed.fastq.gz\n",
      "Approx 60% complete for SRR13349131_1_trimmed.fastq.gz\n",
      "Approx 65% complete for SRR13349131_1_trimmed.fastq.gz\n",
      "Approx 70% complete for SRR13349131_1_trimmed.fastq.gz\n",
      "Approx 75% complete for SRR13349131_1_trimmed.fastq.gz\n",
      "Approx 80% complete for SRR13349131_1_trimmed.fastq.gz\n",
      "Approx 85% complete for SRR13349131_1_trimmed.fastq.gz\n",
      "Approx 90% complete for SRR13349131_1_trimmed.fastq.gz\n",
      "Approx 95% complete for SRR13349131_1_trimmed.fastq.gz\n",
      "Analysis complete for SRR13349131_1_trimmed.fastq.gz\n",
      "application/gzip\n",
      "Started analysis of SRR13349132_1_trimmed.fastq.gz\n",
      "Approx 5% complete for SRR13349132_1_trimmed.fastq.gz\n",
      "Approx 10% complete for SRR13349132_1_trimmed.fastq.gz\n",
      "Approx 15% complete for SRR13349132_1_trimmed.fastq.gz\n",
      "Approx 20% complete for SRR13349132_1_trimmed.fastq.gz\n",
      "Approx 25% complete for SRR13349132_1_trimmed.fastq.gz\n",
      "Approx 30% complete for SRR13349132_1_trimmed.fastq.gz\n",
      "Approx 35% complete for SRR13349132_1_trimmed.fastq.gz\n",
      "Approx 40% complete for SRR13349132_1_trimmed.fastq.gz\n",
      "Approx 45% complete for SRR13349132_1_trimmed.fastq.gz\n",
      "Approx 50% complete for SRR13349132_1_trimmed.fastq.gz\n",
      "Approx 55% complete for SRR13349132_1_trimmed.fastq.gz\n",
      "Approx 60% complete for SRR13349132_1_trimmed.fastq.gz\n",
      "Approx 65% complete for SRR13349132_1_trimmed.fastq.gz\n",
      "Approx 70% complete for SRR13349132_1_trimmed.fastq.gz\n",
      "Approx 75% complete for SRR13349132_1_trimmed.fastq.gz\n",
      "Approx 80% complete for SRR13349132_1_trimmed.fastq.gz\n",
      "Approx 85% complete for SRR13349132_1_trimmed.fastq.gz\n",
      "Approx 90% complete for SRR13349132_1_trimmed.fastq.gz\n",
      "Approx 95% complete for SRR13349132_1_trimmed.fastq.gz\n",
      "Analysis complete for SRR13349132_1_trimmed.fastq.gz\n",
      "application/gzip\n",
      "Started analysis of SRR13349133_1_trimmed.fastq.gz\n",
      "Approx 5% complete for SRR13349133_1_trimmed.fastq.gz\n",
      "Approx 10% complete for SRR13349133_1_trimmed.fastq.gz\n",
      "Approx 15% complete for SRR13349133_1_trimmed.fastq.gz\n",
      "Approx 20% complete for SRR13349133_1_trimmed.fastq.gz\n",
      "Approx 25% complete for SRR13349133_1_trimmed.fastq.gz\n",
      "Approx 30% complete for SRR13349133_1_trimmed.fastq.gz\n",
      "Approx 35% complete for SRR13349133_1_trimmed.fastq.gz\n",
      "Approx 40% complete for SRR13349133_1_trimmed.fastq.gz\n",
      "Approx 45% complete for SRR13349133_1_trimmed.fastq.gz\n",
      "Approx 50% complete for SRR13349133_1_trimmed.fastq.gz\n",
      "Approx 55% complete for SRR13349133_1_trimmed.fastq.gz\n",
      "Approx 60% complete for SRR13349133_1_trimmed.fastq.gz\n",
      "Approx 65% complete for SRR13349133_1_trimmed.fastq.gz\n",
      "Approx 70% complete for SRR13349133_1_trimmed.fastq.gz\n",
      "Approx 75% complete for SRR13349133_1_trimmed.fastq.gz\n",
      "Approx 80% complete for SRR13349133_1_trimmed.fastq.gz\n",
      "Approx 85% complete for SRR13349133_1_trimmed.fastq.gz\n",
      "Approx 90% complete for SRR13349133_1_trimmed.fastq.gz\n",
      "Approx 95% complete for SRR13349133_1_trimmed.fastq.gz\n",
      "Analysis complete for SRR13349133_1_trimmed.fastq.gz\n"
     ]
    }
   ],
   "source": [
    "! cat accs.txt | xargs -I {} fastqc -t $CORES \"data/trimmed/{}_1_trimmed.fastq.gz\" -o data/fastqc/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 8: Run MultiQC\n",
    "MultiQC reads in the FastQC reports and generate a compiled report for all the analyzed FASTQ files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[91m///\u001b[0m \u001b]8;id=929879;https://multiqc.info\u001b\\\u001b[1mMultiQC\u001b[0m\u001b]8;;\u001b\\ 🍾 \u001b[2mv1.33\u001b[0m\n",
      "\n",
      "\u001b[34m       file_search\u001b[0m | Search path: /home/jupyter/rnaseq-myco-notebook/data/fastqc\n",
      "\u001b[2K         \u001b[34msearching\u001b[0m | \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100%\u001b[0m \u001b[32m24/24\u001b[0m  349123_1_trimmed_fastqc.html\u001b[0m\n",
      "\u001b[?25h\u001b[34m            fastqc\u001b[0m | Found 12 reports\n",
      "\u001b[34m     write_results\u001b[0m | Data        : multiqc_data   (overwritten)\n",
      "\u001b[34m     write_results\u001b[0m | Report      : multiqc_report.html   (overwritten)\n",
      "\u001b[34m           multiqc\u001b[0m | MultiQC complete\n"
     ]
    }
   ],
   "source": [
    "! multiqc -f data/fastqc/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 9: Index the Transcriptome so that Trimmed Reads Can Be Mapped Using Salmon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Version Server Response: Not Found\n",
      "index [\"data/reference/transcriptome_index\"] did not previously exist  . . . creating it\n",
      "[2026-01-05 19:29:24.154] [jLog] [info] building index\n",
      "out : data/reference/transcriptome_index\n",
      "\u001b[00m[2026-01-05 19:29:24.155] [puff::index::jointLog] [info] Running fixFasta\n",
      "\u001b[00m\n",
      "[Step 1 of 4] : counting k-mers\n",
      "\n",
      "\u001b[35m[2026-01-05 19:29:24.422] [puff::index::jointLog] [warning] There were 1 transcripts that would need to be removed to avoid duplicates.\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:29:24.424] [puff::index::jointLog] [info] Replaced 0 non-ATCG nucleotides\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:29:24.424] [puff::index::jointLog] [info] Clipped poly-A tails from 0 transcripts\n",
      "\u001b[00mwrote 4930 cleaned references\n",
      "\u001b[00m[2026-01-05 19:29:24.444] [puff::index::jointLog] [info] Filter size not provided; estimating from number of distinct k-mers\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:29:24.548] [puff::index::jointLog] [info] ntHll estimated 4966944 distinct k-mers, setting filter size to 2^27\n",
      "\u001b[00mThreads = 4\n",
      "Vertex length = 31\n",
      "Hash functions = 5\n",
      "Filter size = 134217728\n",
      "Capacity = 2\n",
      "Files: \n",
      "data/reference/transcriptome_index/ref_k31_fixed.fa\n",
      "--------------------------------------------------------------------------------\n",
      "Round 0, 0:134217728\n",
      "Pass\tFilling\tFiltering\n",
      "1\t2\t3\t\n",
      "2\t0\t0\n",
      "True junctions count = 10254\n",
      "False junctions count = 5108\n",
      "Hash table size = 15362\n",
      "Candidate marks count = 31289\n",
      "--------------------------------------------------------------------------------\n",
      "Reallocating bifurcations time: 0\n",
      "True marks count: 21534\n",
      "Edges construction time: 1\n",
      "--------------------------------------------------------------------------------\n",
      "Distinct junctions = 10254\n",
      "\n",
      "TwoPaCo::buildGraphMain:: allocated with scalable_malloc; freeing.\n",
      "TwoPaCo::buildGraphMain:: Calling scalable_allocation_command(TBBMALLOC_CLEAN_ALL_BUFFERS, 0);\n",
      "allowedIn: 17\n",
      "Max Junction ID: 10297\n",
      "seen.size():82385 kmerInfo.size():10298\n",
      "approximateContigTotalLength: 4949999\n",
      "counters for complex kmers:\n",
      "(prec>1 & succ>1)=8 | (succ>1 & isStart)=0 | (prec>1 & isEnd)=0 | (isStart & isEnd)=3\n",
      "contig count: 10477 element count: 5331843 complex nodes: 11\n",
      "# of ones in rank vector: 10476\n",
      "\u001b[00m[2026-01-05 19:29:30.705] [puff::index::jointLog] [info] Starting the Pufferfish indexing by reading the GFA binary file.\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:29:30.705] [puff::index::jointLog] [info] Setting the index/BinaryGfa directory data/reference/transcriptome_index\n",
      "\u001b[00msize = 5331843\n",
      "-----------------------------------------\n",
      "| Loading contigs | Time = 1.2799 ms\n",
      "-----------------------------------------\n",
      "size = 5331843\n",
      "-----------------------------------------\n",
      "| Loading contig boundaries | Time = 639.86 us\n",
      "-----------------------------------------\n",
      "Number of ones: 10476\n",
      "Number of ones per inventory item: 512\n",
      "Inventory entries filled: 21\n",
      "10476\n",
      "\u001b[00m[2026-01-05 19:29:30.716] [puff::index::jointLog] [info] Done wrapping the rank vector with a rank9sel structure.\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:29:30.716] [puff::index::jointLog] [info] contig count for validation: 10476\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:29:30.719] [puff::index::jointLog] [info] Total # of Contigs : 10476\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:29:30.719] [puff::index::jointLog] [info] Total # of numerical Contigs : 10476\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:29:30.719] [puff::index::jointLog] [info] Total # of contig vec entries: 16640\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:29:30.719] [puff::index::jointLog] [info] bits per offset entry 15\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:29:30.720] [puff::index::jointLog] [info] Done constructing the contig vector. 10477\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:29:30.721] [puff::index::jointLog] [info] # segments = 10476\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:29:30.721] [puff::index::jointLog] [info] total length = 5331843\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:29:30.723] [puff::index::jointLog] [info] Reading the reference files ...\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:29:30.767] [puff::index::jointLog] [info] positional integer width = 23\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:29:30.767] [puff::index::jointLog] [info] seqSize = 5331843\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:29:30.767] [puff::index::jointLog] [info] rankSize = 5331843\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:29:30.767] [puff::index::jointLog] [info] edgeVecSize = 0\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:29:30.767] [puff::index::jointLog] [info] num keys = 5017563\n",
      "\u001b[00mfor info, total work write each  : 2.331    total work inram from level 3 : 4.322  total work raw : 25.000 \n",
      "[Building BooPHF]  100  %   elapsed:   0 min 0  sec   remaining:   0 min 0  sec\n",
      "Bitarray        26296128  bits (100.00 %)   (array + ranks )\n",
      "final hash             0  bits (0.00 %) (nb in final hash 0)\n",
      "\u001b[00m[2026-01-05 19:29:31.071] [puff::index::jointLog] [info] mphf size = 3.13474 MB\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:29:31.076] [puff::index::jointLog] [info] chunk size = 1332961\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:29:31.076] [puff::index::jointLog] [info] chunk 0 = [0, 1332961)\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:29:31.076] [puff::index::jointLog] [info] chunk 1 = [1332961, 2665922)\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:29:31.076] [puff::index::jointLog] [info] chunk 2 = [2665922, 3998883)\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:29:31.076] [puff::index::jointLog] [info] chunk 3 = [3998883, 5331813)\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:29:31.425] [puff::index::jointLog] [info] finished populating pos vector\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:29:31.425] [puff::index::jointLog] [info] writing index components\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:29:31.441] [puff::index::jointLog] [info] finished writing dense pufferfish index\n",
      "\u001b[00m[2026-01-05 19:29:31.444] [jLog] [info] done building index\n"
     ]
    }
   ],
   "source": [
    "! salmon index -t data/reference/GCF_001632805.1_transcriptome_reference_w_decoy.fa -p $CORES -i data/reference/transcriptome_index --decoys data/reference/decoys.txt -k 31 --keepDuplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 10: Run Salmon to Map Reads to Transcripts and Quantify Expression Levels\n",
    "Salmon aligns the trimmed reads to the reference transcriptome and generates the read counts per transcript. In this analysis, each gene has a single transcript."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Version Server Response: Not Found\n",
      "### salmon (selective-alignment-based) v1.10.3\n",
      "### [ program ] => salmon \n",
      "### [ command ] => quant \n",
      "### [ index ] => { data/reference/transcriptome_index }\n",
      "### [ libType ] => { SR }\n",
      "### [ unmatedReads ] => { data/trimmed/SRR13349122_1_trimmed.fastq.gz }\n",
      "### [ threads ] => { 4 }\n",
      "### [ validateMappings ] => { }\n",
      "### [ output ] => { data/quants/SRR13349122_quant }\n",
      "Logs will be written to data/quants/SRR13349122_quant/logs\n",
      "\u001b[00m[2026-01-05 19:29:31.618] [jointLog] [info] setting maxHashResizeThreads to 4\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:29:31.618] [jointLog] [info] Fragment incompatibility prior below threshold.  Incompatible fragments will be ignored.\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:29:31.618] [jointLog] [info] Usage of --validateMappings implies use of minScoreFraction. Since not explicitly specified, it is being set to 0.65\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:29:31.618] [jointLog] [info] Setting consensusSlack to selective-alignment default of 0.35.\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:29:31.618] [jointLog] [info] parsing read library format\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:29:31.619] [jointLog] [info] There is 1 library.\n",
      "\u001b[00m-----------------------------------------\n",
      "| Loading contig table | Time = 1.0345 ms\n",
      "-----------------------------------------\n",
      "size = 10477\n",
      "-----------------------------------------\n",
      "| Loading contig offsets | Time = 124 us\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| Loading reference lengths | Time = 21.081 us\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| Loading mphf table | Time = 2.9635 ms\n",
      "-----------------------------------------\n",
      "size = 5331843\n",
      "Number of ones: 10476\n",
      "Number of ones per inventory item: 512\n",
      "Inventory entries filled: 21\n",
      "-----------------------------------------\n",
      "| Loading contig boundaries | Time = 9.8123 ms\n",
      "-----------------------------------------\n",
      "size = 5331843\n",
      "-----------------------------------------\n",
      "| Loading sequence | Time = 1.4561 ms\n",
      "-----------------------------------------\n",
      "size = 5017563\n",
      "\u001b[00m[2026-01-05 19:29:31.619] [jointLog] [info] Loading pufferfish index\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:29:31.619] [jointLog] [info] Loading dense pufferfish index.\n",
      "\u001b[00m-----------------------------------------\n",
      "| Loading positions | Time = 11.91 ms\n",
      "-----------------------------------------\n",
      "size = 9697527\n",
      "-----------------------------------------\n",
      "| Loading reference sequence | Time = 2.0709 ms\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| Loading reference accumulative lengths | Time = 41.092 us\n",
      "-----------------------------------------\n",
      "\u001b[00m[2026-01-05 19:29:31.649] [jointLog] [info] done\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:29:31.699] [jointLog] [info] Index contained 4930 targets\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:29:31.701] [jointLog] [info] Number of decoys : 1\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:29:31.701] [jointLog] [info] First decoy index : 4929 \n",
      "\u001b[00m\n",
      "\n",
      "\n",
      "\n",
      "\u001b[32mprocessed\u001b[31m 500000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 1000000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 1500000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 2000000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 2500000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 3000000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 3500000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 4000000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 4500000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 5000001 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 5500001 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 6000001 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 6500000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 7000001 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 8000001 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 8500001 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 9000001 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 9500000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 10000000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 10500000 \u001b[32mfragments\u001b[0m\n",
      "hits: 10013192; hits per frag:  0.954792\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[00m[2026-01-05 19:29:51.114] [jointLog] [info] Thread saw mini-batch with a maximum of 0.34% zero probability fragments\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:29:51.116] [jointLog] [info] Thread saw mini-batch with a maximum of 0.42% zero probability fragments\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:29:51.125] [jointLog] [info] Thread saw mini-batch with a maximum of 0.38% zero probability fragments\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:29:51.131] [jointLog] [info] Thread saw mini-batch with a maximum of 0.38% zero probability fragments\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:29:51.147] [jointLog] [info] Computed 4614 rich equivalence classes for further processing\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:29:51.147] [jointLog] [info] Counted 10288422 total reads in the equivalence classes \n",
      "\u001b[00m\u001b[00m[2026-01-05 19:29:51.151] [jointLog] [info] Number of mappings discarded because of alignment score : 160514\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:29:51.151] [jointLog] [info] Number of fragments entirely discarded because of alignment score : 134296\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:29:51.151] [jointLog] [info] Number of fragments discarded because they are best-mapped to decoys : 73271\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:29:51.151] [jointLog] [info] Number of fragments discarded because they have only dovetail (discordant) mappings to valid targets : 0\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:29:51.151] [jointLog] [info] Mapping rate = 95.1727%\n",
      "\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:29:51.151] [jointLog] [info] finished quantifyLibrary()\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:29:51.151] [jointLog] [info] Starting optimizer\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:29:51.153] [jointLog] [info] Marked 0 weighted equivalence classes as degenerate\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:29:51.153] [jointLog] [info] iteration = 0 | max rel diff. = 3314.84\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:29:51.189] [jointLog] [info] iteration = 100 | max rel diff. = 0\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:29:51.190] [jointLog] [info] Finished optimizer\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:29:51.190] [jointLog] [info] writing output \n",
      "\n",
      "\u001b[00mVersion Server Response: Not Found\n",
      "### salmon (selective-alignment-based) v1.10.3\n",
      "### [ program ] => salmon \n",
      "### [ command ] => quant \n",
      "### [ index ] => { data/reference/transcriptome_index }\n",
      "### [ libType ] => { SR }\n",
      "### [ unmatedReads ] => { data/trimmed/SRR13349123_1_trimmed.fastq.gz }\n",
      "### [ threads ] => { 4 }\n",
      "### [ validateMappings ] => { }\n",
      "### [ output ] => { data/quants/SRR13349123_quant }\n",
      "Logs will be written to data/quants/SRR13349123_quant/logs\n",
      "\u001b[00m[2026-01-05 19:29:51.477] [jointLog] [info] setting maxHashResizeThreads to 4\n",
      "\u001b[00m-----------------------------------------\n",
      "| Loading contig table | Time = 1.1056 ms\n",
      "-----------------------------------------\n",
      "\u001b[00msize = [2026-01-05 19:29:51.477] [jointLog] [info] Fragment incompatibility prior below threshold.  Incompatible fragments will be ignored.\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:29:51.477] [jointLog] [info] Usage of --validateMappings implies use of minScoreFraction. Since not explicitly specified, it is being set to 0.65\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:29:51.477] [jointLog] [info] Setting consensusSlack to selective-alignment default of 0.35.\n",
      "\u001b[00m10477\n",
      "\u001b[00m[2026-01-05 19:29:51.477] [jointLog] [info] parsing read library format\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:29:51.477] [jointLog] [info] There is 1 library.\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:29:51.477] [jointLog] [info] Loading pufferfish index\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:29:51.477] [jointLog] [info] Loading dense pufferfish index.\n",
      "\u001b[00m-----------------------------------------\n",
      "| Loading contig offsets | Time = 172.53 us\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| Loading reference lengths | Time = 20.763 us\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| Loading mphf table | Time = 3.0599 ms\n",
      "-----------------------------------------\n",
      "size = 5331843\n",
      "Number of ones: 10476\n",
      "Number of ones per inventory item: 512\n",
      "Inventory entries filled: 21\n",
      "-----------------------------------------\n",
      "| Loading contig boundaries | Time = 9.6707 ms\n",
      "-----------------------------------------\n",
      "size = 5331843\n",
      "-----------------------------------------\n",
      "| Loading sequence | Time = 1.2675 ms\n",
      "-----------------------------------------\n",
      "size = 5017563\n",
      "-----------------------------------------\n",
      "| Loading positions | Time = 13.054 ms\n",
      "-----------------------------------------\n",
      "size = 9697527\n",
      "-----------------------------------------\n",
      "| Loading reference sequence | Time = 2.3272 ms\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| Loading reference accumulative lengths | Time = 48.677 us\n",
      "-----------------------------------------\n",
      "\u001b[00m[2026-01-05 19:29:51.508] [jointLog] [info] done\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:29:51.559] [jointLog] [info] Index contained 4930 targets\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:29:51.560] [jointLog] [info] Number of decoys : 1\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:29:51.560] [jointLog] [info] First decoy index : 4929 \n",
      "\u001b[00m\n",
      "\n",
      "\n",
      "\n",
      "\u001b[32mprocessed\u001b[31m 500001 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 1000000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 1500000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 2000001 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 2500000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 3000000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 3500000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 4000000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 4500000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 5000000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 5500001 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 6000000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 6500000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 7000000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 7500000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 8000000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 8500001 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 9000000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 9500002 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 10000000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 10500001 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 11000000 \u001b[32mfragments\u001b[0m\n",
      "hits: 10546982; hits per frag:  0.960324\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[00m[2026-01-05 19:30:12.615] [jointLog] [info] Thread saw mini-batch with a maximum of 0.48% zero probability fragments\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:30:12.622] [jointLog] [info] Thread saw mini-batch with a maximum of 0.44% zero probability fragments\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:30:12.625] [jointLog] [info] Thread saw mini-batch with a maximum of 0.40% zero probability fragments\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:30:12.632] [jointLog] [info] Thread saw mini-batch with a maximum of 0.42% zero probability fragments\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:30:12.647] [jointLog] [info] Computed 4670 rich equivalence classes for further processing\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:30:12.647] [jointLog] [info] Counted 10613962 total reads in the equivalence classes \n",
      "\u001b[00m\u001b[00m[2026-01-05 19:30:12.650] [jointLog] [info] Number of mappings discarded because of alignment score : 166631\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:30:12.650] [jointLog] [info] Number of fragments entirely discarded because of alignment score : 143413\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:30:12.650] [jointLog] [info] Number of fragments discarded because they are best-mapped to decoys : 81088\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:30:12.650] [jointLog] [info] Number of fragments discarded because they have only dovetail (discordant) mappings to valid targets : 0\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:30:12.650] [jointLog] [info] Mapping rate = 95.6535%\n",
      "\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:30:12.650] [jointLog] [info] finished quantifyLibrary()\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:30:12.650] [jointLog] [info] Starting optimizer\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:30:12.652] [jointLog] [info] Marked 0 weighted equivalence classes as degenerate\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:30:12.652] [jointLog] [info] iteration = 0 | max rel diff. = 3391.72\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:30:12.687] [jointLog] [info] iteration = 100 | max rel diff. = 2.67393e-09\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:30:12.687] [jointLog] [info] Finished optimizer\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:30:12.687] [jointLog] [info] writing output \n",
      "\n",
      "\u001b[00mVersion Server Response: Not Found\n",
      "### salmon (selective-alignment-based) v1.10.3\n",
      "### [ program ] => salmon \n",
      "### [ command ] => quant \n",
      "### [ index ] => { data/reference/transcriptome_index }\n",
      "### [ libType ] => { SR }\n",
      "### [ unmatedReads ] => { data/trimmed/SRR13349124_1_trimmed.fastq.gz }\n",
      "### [ threads ] => { 4 }\n",
      "### [ validateMappings ] => { }\n",
      "### [ output ] => { data/quants/SRR13349124_quant }\n",
      "Logs will be written to data/quants/SRR13349124_quant/logs\n",
      "\u001b[00m[2026-01-05 19:30:13.561] [jointLog] [info] setting maxHashResizeThreads to 4\n",
      "\u001b[00m-----------------------------------------\n",
      "| Loading contig table | Time = 1.1966 ms\n",
      "-----------------------------------------\n",
      "\u001b[00m[2026-01-05 19:30:13.561] [jointLog] [info] Fragment incompatibility prior below threshold.  Incompatible fragments will be ignored.\n",
      "size = \u001b[00m\u001b[00m[2026-01-05 19:30:13.561] [jointLog] [info] Usage of --validateMappings implies use of minScoreFraction. Since not explicitly specified, it is being set to 0.65\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:30:13.561] [jointLog] [info] Setting consensusSlack to selective-alignment default of 0.35.\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:30:13.561] [jointLog] [info] parsing read library format\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:30:13.561] [jointLog] [info] There is 1 library.\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:30:13.561] [jointLog] [info] Loading pufferfish index\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:30:13.561] [jointLog] [info] Loading dense pufferfish index.\n",
      "\u001b[00m10477\n",
      "-----------------------------------------\n",
      "| Loading contig offsets | Time = 272.44 us\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| Loading reference lengths | Time = 22.022 us\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| Loading mphf table | Time = 3.0191 ms\n",
      "-----------------------------------------\n",
      "size = 5331843\n",
      "Number of ones: 10476\n",
      "Number of ones per inventory item: 512\n",
      "Inventory entries filled: 21\n",
      "-----------------------------------------\n",
      "| Loading contig boundaries | Time = 9.487 ms\n",
      "-----------------------------------------\n",
      "size = 5331843\n",
      "-----------------------------------------\n",
      "| Loading sequence | Time = 1.2596 ms\n",
      "-----------------------------------------\n",
      "size = 5017563\n",
      "-----------------------------------------\n",
      "| Loading positions | Time = 12.312 ms\n",
      "-----------------------------------------\n",
      "size = 9697527\n",
      "-----------------------------------------\n",
      "| Loading reference sequence | Time = 2.1091 ms\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| Loading reference accumulative lengths | Time = 36.484 us\n",
      "-----------------------------------------\n",
      "\u001b[00m[2026-01-05 19:30:13.591] [jointLog] [info] done\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:30:13.641] [jointLog] [info] Index contained 4930 targets\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:30:13.641] [jointLog] [info] Number of decoys : 1\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:30:13.641] [jointLog] [info] First decoy index : 4929 \n",
      "\u001b[00m\n",
      "\n",
      "\n",
      "\n",
      "\u001b[32mprocessed\u001b[31m 500000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 1000000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 1500000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 2000000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 2500000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 3000000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 3500000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 4000000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 4500000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 5000000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 5500000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 6000000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 6500000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 7000000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 7500000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 8000001 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 8500000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 9000001 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 9500000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 10000000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 10500000 \u001b[32mfragments\u001b[0m\n",
      "hits: 9990954; hits per frag:  0.9517\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[00m[2026-01-05 19:30:32.703] [jointLog] [info] Thread saw mini-batch with a maximum of 0.32% zero probability fragments\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:30:32.704] [jointLog] [info] Thread saw mini-batch with a maximum of 0.34% zero probability fragments\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:30:32.713] [jointLog] [info] Thread saw mini-batch with a maximum of 0.32% zero probability fragments\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:30:32.719] [jointLog] [info] Thread saw mini-batch with a maximum of 0.34% zero probability fragments\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:30:32.734] [jointLog] [info] Computed 4590 rich equivalence classes for further processing\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:30:32.734] [jointLog] [info] Counted 10173217 total reads in the equivalence classes \n",
      "\u001b[00m\u001b[00m[2026-01-05 19:30:32.737] [jointLog] [info] Number of mappings discarded because of alignment score : 195170\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:30:32.737] [jointLog] [info] Number of fragments entirely discarded because of alignment score : 144977\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:30:32.737] [jointLog] [info] Number of fragments discarded because they are best-mapped to decoys : 64816\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:30:32.737] [jointLog] [info] Number of fragments discarded because they have only dovetail (discordant) mappings to valid targets : 0\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:30:32.737] [jointLog] [info] Mapping rate = 94.9866%\n",
      "\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:30:32.737] [jointLog] [info] finished quantifyLibrary()\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:30:32.737] [jointLog] [info] Starting optimizer\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:30:32.740] [jointLog] [info] Marked 0 weighted equivalence classes as degenerate\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:30:32.740] [jointLog] [info] iteration = 0 | max rel diff. = 1643.21\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:30:32.774] [jointLog] [info] iteration = 100 | max rel diff. = 1.82387e-16\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:30:32.775] [jointLog] [info] Finished optimizer\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:30:32.775] [jointLog] [info] writing output \n",
      "\n",
      "\u001b[00mVersion Server Response: Not Found\n",
      "### salmon (selective-alignment-based) v1.10.3\n",
      "### [ program ] => salmon \n",
      "### [ command ] => quant \n",
      "### [ index ] => { data/reference/transcriptome_index }\n",
      "### [ libType ] => { SR }\n",
      "### [ unmatedReads ] => { data/trimmed/SRR13349125_1_trimmed.fastq.gz }\n",
      "### [ threads ] => { 4 }\n",
      "### [ validateMappings ] => { }\n",
      "### [ output ] => { data/quants/SRR13349125_quant }\n",
      "Logs will be written to data/quants/SRR13349125_quant/logs\n",
      "\u001b[00m[2026-01-05 19:30:33.609] [jointLog] [info] setting maxHashResizeThreads to 4\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:30:33.609] [jointLog] [info] Fragment incompatibility prior below threshold.  Incompatible fragments will be ignored.\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:30:33.609] [jointLog] [info] Usage of --validateMappings implies use of minScoreFraction. Since not explicitly specified, it is being set to 0.65\n",
      "\u001b[00m\u001b[00m-----------------------------------------\n",
      "| Loading contig table | Time = 1.0963 ms\n",
      "-----------------------------------------[2026-01-05 19:30:33.609] [jointLog] [info] Setting consensusSlack to selective-alignment default of 0.35.\n",
      "\u001b[00m\u001b[00m\n",
      "[2026-01-05 19:30:33.609] [jointLog] [info] parsing read library format\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:30:33.609] [jointLog] [info] There is 1 library.\n",
      "\u001b[00msize = 10477\n",
      "\u001b[00m[2026-01-05 19:30:33.609] [jointLog] [info] Loading pufferfish index\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:30:33.609] [jointLog] [info] Loading dense pufferfish index.\n",
      "\u001b[00m-----------------------------------------\n",
      "| Loading contig offsets | Time = 118.56 us\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| Loading reference lengths | Time = 25.83 us\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| Loading mphf table | Time = 2.9888 ms\n",
      "-----------------------------------------\n",
      "size = 5331843\n",
      "Number of ones: 10476\n",
      "Number of ones per inventory item: 512\n",
      "Inventory entries filled: 21\n",
      "-----------------------------------------\n",
      "| Loading contig boundaries | Time = 9.8038 ms\n",
      "-----------------------------------------\n",
      "size = 5331843\n",
      "-----------------------------------------\n",
      "| Loading sequence | Time = 1.3058 ms\n",
      "-----------------------------------------\n",
      "size = 5017563\n",
      "-----------------------------------------\n",
      "| Loading positions | Time = 12.364 ms\n",
      "-----------------------------------------\n",
      "size = 9697527\n",
      "-----------------------------------------\n",
      "| Loading reference sequence | Time = 2.1067 ms\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| Loading reference accumulative lengths | Time = 39.023 us\n",
      "-----------------------------------------\n",
      "\u001b[00m[2026-01-05 19:30:33.640] [jointLog] [info] done\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:30:33.691] [jointLog] [info] Index contained 4930 targets\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:30:33.692] [jointLog] [info] Number of decoys : 1\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:30:33.692] [jointLog] [info] First decoy index : 4929 \n",
      "\u001b[00m\n",
      "\n",
      "\n",
      "\n",
      "\u001b[32mprocessed\u001b[31m 500001 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 1000000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 1500000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 2000000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 2500001 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 3000000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 3500000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 4000000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 4500000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 5000000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 5500000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 6000000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 6500000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 7000000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 7500000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 8000000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 8500000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 9000000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 9500000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 10000000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 10500000 \u001b[32mfragments\u001b[0m\n",
      "hits: 10044872; hits per frag:  0.95734\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[00m[2026-01-05 19:30:56.043] [jointLog] [info] Thread saw mini-batch with a maximum of 0.44% zero probability fragments\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:30:56.048] [jointLog] [info] Thread saw mini-batch with a maximum of 0.38% zero probability fragments\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:30:56.054] [jointLog] [info] Thread saw mini-batch with a maximum of 0.40% zero probability fragments\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:30:56.059] [jointLog] [info] Thread saw mini-batch with a maximum of 0.38% zero probability fragments\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:30:56.075] [jointLog] [info] Computed 4603 rich equivalence classes for further processing\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:30:56.075] [jointLog] [info] Counted 10430229 total reads in the equivalence classes \n",
      "\u001b[00m\u001b[00m[2026-01-05 19:30:56.078] [jointLog] [info] Number of mappings discarded because of alignment score : 196911\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:30:56.078] [jointLog] [info] Number of fragments entirely discarded because of alignment score : 150464\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:30:56.078] [jointLog] [info] Number of fragments discarded because they are best-mapped to decoys : 70684\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:30:56.078] [jointLog] [info] Number of fragments discarded because they have only dovetail (discordant) mappings to valid targets : 0\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:30:56.078] [jointLog] [info] Mapping rate = 95.4759%\n",
      "\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:30:56.078] [jointLog] [info] finished quantifyLibrary()\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:30:56.078] [jointLog] [info] Starting optimizer\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:30:56.081] [jointLog] [info] Marked 0 weighted equivalence classes as degenerate\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:30:56.081] [jointLog] [info] iteration = 0 | max rel diff. = 1673.88\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:30:56.117] [jointLog] [info] iteration = 100 | max rel diff. = 1.61128e-16\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:30:56.117] [jointLog] [info] Finished optimizer\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:30:56.117] [jointLog] [info] writing output \n",
      "\n",
      "\u001b[00mVersion Server Response: Not Found\n",
      "### salmon (selective-alignment-based) v1.10.3\n",
      "### [ program ] => salmon \n",
      "### [ command ] => quant \n",
      "### [ index ] => { data/reference/transcriptome_index }\n",
      "### [ libType ] => { SR }\n",
      "### [ unmatedReads ] => { data/trimmed/SRR13349126_1_trimmed.fastq.gz }\n",
      "### [ threads ] => { 4 }\n",
      "### [ validateMappings ] => { }\n",
      "### [ output ] => { data/quants/SRR13349126_quant }\n",
      "Logs will be written to data/quants/SRR13349126_quant/logs\n",
      "\u001b[00m[2026-01-05 19:30:56.476] [jointLog] [info] setting maxHashResizeThreads to 4\n",
      "\u001b[00m-----------------------------------------\n",
      "| Loading contig table | Time = 1.0533 ms\n",
      "-----------------------------------------\n",
      "size = 10477\n",
      "\u001b[00m[2026-01-05 19:30:56.476] [jointLog] [info] Fragment incompatibility prior below threshold.  Incompatible fragments will be ignored.\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:30:56.476] [jointLog] [info] Usage of --validateMappings implies use of minScoreFraction. Since not explicitly specified, it is being set to 0.65\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:30:56.476] [jointLog] [info] Setting consensusSlack to selective-alignment default of 0.35.\n",
      "\u001b[00m\u001b[00m-----------------------------------------\n",
      "| Loading contig offsets | Time = 290.5 us\n",
      "-----------------------------------------\n",
      "[2026-01-05 19:30:56.476] [jointLog] [info] parsing read library format\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:30:56.476] [jointLog] [info] There is 1 library.\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:30:56.476] [jointLog] [info] Loading pufferfish index\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:30:56.476] [jointLog] [info] Loading dense pufferfish index.\n",
      "\u001b[00m-----------------------------------------\n",
      "| Loading reference lengths | Time = 22.024 us\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| Loading mphf table | Time = 3.1015 ms\n",
      "-----------------------------------------\n",
      "size = 5331843\n",
      "Number of ones: 10476\n",
      "Number of ones per inventory item: 512\n",
      "Inventory entries filled: 21\n",
      "-----------------------------------------\n",
      "| Loading contig boundaries | Time = 9.725 ms\n",
      "-----------------------------------------\n",
      "size = 5331843\n",
      "-----------------------------------------\n",
      "| Loading sequence | Time = 1.3802 ms\n",
      "-----------------------------------------\n",
      "size = 5017563\n",
      "-----------------------------------------\n",
      "| Loading positions | Time = 11.905 ms\n",
      "-----------------------------------------\n",
      "size = 9697527\n",
      "-----------------------------------------\n",
      "| Loading reference sequence | Time = 2.169 ms\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| Loading reference accumulative lengths | Time = 34.99 us\n",
      "-----------------------------------------\n",
      "\u001b[00m[2026-01-05 19:30:56.506] [jointLog] [info] done\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:30:56.558] [jointLog] [info] Index contained 4930 targets\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:30:56.559] [jointLog] [info] Number of decoys : 1\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:30:56.559] [jointLog] [info] First decoy index : 4929 \n",
      "\u001b[00m\n",
      "\n",
      "\n",
      "\n",
      "\u001b[32mprocessed\u001b[31m 500001 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 1000002 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 1500000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 2000000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 2500000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 3000000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 3500000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 4000000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 4500000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 5000001 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 5500000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 6000001 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 6500000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 7000000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 7500000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 8000000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 8500000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 9000000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 9500000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 10000000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 10500000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 11000000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 11500002 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 12000000 \u001b[32mfragments\u001b[0m\n",
      "hits: 11496342; hits per frag:  0.95944\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[00m[2026-01-05 19:31:19.741] [jointLog] [info] Thread saw mini-batch with a maximum of 0.28% zero probability fragments\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:31:19.754] [jointLog] [info] Thread saw mini-batch with a maximum of 0.26% zero probability fragments\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:31:19.757] [jointLog] [info] Thread saw mini-batch with a maximum of 0.26% zero probability fragments\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:31:19.761] [jointLog] [info] Thread saw mini-batch with a maximum of 0.34% zero probability fragments\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:31:19.778] [jointLog] [info] Computed 4603 rich equivalence classes for further processing\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:31:19.778] [jointLog] [info] Counted 11716642 total reads in the equivalence classes \n",
      "\u001b[00m\u001b[00m[2026-01-05 19:31:19.780] [jointLog] [info] Number of mappings discarded because of alignment score : 193327\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:31:19.780] [jointLog] [info] Number of fragments entirely discarded because of alignment score : 145099\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:31:19.780] [jointLog] [info] Number of fragments discarded because they are best-mapped to decoys : 65435\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:31:19.780] [jointLog] [info] Number of fragments discarded because they have only dovetail (discordant) mappings to valid targets : 0\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:31:19.780] [jointLog] [info] Mapping rate = 95.6616%\n",
      "\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:31:19.780] [jointLog] [info] finished quantifyLibrary()\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:31:19.781] [jointLog] [info] Starting optimizer\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:31:19.783] [jointLog] [info] Marked 0 weighted equivalence classes as degenerate\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:31:19.783] [jointLog] [info] iteration = 0 | max rel diff. = 1836.4\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:31:19.815] [jointLog] [info] iteration = 100 | max rel diff. = 0\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:31:19.815] [jointLog] [info] Finished optimizer\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:31:19.815] [jointLog] [info] writing output \n",
      "\n",
      "\u001b[00mVersion Server Response: Not Found\n",
      "### salmon (selective-alignment-based) v1.10.3\n",
      "### [ program ] => salmon \n",
      "### [ command ] => quant \n",
      "### [ index ] => { data/reference/transcriptome_index }\n",
      "### [ libType ] => { SR }\n",
      "### [ unmatedReads ] => { data/trimmed/SRR13349127_1_trimmed.fastq.gz }\n",
      "### [ threads ] => { 4 }\n",
      "### [ validateMappings ] => { }\n",
      "### [ output ] => { data/quants/SRR13349127_quant }\n",
      "Logs will be written to data/quants/SRR13349127_quant/logs\n",
      "\u001b[00m[2026-01-05 19:31:20.584] [jointLog] [info] setting maxHashResizeThreads to 4\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:31:20.584] [jointLog] [info] Fragment incompatibility prior below threshold.  Incompatible fragments will be ignored.\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:31:20.584] [jointLog] [info] Usage of --validateMappings implies use of minScoreFraction. Since not explicitly specified, it is being set to 0.65\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:31:20.584] [jointLog] [info] Setting consensusSlack to selective-alignment default of 0.35.\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:31:20.584] [jointLog] [info] parsing read library format\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:31:20.584] [jointLog] [info] There is 1 library.\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:31:20.584] [jointLog] [info] Loading pufferfish index\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:31:20.584] [jointLog] [info] Loading dense pufferfish index.\n",
      "\u001b[00m-----------------------------------------\n",
      "| Loading contig table | Time = 1.1736 ms\n",
      "-----------------------------------------\n",
      "size = 10477\n",
      "-----------------------------------------\n",
      "| Loading contig offsets | Time = 125.73 us\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| Loading reference lengths | Time = 22.423 us\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| Loading mphf table | Time = 3.2961 ms\n",
      "-----------------------------------------\n",
      "size = 5331843\n",
      "Number of ones: 10476\n",
      "Number of ones per inventory item: 512\n",
      "Inventory entries filled: 21\n",
      "-----------------------------------------\n",
      "| Loading contig boundaries | Time = 9.9943 ms\n",
      "-----------------------------------------\n",
      "size = 5331843\n",
      "-----------------------------------------\n",
      "| Loading sequence | Time = 1.2654 ms\n",
      "-----------------------------------------\n",
      "size = 5017563\n",
      "-----------------------------------------\n",
      "| Loading positions | Time = 12.411 ms\n",
      "-----------------------------------------\n",
      "size = 9697527\n",
      "-----------------------------------------\n",
      "| Loading reference sequence | Time = 2.1926 ms\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| Loading reference accumulative lengths | Time = 40.721 us\n",
      "-----------------------------------------\n",
      "\u001b[00m[2026-01-05 19:31:20.615] [jointLog] [info] done\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:31:20.667] [jointLog] [info] Index contained 4930 targets\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:31:20.668] [jointLog] [info] Number of decoys : 1\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:31:20.668] [jointLog] [info] First decoy index : 4929 \n",
      "\u001b[00m\n",
      "\n",
      "\n",
      "\n",
      "\u001b[32mprocessed\u001b[31m 500000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 1000000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 1500000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 2000000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 2500001 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 3000000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 3500000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 4000000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 4500000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 5000000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 6000001 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 6500000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 7000000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 7500000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 8000000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 8500000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 8500068 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 9000000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 9500000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 10000000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 10500000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 11000000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 11500001 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 12000000 \u001b[32mfragments\u001b[0m\n",
      "hits: 11556281; hits per frag:  0.964755\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[00m[2026-01-05 19:31:42.814] [jointLog] [info] Thread saw mini-batch with a maximum of 0.38% zero probability fragments\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:31:42.819] [jointLog] [info] Thread saw mini-batch with a maximum of 0.36% zero probability fragments\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:31:42.821] [jointLog] [info] Thread saw mini-batch with a maximum of 0.38% zero probability fragments\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:31:42.831] [jointLog] [info] Thread saw mini-batch with a maximum of 0.38% zero probability fragments\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:31:42.848] [jointLog] [info] Computed 4647 rich equivalence classes for further processing\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:31:42.848] [jointLog] [info] Counted 12003568 total reads in the equivalence classes \n",
      "\u001b[00m\u001b[00m[2026-01-05 19:31:42.851] [jointLog] [info] Number of mappings discarded because of alignment score : 194722\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:31:42.851] [jointLog] [info] Number of fragments entirely discarded because of alignment score : 150561\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:31:42.851] [jointLog] [info] Number of fragments discarded because they are best-mapped to decoys : 71169\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:31:42.851] [jointLog] [info] Number of fragments discarded because they have only dovetail (discordant) mappings to valid targets : 0\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:31:42.851] [jointLog] [info] Mapping rate = 96.1396%\n",
      "\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:31:42.851] [jointLog] [info] finished quantifyLibrary()\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:31:42.851] [jointLog] [info] Starting optimizer\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:31:42.854] [jointLog] [info] Marked 0 weighted equivalence classes as degenerate\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:31:42.854] [jointLog] [info] iteration = 0 | max rel diff. = 3700.78\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:31:42.894] [jointLog] [info] iteration = 100 | max rel diff. = 0\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:31:42.895] [jointLog] [info] Finished optimizer\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:31:42.895] [jointLog] [info] writing output \n",
      "\n",
      "\u001b[00mVersion Server Response: Not Found\n",
      "### salmon (selective-alignment-based) v1.10.3\n",
      "### [ program ] => salmon \n",
      "### [ command ] => quant \n",
      "### [ index ] => { data/reference/transcriptome_index }\n",
      "### [ libType ] => { SR }\n",
      "### [ unmatedReads ] => { data/trimmed/SRR13349128_1_trimmed.fastq.gz }\n",
      "### [ threads ] => { 4 }\n",
      "### [ validateMappings ] => { }\n",
      "### [ output ] => { data/quants/SRR13349128_quant }\n",
      "Logs will be written to data/quants/SRR13349128_quant/logs\n",
      "\u001b[00m[2026-01-05 19:31:43.667] [jointLog] [info] setting maxHashResizeThreads to 4\n",
      "\u001b[00m-----------------------------------------\n",
      "| Loading contig table | Time = 1.0126 ms\n",
      "-----------------------------------------\n",
      "\u001b[00m[2026-01-05 19:31:43.667] [jointLog] [info] Fragment incompatibility prior below threshold.  Incompatible fragments will be ignored.\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:31:43.667] [jointLog] [info] Usage of --validateMappings implies use of minScoreFraction. Since not explicitly specified, it is being set to 0.65\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:31:43.667] [jointLog] [info] Setting consensusSlack to selective-alignment default of 0.35.\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:31:43.667] [jointLog] [info] parsing read library format\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:31:43.667] [jointLog] [info] There is 1 library.\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:31:43.667] [jointLog] [info] Loading pufferfish index\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:31:43.667] [jointLog] [info] Loading dense pufferfish index.\n",
      "\u001b[00msize = 10477\n",
      "-----------------------------------------\n",
      "| Loading contig offsets | Time = 116.22 us\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| Loading reference lengths | Time = 21.933 us\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| Loading mphf table | Time = 3.0143 ms\n",
      "-----------------------------------------\n",
      "size = 5331843\n",
      "Number of ones: 10476\n",
      "Number of ones per inventory item: 512\n",
      "Inventory entries filled: 21\n",
      "-----------------------------------------\n",
      "| Loading contig boundaries | Time = 9.4168 ms\n",
      "-----------------------------------------\n",
      "size = 5331843\n",
      "-----------------------------------------\n",
      "| Loading sequence | Time = 1.2511 ms\n",
      "-----------------------------------------\n",
      "size = 5017563\n",
      "-----------------------------------------\n",
      "| Loading positions | Time = 12.579 ms\n",
      "-----------------------------------------\n",
      "size = 9697527\n",
      "-----------------------------------------\n",
      "| Loading reference sequence | Time = 2.4093 ms\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| Loading reference accumulative lengths | Time = 41.117 us\n",
      "-----------------------------------------\n",
      "\u001b[00m[2026-01-05 19:31:43.697] [jointLog] [info] done\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:31:43.752] [jointLog] [info] Index contained 4930 targets\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:31:43.752] [jointLog] [info] Number of decoys : 1\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:31:43.752] [jointLog] [info] First decoy index : 4929 \n",
      "\u001b[00m\n",
      "\n",
      "\n",
      "\n",
      "\u001b[32mprocessed\u001b[31m 500000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 1000001 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 1500001 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 2000000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 2500000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 3000001 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 3500000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 4000001 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 4500000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 5000000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 5500001 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 6000000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 6500000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 7000000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 7500000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 8000000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 8500000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 9000000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 9500000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 10000000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 10500000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 11000001 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 11500000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 12000000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 12500000 \u001b[32mfragments\u001b[0m\n",
      "hits: 11844661; hits per frag:  0.94844\u001b[00m[2026-01-05 19:32:07.473] [jointLog] [info] Thread saw mini-batch with a maximum of 0.32% zero probability fragments\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:32:07.483] [jointLog] [info] Thread saw mini-batch with a maximum of 0.26% zero probability fragments\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:32:07.483] [jointLog] [info] Thread saw mini-batch with a maximum of 0.30% zero probability fragments\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:32:07.485] [jointLog] [info] Thread saw mini-batch with a maximum of 0.28% zero probability fragments\n",
      "\u001b[00m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[00m[2026-01-05 19:32:07.505] [jointLog] [info] Computed 4534 rich equivalence classes for further processing\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:32:07.505] [jointLog] [info] Counted 11952992 total reads in the equivalence classes \n",
      "\u001b[00m\u001b[00m[2026-01-05 19:32:07.509] [jointLog] [info] Number of mappings discarded because of alignment score : 447724\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:32:07.509] [jointLog] [info] Number of fragments entirely discarded because of alignment score : 260225\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:32:07.509] [jointLog] [info] Number of fragments discarded because they are best-mapped to decoys : 48798\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:32:07.509] [jointLog] [info] Number of fragments discarded because they have only dovetail (discordant) mappings to valid targets : 0\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:32:07.509] [jointLog] [info] Mapping rate = 94.6249%\n",
      "\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:32:07.509] [jointLog] [info] finished quantifyLibrary()\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:32:07.510] [jointLog] [info] Starting optimizer\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:32:07.513] [jointLog] [info] Marked 0 weighted equivalence classes as degenerate\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:32:07.513] [jointLog] [info] iteration = 0 | max rel diff. = 1844.9\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:32:07.549] [jointLog] [info] iteration = 100 | max rel diff. = 1.45601e-16\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:32:07.550] [jointLog] [info] Finished optimizer\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:32:07.550] [jointLog] [info] writing output \n",
      "\n",
      "\u001b[00mVersion Server Response: Not Found\n",
      "### salmon (selective-alignment-based) v1.10.3\n",
      "### [ program ] => salmon \n",
      "### [ command ] => quant \n",
      "### [ index ] => { data/reference/transcriptome_index }\n",
      "### [ libType ] => { SR }\n",
      "### [ unmatedReads ] => { data/trimmed/SRR13349129_1_trimmed.fastq.gz }\n",
      "### [ threads ] => { 4 }\n",
      "### [ validateMappings ] => { }\n",
      "### [ output ] => { data/quants/SRR13349129_quant }\n",
      "Logs will be written to data/quants/SRR13349129_quant/logs\n",
      "\u001b[00m[2026-01-05 19:32:08.300] [jointLog] [info] setting maxHashResizeThreads to 4\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:32:08.300] [jointLog] [info] Fragment incompatibility prior below threshold.  Incompatible fragments will be ignored.\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:32:08.300] [jointLog] [info] Usage of --validateMappings implies use of minScoreFraction. Since not explicitly specified, it is being set to 0.65\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:32:08.300] [jointLog] [info] Setting consensusSlack to selective-alignment default of 0.35.\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:32:08.300] [jointLog] [info] parsing read library format\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:32:08.300] [jointLog] [info] There is 1 library.\n",
      "\u001b[00m\u001b[00m-----------------------------------------\n",
      "| Loading contig table | Time = 1.1247 ms\n",
      "-----------------------------------------[2026-01-05 19:32:08.300] [jointLog] [info] Loading pufferfish index\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:32:08.300] [jointLog] [info] Loading dense pufferfish index.\n",
      "\u001b[00m\n",
      "size = 10477\n",
      "-----------------------------------------\n",
      "| Loading contig offsets | Time = 109.85 us\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| Loading reference lengths | Time = 22.21 us\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| Loading mphf table | Time = 2.8798 ms\n",
      "-----------------------------------------\n",
      "size = 5331843\n",
      "Number of ones: 10476\n",
      "Number of ones per inventory item: 512\n",
      "Inventory entries filled: 21\n",
      "-----------------------------------------\n",
      "| Loading contig boundaries | Time = 9.6832 ms\n",
      "-----------------------------------------\n",
      "size = 5331843\n",
      "-----------------------------------------\n",
      "| Loading sequence | Time = 1.2968 ms\n",
      "-----------------------------------------\n",
      "size = 5017563\n",
      "-----------------------------------------\n",
      "| Loading positions | Time = 12.376 ms\n",
      "-----------------------------------------\n",
      "size = 9697527\n",
      "-----------------------------------------\n",
      "| Loading reference sequence | Time = 2.1661 ms\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| Loading reference accumulative lengths | Time = 37.826 us\n",
      "-----------------------------------------\n",
      "\u001b[00m[2026-01-05 19:32:08.330] [jointLog] [info] done\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:32:08.380] [jointLog] [info] Index contained 4930 targets\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:32:08.380] [jointLog] [info] Number of decoys : 1\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:32:08.380] [jointLog] [info] First decoy index : 4929 \n",
      "\u001b[00m\n",
      "\n",
      "\n",
      "\n",
      "\u001b[32mprocessed\u001b[31m 500001 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 1000000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 1500000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 2000001 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 2500000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 3000000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 3500000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 4000001 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 4500000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 4500024 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 5000000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 5500000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 6000000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 6500000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 7000000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 7500000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 8000000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 8500000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 9000000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 9500000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 10000000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 10500000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 11000000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 11500000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 12000000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 12500000 \u001b[32mfragments\u001b[0m\n",
      "hits: 11907765; hits per frag:  0.953901\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[00m[2026-01-05 19:32:31.219] [jointLog] [info] Thread saw mini-batch with a maximum of 0.32% zero probability fragments\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:32:31.224] [jointLog] [info] Thread saw mini-batch with a maximum of 0.36% zero probability fragments\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:32:31.228] [jointLog] [info] Thread saw mini-batch with a maximum of 0.32% zero probability fragments\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:32:31.234] [jointLog] [info] Thread saw mini-batch with a maximum of 0.36% zero probability fragments\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:32:31.249] [jointLog] [info] Computed 4585 rich equivalence classes for further processing\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:32:31.249] [jointLog] [info] Counted 12252032 total reads in the equivalence classes \n",
      "\u001b[00m\u001b[00m[2026-01-05 19:32:31.252] [jointLog] [info] Number of mappings discarded because of alignment score : 448162\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:32:31.252] [jointLog] [info] Number of fragments entirely discarded because of alignment score : 265450\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:32:31.252] [jointLog] [info] Number of fragments discarded because they are best-mapped to decoys : 55199\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:32:31.252] [jointLog] [info] Number of fragments discarded because they have only dovetail (discordant) mappings to valid targets : 0\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:32:31.252] [jointLog] [info] Mapping rate = 95.1102%\n",
      "\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:32:31.252] [jointLog] [info] finished quantifyLibrary()\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:32:31.252] [jointLog] [info] Starting optimizer\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:32:31.254] [jointLog] [info] Marked 0 weighted equivalence classes as degenerate\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:32:31.254] [jointLog] [info] iteration = 0 | max rel diff. = 3752.46\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:32:31.289] [jointLog] [info] iteration = 100 | max rel diff. = 0\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:32:31.289] [jointLog] [info] Finished optimizer\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:32:31.289] [jointLog] [info] writing output \n",
      "\n",
      "\u001b[00mVersion Server Response: Not Found\n",
      "### salmon (selective-alignment-based) v1.10.3\n",
      "### [ program ] => salmon \n",
      "### [ command ] => quant \n",
      "### [ index ] => { data/reference/transcriptome_index }\n",
      "### [ libType ] => { SR }\n",
      "### [ unmatedReads ] => { data/trimmed/SRR13349130_1_trimmed.fastq.gz }\n",
      "### [ threads ] => { 4 }\n",
      "### [ validateMappings ] => { }\n",
      "### [ output ] => { data/quants/SRR13349130_quant }\n",
      "Logs will be written to data/quants/SRR13349130_quant/logs\n",
      "\u001b[00m[2026-01-05 19:32:31.643] [jointLog] [info] setting maxHashResizeThreads to 4\n",
      "\u001b[00m-----------------------------------------\n",
      "| Loading contig table | Time = 1.051 ms\n",
      "-----------------------------------------\n",
      "\u001b[00m[2026-01-05 19:32:31.643] [jointLog] [info] Fragment incompatibility prior below threshold.  Incompatible fragments will be ignored.\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:32:31.643] [jointLog] [info] Usage of --validateMappings implies use of minScoreFraction. Since not explicitly specified, it is being set to 0.65\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:32:31.643] [jointLog] [info] Setting consensusSlack to selective-alignment default of 0.35.\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:32:31.643] [jointLog] [info] parsing read library format\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:32:31.643] [jointLog] [info] There is 1 library.\n",
      "size = \u001b[00m\u001b[00m[2026-01-05 19:32:31.643] [jointLog] [info] Loading pufferfish index\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:32:31.643] [jointLog] [info] Loading dense pufferfish index.\n",
      "\u001b[00m10477\n",
      "-----------------------------------------\n",
      "| Loading contig offsets | Time = 382.82 us\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| Loading reference lengths | Time = 20.656 us\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| Loading mphf table | Time = 2.9497 ms\n",
      "-----------------------------------------\n",
      "size = 5331843\n",
      "Number of ones: 10476\n",
      "Number of ones per inventory item: 512\n",
      "Inventory entries filled: 21\n",
      "-----------------------------------------\n",
      "| Loading contig boundaries | Time = 9.8245 ms\n",
      "-----------------------------------------\n",
      "size = 5331843\n",
      "-----------------------------------------\n",
      "| Loading sequence | Time = 1.3188 ms\n",
      "-----------------------------------------\n",
      "size = 5017563\n",
      "-----------------------------------------\n",
      "| Loading positions | Time = 12.579 ms\n",
      "-----------------------------------------\n",
      "size = 9697527\n",
      "-----------------------------------------\n",
      "| Loading reference sequence | Time = 2.2899 ms\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| Loading reference accumulative lengths | Time = 40.832 us\n",
      "-----------------------------------------\n",
      "\u001b[00m[2026-01-05 19:32:31.674] [jointLog] [info] done\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:32:31.723] [jointLog] [info] Index contained 4930 targets\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:32:31.724] [jointLog] [info] Number of decoys : 1\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:32:31.724] [jointLog] [info] First decoy index : 4929 \n",
      "\u001b[00m\n",
      "\n",
      "\n",
      "\n",
      "\u001b[32mprocessed\u001b[31m 500000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 1000000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 1500000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 2000000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 2500001 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 3000000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 3500000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 4000000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 4500000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 5000000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 5500000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 6000000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 6500000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 7000000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 7500001 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 8000000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 8500000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 9000000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 9500000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 10000001 \u001b[32mfragments\u001b[0m\n",
      "hits: 9581316; hits per frag:  0.96089\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[00m[2026-01-05 19:32:50.797] [jointLog] [info] Thread saw mini-batch with a maximum of 0.34% zero probability fragments\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:32:50.801] [jointLog] [info] Thread saw mini-batch with a maximum of 0.34% zero probability fragments\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:32:50.804] [jointLog] [info] Thread saw mini-batch with a maximum of 0.38% zero probability fragments\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:32:50.810] [jointLog] [info] Thread saw mini-batch with a maximum of 0.36% zero probability fragments\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:32:50.826] [jointLog] [info] Computed 4500 rich equivalence classes for further processing\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:32:50.826] [jointLog] [info] Counted 9629520 total reads in the equivalence classes \n",
      "\u001b[00m\u001b[00m[2026-01-05 19:32:50.829] [jointLog] [info] Number of mappings discarded because of alignment score : 167693\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:32:50.829] [jointLog] [info] Number of fragments entirely discarded because of alignment score : 116098\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:32:50.829] [jointLog] [info] Number of fragments discarded because they are best-mapped to decoys : 44250\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:32:50.829] [jointLog] [info] Number of fragments discarded because they have only dovetail (discordant) mappings to valid targets : 0\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:32:50.829] [jointLog] [info] Mapping rate = 95.6536%\n",
      "\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:32:50.829] [jointLog] [info] finished quantifyLibrary()\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:32:50.829] [jointLog] [info] Starting optimizer\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:32:50.832] [jointLog] [info] Marked 0 weighted equivalence classes as degenerate\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:32:50.832] [jointLog] [info] iteration = 0 | max rel diff. = 1576.58\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:32:50.865] [jointLog] [info] iteration = 100 | max rel diff. = 2.04199e-16\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:32:50.865] [jointLog] [info] Finished optimizer\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:32:50.865] [jointLog] [info] writing output \n",
      "\n",
      "\u001b[00mVersion Server Response: Not Found\n",
      "### salmon (selective-alignment-based) v1.10.3\n",
      "### [ program ] => salmon \n",
      "### [ command ] => quant \n",
      "### [ index ] => { data/reference/transcriptome_index }\n",
      "### [ libType ] => { SR }\n",
      "### [ unmatedReads ] => { data/trimmed/SRR13349131_1_trimmed.fastq.gz }\n",
      "### [ threads ] => { 4 }\n",
      "### [ validateMappings ] => { }\n",
      "### [ output ] => { data/quants/SRR13349131_quant }\n",
      "Logs will be written to data/quants/SRR13349131_quant/logs\n",
      "\u001b[00m[2026-01-05 19:32:51.680] [jointLog] [info] setting maxHashResizeThreads to 4\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:32:51.680] [jointLog] [info] Fragment incompatibility prior below threshold.  Incompatible fragments will be ignored.\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:32:51.680] [jointLog] [info] Usage of --validateMappings implies use of minScoreFraction. Since not explicitly specified, it is being set to 0.65\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:32:51.680] [jointLog] [info] Setting consensusSlack to selective-alignment default of 0.35.\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:32:51.680] [jointLog] [info] parsing read library format\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:32:51.680] [jointLog] [info] There is 1 library.\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:32:51.680] [jointLog] [info] Loading pufferfish index\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:32:51.680] [jointLog] [info] Loading dense pufferfish index.\n",
      "\u001b[00m-----------------------------------------\n",
      "| Loading contig table | Time = 1.148 ms\n",
      "-----------------------------------------\n",
      "size = 10477\n",
      "-----------------------------------------\n",
      "| Loading contig offsets | Time = 118.04 us\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| Loading reference lengths | Time = 23.064 us\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| Loading mphf table | Time = 2.9711 ms\n",
      "-----------------------------------------\n",
      "size = 5331843\n",
      "Number of ones: 10476\n",
      "Number of ones per inventory item: 512\n",
      "Inventory entries filled: 21\n",
      "-----------------------------------------\n",
      "| Loading contig boundaries | Time = 10.321 ms\n",
      "-----------------------------------------\n",
      "size = 5331843\n",
      "-----------------------------------------\n",
      "| Loading sequence | Time = 1.2129 ms\n",
      "-----------------------------------------\n",
      "size = 5017563\n",
      "-----------------------------------------\n",
      "| Loading positions | Time = 12.239 ms\n",
      "-----------------------------------------\n",
      "size = 9697527\n",
      "-----------------------------------------\n",
      "| Loading reference sequence | Time = 2.1223 ms\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| Loading reference accumulative lengths | Time = 41.956 us\n",
      "-----------------------------------------\n",
      "\u001b[00m[2026-01-05 19:32:51.710] [jointLog] [info] done\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:32:51.767] [jointLog] [info] Index contained 4930 targets\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:32:51.768] [jointLog] [info] Number of decoys : 1\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:32:51.768] [jointLog] [info] First decoy index : 4929 \n",
      "\u001b[00m\n",
      "\n",
      "\n",
      "\n",
      "\u001b[32mprocessed\u001b[31m 500001 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 1000000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 1500001 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 2000001 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 2500000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 3000000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 3500000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 4000000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 4500000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 5000001 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 5500000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 6000000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 6500000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 7000000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 7500001 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 8000000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 8500000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 9000000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 9500000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 10000000 \u001b[32mfragments\u001b[0m\n",
      "hits: 9636515; hits per frag:  0.965842\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[00m[2026-01-05 19:33:12.640] [jointLog] [info] Thread saw mini-batch with a maximum of 0.36% zero probability fragments\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:33:12.644] [jointLog] [info] Thread saw mini-batch with a maximum of 0.36% zero probability fragments\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:33:12.652] [jointLog] [info] Thread saw mini-batch with a maximum of 0.38% zero probability fragments\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:33:12.654] [jointLog] [info] Thread saw mini-batch with a maximum of 0.36% zero probability fragments\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:33:12.671] [jointLog] [info] Computed 4565 rich equivalence classes for further processing\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:33:12.671] [jointLog] [info] Counted 10028999 total reads in the equivalence classes \n",
      "\u001b[00m\u001b[00m[2026-01-05 19:33:12.674] [jointLog] [info] Number of mappings discarded because of alignment score : 173163\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:33:12.674] [jointLog] [info] Number of fragments entirely discarded because of alignment score : 123715\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:33:12.674] [jointLog] [info] Number of fragments discarded because they are best-mapped to decoys : 50444\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:33:12.674] [jointLog] [info] Number of fragments discarded because they have only dovetail (discordant) mappings to valid targets : 0\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:33:12.674] [jointLog] [info] Mapping rate = 96.1812%\n",
      "\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:33:12.674] [jointLog] [info] finished quantifyLibrary()\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:33:12.674] [jointLog] [info] Starting optimizer\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:33:12.676] [jointLog] [info] Marked 0 weighted equivalence classes as degenerate\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:33:12.677] [jointLog] [info] iteration = 0 | max rel diff. = 1625.87\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:33:12.711] [jointLog] [info] iteration = 100 | max rel diff. = 1.38559e-16\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:33:12.711] [jointLog] [info] Finished optimizer\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:33:12.711] [jointLog] [info] writing output \n",
      "\n",
      "\u001b[00mVersion Server Response: Not Found\n",
      "### salmon (selective-alignment-based) v1.10.3\n",
      "### [ program ] => salmon \n",
      "### [ command ] => quant \n",
      "### [ index ] => { data/reference/transcriptome_index }\n",
      "### [ libType ] => { SR }\n",
      "### [ unmatedReads ] => { data/trimmed/SRR13349132_1_trimmed.fastq.gz }\n",
      "### [ threads ] => { 4 }\n",
      "### [ validateMappings ] => { }\n",
      "### [ output ] => { data/quants/SRR13349132_quant }\n",
      "Logs will be written to data/quants/SRR13349132_quant/logs\n",
      "\u001b[00m[2026-01-05 19:33:13.077] [jointLog] [info] setting maxHashResizeThreads to 4\n",
      "\u001b[00m-----------------------------------------\n",
      "| Loading contig table | Time = 1.052 ms\n",
      "-----------------------------------------\n",
      "size = 10477\n",
      "\u001b[00m[2026-01-05 19:33:13.077] [jointLog] [info] Fragment incompatibility prior below threshold.  Incompatible fragments will be ignored.\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:33:13.077] [jointLog] [info] Usage of --validateMappings implies use of minScoreFraction. Since not explicitly specified, it is being set to 0.65\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:33:13.077] [jointLog] [info] Setting consensusSlack to selective-alignment default of 0.35.\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:33:13.077] [jointLog] [info] parsing read library format\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:33:13.077] [jointLog] [info] There is 1 library.\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:33:13.077] [jointLog] [info] Loading pufferfish index\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:33:13.077] [jointLog] [info] Loading dense pufferfish index.\n",
      "\u001b[00m-----------------------------------------\n",
      "| Loading contig offsets | Time = 177.91 us\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| Loading reference lengths | Time = 18.791 us\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| Loading mphf table | Time = 3.3489 ms\n",
      "-----------------------------------------\n",
      "size = 5331843\n",
      "Number of ones: 10476\n",
      "Number of ones per inventory item: 512\n",
      "Inventory entries filled: 21\n",
      "-----------------------------------------\n",
      "| Loading contig boundaries | Time = 9.7569 ms\n",
      "-----------------------------------------\n",
      "size = 5331843\n",
      "-----------------------------------------\n",
      "| Loading sequence | Time = 1.2797 ms\n",
      "-----------------------------------------\n",
      "size = 5017563\n",
      "-----------------------------------------\n",
      "| Loading positions | Time = 12.32 ms\n",
      "-----------------------------------------\n",
      "size = 9697527\n",
      "-----------------------------------------\n",
      "| Loading reference sequence | Time = 2.3849 ms\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| Loading reference accumulative lengths | Time = 42.821 us\n",
      "-----------------------------------------\n",
      "\u001b[00m[2026-01-05 19:33:13.108] [jointLog] [info] done\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:33:13.161] [jointLog] [info] Index contained 4930 targets\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:33:13.162] [jointLog] [info] Number of decoys : 1\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:33:13.162] [jointLog] [info] First decoy index : 4929 \n",
      "\u001b[00m\n",
      "\n",
      "\n",
      "\n",
      "\u001b[32mprocessed\u001b[31m 500000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 1000000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 1500001 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 2000000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 2500000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 3000000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 3500000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 4000000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 4500000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 5000000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 5500000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 6000000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 6500000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 7000001 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 7500000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 8000000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 8500000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 9000000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 9500001 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 10000000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 10500000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 11000000 \u001b[32mfragments\u001b[0m\n",
      "hits: 10525154; hits per frag:  0.958383\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[00m[2026-01-05 19:33:34.178] [jointLog] [info] Thread saw mini-batch with a maximum of 0.36% zero probability fragments\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:33:34.186] [jointLog] [info] Thread saw mini-batch with a maximum of 0.38% zero probability fragments\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:33:34.188] [jointLog] [info] Thread saw mini-batch with a maximum of 0.38% zero probability fragments\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:33:34.193] [jointLog] [info] Thread saw mini-batch with a maximum of 0.38% zero probability fragments\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:33:34.209] [jointLog] [info] Computed 4590 rich equivalence classes for further processing\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:33:34.209] [jointLog] [info] Counted 10812351 total reads in the equivalence classes \n",
      "\u001b[00m\u001b[00m[2026-01-05 19:33:34.212] [jointLog] [info] Number of mappings discarded because of alignment score : 186516\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:33:34.212] [jointLog] [info] Number of fragments entirely discarded because of alignment score : 138089\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:33:34.212] [jointLog] [info] Number of fragments discarded because they are best-mapped to decoys : 62934\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:33:34.212] [jointLog] [info] Number of fragments discarded because they have only dovetail (discordant) mappings to valid targets : 0\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:33:34.212] [jointLog] [info] Mapping rate = 95.4894%\n",
      "\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:33:34.212] [jointLog] [info] finished quantifyLibrary()\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:33:34.212] [jointLog] [info] Starting optimizer\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:33:34.215] [jointLog] [info] Marked 0 weighted equivalence classes as degenerate\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:33:34.215] [jointLog] [info] iteration = 0 | max rel diff. = 1718.47\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:33:34.251] [jointLog] [info] iteration = 100 | max rel diff. = 2.28525e-16\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:33:34.251] [jointLog] [info] Finished optimizer\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:33:34.251] [jointLog] [info] writing output \n",
      "\n",
      "\u001b[00mVersion Server Response: Not Found\n",
      "### salmon (selective-alignment-based) v1.10.3\n",
      "### [ program ] => salmon \n",
      "### [ command ] => quant \n",
      "### [ index ] => { data/reference/transcriptome_index }\n",
      "### [ libType ] => { SR }\n",
      "### [ unmatedReads ] => { data/trimmed/SRR13349133_1_trimmed.fastq.gz }\n",
      "### [ threads ] => { 4 }\n",
      "### [ validateMappings ] => { }\n",
      "### [ output ] => { data/quants/SRR13349133_quant }\n",
      "Logs will be written to data/quants/SRR13349133_quant/logs\n",
      "\u001b[00m[2026-01-05 19:33:34.435] [jointLog] [info] setting maxHashResizeThreads to 4\n",
      "\u001b[00m-----------------------------------------\n",
      "| Loading contig table | Time = 1.0768 ms\n",
      "-----------------------------------------\n",
      "\u001b[00m[2026-01-05 19:33:34.435] [jointLog] [info] Fragment incompatibility prior below threshold.  Incompatible fragments will be ignored.\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:33:34.435] [jointLog] [info] Usage of --validateMappings implies use of minScoreFraction. Since not explicitly specified, it is being set to 0.65\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:33:34.435] [jointLog] [info] Setting consensusSlack to selective-alignment default of 0.35.\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:33:34.435] [jointLog] [info] parsing read library format\n",
      "\u001b[00msize = 10477\n",
      "\u001b[00m[2026-01-05 19:33:34.435] [jointLog] [info] There is 1 library.\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:33:34.435] [jointLog] [info] Loading pufferfish index\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:33:34.435] [jointLog] [info] Loading dense pufferfish index.\n",
      "\u001b[00m-----------------------------------------\n",
      "| Loading contig offsets | Time = 138.89 us\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| Loading reference lengths | Time = 24.109 us\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| Loading mphf table | Time = 3.196 ms\n",
      "-----------------------------------------\n",
      "size = 5331843\n",
      "Number of ones: 10476\n",
      "Number of ones per inventory item: 512\n",
      "Inventory entries filled: 21\n",
      "-----------------------------------------\n",
      "| Loading contig boundaries | Time = 9.886 ms\n",
      "-----------------------------------------\n",
      "size = 5331843\n",
      "-----------------------------------------\n",
      "| Loading sequence | Time = 1.3414 ms\n",
      "-----------------------------------------\n",
      "size = 5017563\n",
      "-----------------------------------------\n",
      "| Loading positions | Time = 12.809 ms\n",
      "-----------------------------------------\n",
      "size = 9697527\n",
      "-----------------------------------------\n",
      "| Loading reference sequence | Time = 2.17 ms\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| Loading reference accumulative lengths | Time = 36.806 us\n",
      "-----------------------------------------\n",
      "\u001b[00m[2026-01-05 19:33:34.467] [jointLog] [info] done\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:33:34.521] [jointLog] [info] Index contained 4930 targets\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:33:34.521] [jointLog] [info] Number of decoys : 1\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:33:34.521] [jointLog] [info] First decoy index : 4929 \n",
      "\u001b[00m\n",
      "\n",
      "\n",
      "\n",
      "\u001b[32mprocessed\u001b[31m 500000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 1000000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 1500000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 2000000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 2500000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 3000000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 3500000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 4000000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 4500000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 5000001 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 5500000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 6000001 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 6500000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 7000000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 7500000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 8000000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 8500000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 9000000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 9500001 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 10000000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 10500001 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 11000000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 11500000 \u001b[32mfragments\u001b[0m\n",
      "hits: 11059158; hits per frag:  0.962132\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[00m[2026-01-05 19:33:55.122] [jointLog] [info] Thread saw mini-batch with a maximum of 0.42% zero probability fragments\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:33:55.124] [jointLog] [info] Thread saw mini-batch with a maximum of 0.48% zero probability fragments\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:33:55.130] [jointLog] [info] Thread saw mini-batch with a maximum of 0.46% zero probability fragments\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:33:55.135] [jointLog] [info] Thread saw mini-batch with a maximum of 0.40% zero probability fragments\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:33:55.151] [jointLog] [info] Computed 4599 rich equivalence classes for further processing\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:33:55.151] [jointLog] [info] Counted 11061911 total reads in the equivalence classes \n",
      "\u001b[00m\u001b[00m[2026-01-05 19:33:55.154] [jointLog] [info] Number of mappings discarded because of alignment score : 188896\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:33:55.154] [jointLog] [info] Number of fragments entirely discarded because of alignment score : 145049\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:33:55.154] [jointLog] [info] Number of fragments discarded because they are best-mapped to decoys : 69979\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:33:55.154] [jointLog] [info] Number of fragments discarded because they have only dovetail (discordant) mappings to valid targets : 0\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:33:55.154] [jointLog] [info] Mapping rate = 95.9287%\n",
      "\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:33:55.154] [jointLog] [info] finished quantifyLibrary()\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:33:55.154] [jointLog] [info] Starting optimizer\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:33:55.156] [jointLog] [info] Marked 0 weighted equivalence classes as degenerate\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:33:55.156] [jointLog] [info] iteration = 0 | max rel diff. = 1746.96\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:33:55.193] [jointLog] [info] iteration = 100 | max rel diff. = 2.34058e-15\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:33:55.193] [jointLog] [info] Finished optimizer\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:33:55.193] [jointLog] [info] writing output \n",
      "\n",
      "\u001b[00m"
     ]
    }
   ],
   "source": [
    "! cat accs.txt | xargs -I {} salmon quant -i data/reference/transcriptome_index -l SR -r \"data/trimmed/{}_1_trimmed.fastq.gz\" -p $CORES --validateMappings -o \"data/quants/{}_quant\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 11: Report the top 10 most highly expressed genes in the samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Top 10 most highly expressed genes in each wild-type sample.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name\tLength\tEffectiveLength\tTPM\tNumReads\n",
      "rna-BB28_RS07080\t117\t3.947\t366585.841449\t16507.000\n",
      "rna-BB28_RS07075\t3114\t2864.000\t234607.889686\t7665021.000\n",
      "rna-BB28_RS07070\t1516\t1266.000\t130436.454701\t1883781.000\n",
      "rna-BB28_RS17330\t369\t119.000\t72495.625414\t98414.000\n",
      "gene-BB28_RS02220\t204\t9.377\t8366.788570\t895.000\n",
      "gene-BB28_RS20695\t231\t14.032\t6853.253254\t1097.000\n",
      "rna-BB28_RS09710\t405\t155.000\t5461.510957\t9657.000\n",
      "gene-BB28_RS18745\t300\t51.326\t3677.163924\t2153.000\n",
      "gene-BB28_RS18945\t222\t12.150\t3527.969159\t489.000\n",
      "gene-BB28_RS24750\t102\t3.543\t3389.529139\t137.000\n",
      "sort: write failed: 'standard output': Broken pipe\n",
      "sort: write error\n",
      "rna-BB28_RS07080\t117\t3.947\t348187.981351\t16529.000\n",
      "rna-BB28_RS07075\t3114\t2864.000\t224080.029008\t7718168.000\n",
      "rna-BB28_RS07070\t1516\t1266.000\t132514.469884\t2017600.000\n",
      "rna-BB28_RS17330\t369\t119.000\t76258.206854\t109137.000\n",
      "gene-BB28_RS02220\t204\t9.377\t8716.636540\t983.000\n",
      "gene-BB28_RS20695\t231\t14.032\t7306.558915\t1233.000\n",
      "rna-BB28_RS09710\t405\t155.000\t6220.151911\t11595.000\n",
      "gene-BB28_RS18745\t300\t51.326\t3995.045166\t2466.000\n",
      "gene-BB28_RS18945\t222\t12.150\t3770.745142\t551.000\n",
      "gene-BB28_RS24750\t102\t3.543\t3449.814950\t147.000\n",
      "sort: write failed: 'standard output': Broken pipe\n",
      "sort: write error\n",
      "rna-BB28_RS07080\t117\t3.947\t471011.580080\t23945.000\n",
      "rna-BB28_RS07075\t3114\t2864.000\t210044.911108\t7747716.000\n",
      "rna-BB28_RS07070\t1516\t1266.000\t108920.282755\t1775951.000\n",
      "rna-BB28_RS17330\t369\t119.000\t58896.341997\t90266.000\n",
      "gene-BB28_RS02220\t204\t9.377\t5705.112178\t689.000\n",
      "gene-BB28_RS20695\t231\t14.032\t5572.227396\t1007.000\n",
      "rna-BB28_RS09710\t405\t155.000\t4723.298806\t9429.000\n",
      "gene-BB28_RS18745\t300\t51.326\t2810.760733\t1858.000\n",
      "gene-BB28_RS18945\t222\t12.150\t2703.121056\t423.000\n",
      "gene-BB28_RS24750\t102\t3.543\t2651.632798\t121.000\n",
      "sort: write failed: 'standard output': Broken pipe\n",
      "sort: write error\n",
      "rna-BB28_RS07080\t117\t3.947\t454130.447356\t24081.000\n",
      "rna-BB28_RS07075\t3114\t2864.000\t201989.488820\t7771430.000\n",
      "rna-BB28_RS07070\t1516\t1266.000\t111212.828855\t1891419.000\n",
      "rna-BB28_RS17330\t369\t119.000\t63330.061498\t101241.000\n",
      "gene-BB28_RS02220\t204\t9.377\t5707.727308\t719.000\n",
      "rna-BB28_RS09710\t405\t155.000\t5617.507157\t11697.000\n",
      "gene-BB28_RS20695\t231\t14.032\t5564.987693\t1049.000\n",
      "gene-BB28_RS24750\t102\t3.543\t3130.427425\t149.000\n",
      "gene-BB28_RS18745\t300\t51.326\t2981.883266\t2056.000\n",
      "gene-BB28_RS18945\t222\t12.150\t2885.595118\t471.000\n",
      "sort: write failed: 'standard output': Broken pipe\n",
      "sort: write error\n",
      "rna-BB28_RS07080\t117\t3.947\t355332.823617\t16373.000\n",
      "rna-BB28_RS07075\t3114\t2864.000\t274176.036012\t9166440.000\n",
      "rna-BB28_RS07070\t1516\t1266.000\t127530.961325\t1884723.000\n",
      "rna-BB28_RS17330\t369\t119.000\t68674.936798\t95399.000\n",
      "gene-BB28_RS02220\t204\t9.377\t7436.347792\t814.000\n",
      "gene-BB28_RS20695\t231\t14.032\t6263.787897\t1026.000\n",
      "rna-BB28_RS09710\t405\t155.000\t4235.704000\t7664.000\n",
      "gene-BB28_RS18945\t222\t12.150\t3757.877848\t533.000\n",
      "gene-BB28_RS24750\t102\t3.543\t3409.081991\t141.000\n",
      "gene-BB28_RS18745\t300\t51.326\t2905.810315\t1741.000\n",
      "sort: write failed: 'standard output': Broken pipe\n",
      "sort: write error\n",
      "rna-BB28_RS07080\t117\t3.947\t342546.108012\t16587.000\n",
      "rna-BB28_RS07075\t3114\t2864.000\t261467.209856\t9186378.000\n",
      "rna-BB28_RS07070\t1516\t1266.000\t130755.487481\t2030709.000\n",
      "rna-BB28_RS17330\t369\t119.000\t72805.196481\t106283.000\n",
      "gene-BB28_RS02220\t204\t9.377\t7467.454408\t859.000\n",
      "gene-BB28_RS20695\t231\t14.032\t6262.569680\t1078.000\n",
      "rna-BB28_RS09710\t405\t155.000\t4782.656439\t9094.000\n",
      "gene-BB28_RS18945\t222\t12.150\t3770.473503\t562.000\n",
      "gene-BB28_RS18745\t300\t51.326\t3225.689355\t2031.000\n",
      "gene-BB28_RS24750\t102\t3.543\t2806.869957\t122.000\n",
      "sort: write failed: 'standard output': Broken pipe\n",
      "sort: write error\n"
     ]
    }
   ],
   "source": [
    "! head data/quants/SRR13349122_quant/quant.sf -n 1\n",
    "! sort -nrk 4,4 data/quants/SRR13349122_quant/quant.sf | head -10\n",
    "! sort -nrk 4,4 data/quants/SRR13349123_quant/quant.sf | head -10\n",
    "! sort -nrk 4,4 data/quants/SRR13349124_quant/quant.sf | head -10\n",
    "! sort -nrk 4,4 data/quants/SRR13349125_quant/quant.sf | head -10\n",
    "! sort -nrk 4,4 data/quants/SRR13349126_quant/quant.sf | head -10\n",
    "! sort -nrk 4,4 data/quants/SRR13349127_quant/quant.sf | head -10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Top 10 most highly expressed genes in the double lysogen samples.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name\tLength\tEffectiveLength\tTPM\tNumReads\n",
      "rna-BB28_RS07080\t117\t3.947\t453587.771883\t24652.000\n",
      "rna-BB28_RS07075\t3114\t2864.000\t246618.398908\t9725111.000\n",
      "rna-BB28_RS07070\t1516\t1266.000\t92386.166160\t1610411.000\n",
      "rna-BB28_RS17330\t369\t119.000\t77504.350847\t126990.000\n",
      "gene-BB28_RS20695\t231\t14.032\t4922.347990\t951.000\n",
      "rna-BB28_RS09710\t405\t155.000\t4304.730201\t9187.000\n",
      "gene-BB28_RS02220\t204\t9.377\t3787.444358\t489.000\n",
      "gene-BB28_RS14885\t195\t8.348\t2601.410265\t299.000\n",
      "gene-BB28_RS06975\t216\t11.099\t2538.997624\t388.000\n",
      "gene-BB28_RS21780\t213\t10.625\t2221.665444\t325.000\n",
      "sort: write failed: 'standard output': Broken pipe\n",
      "sort: write error\n",
      "rna-BB28_RS07080\t117\t3.947\t436872.913506\t24834.000\n",
      "rna-BB28_RS07075\t3114\t2864.000\t237194.551939\t9783056.000\n",
      "rna-BB28_RS07070\t1516\t1266.000\t95484.488841\t1740858.000\n",
      "rna-BB28_RS17330\t369\t119.000\t82989.979689\t142223.000\n",
      "gene-BB28_RS20695\t231\t14.032\t5394.082164\t1090.000\n",
      "rna-BB28_RS09710\t405\t155.000\t5010.356664\t11184.000\n",
      "gene-BB28_RS02220\t204\t9.377\t4117.289994\t556.000\n",
      "gene-BB28_RS14885\t195\t8.348\t3202.562794\t385.000\n",
      "gene-BB28_RS06975\t216\t11.099\t2796.645088\t447.000\n",
      "gene-BB28_RS21780\t213\t10.625\t2431.294133\t372.000\n",
      "sort: write failed: 'standard output': Broken pipe\n",
      "sort: write error\n",
      "rna-BB28_RS07080\t117\t3.947\t400396.565509\t15594.000\n",
      "rna-BB28_RS07075\t3114\t2864.000\t280221.260626\t7918566.000\n",
      "rna-BB28_RS07070\t1516\t1266.000\t94905.739835\t1185492.000\n",
      "rna-BB28_RS17330\t369\t119.000\t76574.357567\t89909.000\n",
      "rna-BB28_RS09710\t405\t155.000\t4703.335031\t7193.000\n",
      "gene-BB28_RS02220\t204\t9.377\t4042.338138\t374.000\n",
      "gene-BB28_RS20695\t231\t14.032\t3994.298915\t553.000\n",
      "gene-BB28_RS14885\t195\t8.348\t2537.508946\t209.000\n",
      "gene-BB28_RS20665\t1293\t1043.000\t2488.586999\t25610.000\n",
      "gene-BB28_RS24750\t102\t3.543\t2116.780383\t74.000\n",
      "sort: write failed: 'standard output': Broken pipe\n",
      "sort: write error\n",
      "rna-BB28_RS07080\t117\t3.947\t382359.806084\t15621.000\n",
      "rna-BB28_RS07075\t3114\t2864.000\t273837.368384\t8117225.000\n",
      "rna-BB28_RS07070\t1516\t1266.000\t98268.618385\t1287628.000\n",
      "rna-BB28_RS17330\t369\t119.000\t80916.301097\t99661.000\n",
      "rna-BB28_RS09710\t405\t155.000\t5286.564135\t8481.000\n",
      "gene-BB28_RS02220\t204\t9.377\t4420.271199\t429.000\n",
      "gene-BB28_RS20695\t231\t14.032\t4351.741563\t632.000\n",
      "gene-BB28_RS14885\t195\t8.348\t3472.267195\t300.000\n",
      "gene-BB28_RS20665\t1293\t1043.000\t2921.514088\t31538.000\n",
      "gene-BB28_RS18745\t300\t51.326\t2317.303289\t1231.000\n",
      "sort: write failed: 'standard output': Broken pipe\n",
      "sort: write error\n",
      "rna-BB28_RS07080\t117\t3.947\t413075.815812\t19297.000\n",
      "rna-BB28_RS07075\t3114\t2864.000\t262090.088830\t8883598.000\n",
      "rna-BB28_RS07070\t1516\t1266.000\t78544.912912\t1176839.000\n",
      "rna-BB28_RS17330\t369\t119.000\t68251.888089\t96123.000\n",
      "rna-BB28_RS09710\t405\t155.000\t5469.326203\t10033.000\n",
      "gene-BB28_RS20695\t231\t14.032\t4889.659519\t812.000\n",
      "gene-BB28_RS02220\t204\t9.377\t4181.057845\t464.000\n",
      "gene-BB28_RS14885\t195\t8.348\t3623.693703\t358.000\n",
      "gene-BB28_RS20665\t1293\t1043.000\t3418.147613\t42193.000\n",
      "gene-BB28_RS18945\t222\t12.150\t2746.916467\t395.000\n",
      "sort: write failed: 'standard output': Broken pipe\n",
      "sort: write error\n",
      "rna-BB28_RS07080\t117\t3.947\t397799.936302\t19555.000\n",
      "rna-BB28_RS07075\t3114\t2864.000\t249576.263443\t8901735.000\n",
      "rna-BB28_RS07070\t1516\t1266.000\t80544.979610\t1269903.000\n",
      "rna-BB28_RS17330\t369\t119.000\t71571.257834\t106068.000\n",
      "rna-BB28_RS09710\t405\t155.000\t6354.375735\t12266.000\n",
      "gene-BB28_RS20695\t231\t14.032\t5407.808634\t945.000\n",
      "gene-BB28_RS02220\t204\t9.377\t4538.485808\t530.000\n",
      "gene-BB28_RS14885\t195\t8.348\t4088.126269\t425.000\n",
      "gene-BB28_RS20665\t1293\t1043.000\t3953.204809\t51349.000\n",
      "gene-BB28_RS06975\t216\t11.099\t2995.219262\t414.000\n",
      "sort: write failed: 'standard output': Broken pipe\n",
      "sort: write error\n"
     ]
    }
   ],
   "source": [
    "! head data/quants/SRR13349122_quant/quant.sf -n 1\n",
    "! sort -nrk 4,4 data/quants/SRR13349128_quant/quant.sf | head -10\n",
    "! sort -nrk 4,4 data/quants/SRR13349129_quant/quant.sf | head -10\n",
    "! sort -nrk 4,4 data/quants/SRR13349130_quant/quant.sf | head -10\n",
    "! sort -nrk 4,4 data/quants/SRR13349131_quant/quant.sf | head -10\n",
    "! sort -nrk 4,4 data/quants/SRR13349132_quant/quant.sf | head -10\n",
    "! sort -nrk 4,4 data/quants/SRR13349133_quant/quant.sf | head -10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 12: Report the expression of a putative acyl-ACP desaturase (BB28_RS16545) that was downregulated in the double lysogen relative to wild-type\n",
    "A acyl-transferase was reported to be downregulated in the double lysogen as shown in the table of the top 20 upregulated and downregulated genes from the paper describing the study.\n",
    "![RNA-Seq workflow](images/table-cushman.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `grep` to report the expression in the wild-type sample. The fields in the Salmon `quant.sf` file are as follows. The level of expression is reported in the Transcripts Per Million (`TPM`) and number of reads (`NumReads`) fields:  \n",
    "`Name    Length  EffectiveLength TPM     NumReads`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gene-BB28_RS16545\t987\t737.000\t53.285962\t448.000\n",
      "gene-BB28_RS16545\t987\t737.000\t50.205866\t445.000\n",
      "gene-BB28_RS16545\t987\t737.000\t42.456975\t403.000\n",
      "gene-BB28_RS16545\t987\t737.000\t44.542229\t441.000\n",
      "gene-BB28_RS16545\t987\t737.000\t52.537906\t452.000\n",
      "gene-BB28_RS16545\t987\t737.000\t53.865093\t487.000\n"
     ]
    }
   ],
   "source": [
    "! grep 'BB28_RS16545' data/quants/SRR13349122_quant/quant.sf\n",
    "! grep 'BB28_RS16545' data/quants/SRR13349123_quant/quant.sf\n",
    "! grep 'BB28_RS16545' data/quants/SRR13349124_quant/quant.sf\n",
    "! grep 'BB28_RS16545' data/quants/SRR13349125_quant/quant.sf\n",
    "! grep 'BB28_RS16545' data/quants/SRR13349126_quant/quant.sf\n",
    "! grep 'BB28_RS16545' data/quants/SRR13349127_quant/quant.sf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `grep` to report the expression in the double lysogen sample. The fields in the Salmon `quant.sf` file are as follows. The level of expression is reported in the Transcripts Per Million (`TPM`) and number of reads (`NumReads`) fields:  \n",
    "`Name    Length  EffectiveLength TPM     NumReads`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gene-BB28_RS16545\t987\t737.000\t4.631635\t47.000\n",
      "gene-BB28_RS16545\t987\t737.000\t6.501069\t69.000\n",
      "gene-BB28_RS16545\t987\t737.000\t5.088172\t37.000\n",
      "gene-BB28_RS16545\t987\t737.000\t5.899337\t45.000\n",
      "gene-BB28_RS16545\t987\t737.000\t4.929872\t43.000\n",
      "gene-BB28_RS16545\t987\t737.000\t6.210249\t57.000\n"
     ]
    }
   ],
   "source": [
    "! grep 'BB28_RS16545' data/quants/SRR13349128_quant/quant.sf\n",
    "! grep 'BB28_RS16545' data/quants/SRR13349129_quant/quant.sf\n",
    "! grep 'BB28_RS16545' data/quants/SRR13349130_quant/quant.sf\n",
    "! grep 'BB28_RS16545' data/quants/SRR13349131_quant/quant.sf\n",
    "! grep 'BB28_RS16545' data/quants/SRR13349132_quant/quant.sf\n",
    "! grep 'BB28_RS16545' data/quants/SRR13349133_quant/quant.sf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 12: Combine Genecounts to a Single Genecount File\n",
    "Commonly, the readcounts for each sample are combined into a single table, where the rows contain the gene ID, and the columns identify the sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Version Server Response: Not Found\n",
      "\u001b[00m[2026-01-05 19:38:49.936] [mergeLog] [info] samples: [ data/quants/SRR13349122_quant, data/quants/SRR13349123_quant, data/quants/SRR13349124_quant, data/quants/SRR13349125_quant, data/quants/SRR13349126_quant, data/quants/SRR13349127_quant, data/quants/SRR13349128_quant, data/quants/SRR13349129_quant, data/quants/SRR13349130_quant, data/quants/SRR13349131_quant, data/quants/SRR13349132_quant, data/quants/SRR13349133_quant ]\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:38:49.936] [mergeLog] [info] sample names : [ SRR13349122_quant, SRR13349123_quant, SRR13349124_quant, SRR13349125_quant, SRR13349126_quant, SRR13349127_quant, SRR13349128_quant, SRR13349129_quant, SRR13349130_quant, SRR13349131_quant, SRR13349132_quant, SRR13349133_quant ]\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:38:49.936] [mergeLog] [info] output column : NUMREADS\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:38:49.936] [mergeLog] [info] output file : data/quants/merged_quants.txt\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:38:49.936] [mergeLog] [info] Parsing data/quants/SRR13349122_quant/quant.sf\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:38:49.942] [mergeLog] [info] Parsing data/quants/SRR13349123_quant/quant.sf\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:38:49.947] [mergeLog] [info] Parsing data/quants/SRR13349124_quant/quant.sf\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:38:49.954] [mergeLog] [info] Parsing data/quants/SRR13349125_quant/quant.sf\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:38:49.961] [mergeLog] [info] Parsing data/quants/SRR13349126_quant/quant.sf\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:38:49.969] [mergeLog] [info] Parsing data/quants/SRR13349127_quant/quant.sf\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:38:49.974] [mergeLog] [info] Parsing data/quants/SRR13349128_quant/quant.sf\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:38:49.980] [mergeLog] [info] Parsing data/quants/SRR13349129_quant/quant.sf\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:38:49.985] [mergeLog] [info] Parsing data/quants/SRR13349130_quant/quant.sf\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:38:49.994] [mergeLog] [info] Parsing data/quants/SRR13349131_quant/quant.sf\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:38:49.999] [mergeLog] [info] Parsing data/quants/SRR13349132_quant/quant.sf\n",
      "\u001b[00m\u001b[00m[2026-01-05 19:38:50.005] [mergeLog] [info] Parsing data/quants/SRR13349133_quant/quant.sf\n",
      "\u001b[00mAn example of a combined genecount outputfile.\n",
      "Name\tSRR13349122\tSRR13349123\tSRR13349124\tSRR13349125\tSRR13349126\tSRR13349127\tSRR13349128\tSRR13349129\tSRR13349130\tSRR13349131\tSRR13349132\tSRR13349133\n",
      "BB28_RS24845\t59\t59\t40\t54\t47\t58\t14\t31\t21\t15\t19\t27\n",
      "BB28_RS24840\t156\t152\t138\t158\t118\t170\t49\t52\t41\t40\t64\t73\n",
      "BB28_RS24300\t495\t525\t396\t438\t438\t493\t155\t197\t128\t131\t180\t225\n",
      "BB28_RS24270\t2\t1\t3\t1\t0\t0\t1\t0\t0\t0\t1\t2\n",
      "BB28_RS24265\t9\t17\t5\t9\t2\t15\t2\t3\t2\t4\t8\t1\n",
      "BB28_RS24255\t13\t9\t13\t10\t10\t7\t14\t19\t13\t21\t24\t34\n",
      "BB28_RS24245\t458\t593\t324\t410\t359\t440\t186\t211\t144\t204\t253\t295\n",
      "BB28_RS24230\t62\t62\t49\t70\t58\t33\t66\t76\t45\t66\t93\t115\n",
      "BB28_RS24220\t525\t633\t452\t505\t401\t490\t298\t353\t276\t361\t495\t588\n"
     ]
    }
   ],
   "source": [
    "##first merge salmon files by number of reads.\n",
    "! salmon quantmerge --column numreads --quants data/quants/*_quant -o data/quants/merged_quants.txt\n",
    "##optinally we can rename the columns\n",
    "! sed -i \"1s/.*/Name\\tSRR13349122\\tSRR13349123\\tSRR13349124\\tSRR13349125\\tSRR13349126\\tSRR13349127\\tSRR13349128\\tSRR13349129\\tSRR13349130\\tSRR13349131\\tSRR13349132\\tSRR13349133/\" data/quants/merged_quants.txt\n",
    "\n",
    "##for further formatting, it may be easier in our r-code to later merge\n",
    "##if we remove the gene- and rna- prefix\n",
    "! sed -i \"s/gene-//\" data/quants/merged_quants.txt\n",
    "! sed -i \"s/rna-//\" data/quants/merged_quants.txt\n",
    "\n",
    "print(\"An example of a combined genecount outputfile.\")\n",
    "! head data/quants/merged_quants.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name=\"workflow\">Additional Workflows</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you have read counts per gene, feel free to explore the R workflow which creates plots and analyses using these readcount files, or try other alternate workflows for creating read count files, such as using snakemake."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "[Workflow One:](Tutorial_1.ipynb) A short introduction to downloading and mapping sequences to a transcriptome using Trimmomatic and Salmon. Here is a link to the YouTube video demonstrating the tutorial: <https://youtu.be/ChGfBR4do_Y>.\n",
    "\n",
    "[Workflow One (Extended):](Tutorial_1B_Extended.ipynb) An extended version of workflow one. Once you have got your feet wet, you can retry workflow one with this extended version that covers the entire dataset, and includes elaboration such as using SRA tools for sequence downloading, and examples of running batches of fastq files through the pipeline. This workflow may take around an hour to run.\n",
    "\n",
    "[Workflow One (Using Snakemake):](Tutorial_2_Snakemake.ipynb) Using snakemake to run workflow one.\n",
    "\n",
    "[Workflow Two (DEG Analysis):](Tutorial_3_DEG_Analysis.ipynb) Using Deseq2 and R to conduct clustering and differential gene expression analysis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![RNA-Seq workflow](images/RNA-Seq_Notebook_Homepage.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This extended RNA-Seq analysis tutorial provided a comprehensive workflow for processing RNA-Seq data, from raw SRA files to a combined gene count table suitable for differential gene expression analysis.  We demonstrated the use of various bioinformatics tools, including `prefetch`, `fasterq-dump`, `Trimmomatic`, `FastQC`, `MultiQC`, `Salmon`, `entrez-direct`, and `gffread`,  highlighting best practices for data management and efficient command-line execution, particularly for batch processing of multiple samples. The tutorial included detailed steps for downloading data from the NCBI SRA database, utilizing both manual accession identification and an optional approach leveraging Google Cloud BigQuery for programmatic retrieval.  The integration of these tools facilitated quality control, read trimming, transcriptome preparation, read alignment, and quantification, culminating in a consolidated gene count file.  This workflow, although time-consuming due to the processing of full FASTQ datasets, provides a robust foundation for more advanced analyses such as those detailed in the subsequent Snakemake and DEG analysis tutorials.  The resulting gene count matrix serves as a crucial input for downstream differential expression analyses, building upon the knowledge gained in this comprehensive guide."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean Up\n",
    "\n",
    "Remember to move to the next notebook or shut down your instance if you are finished."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m137",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m137"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
